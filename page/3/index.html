<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-07-13-【faster rcnn】roi_pooling_layer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-07-13-【faster rcnn】roi_pooling_layer/" itemprop="url">【faster rcnn】roi_pooling_layer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前说过，caffe中的layer层，主要有以下几个函数：</p>
<ul>
<li>setup</li>
<li>reshape</li>
<li>forward</li>
<li>backward</li>
</ul>
<p>在roi_pooling_layer.cpp中，主要是前三个函数，在分别对其进行解析之前，先看一下该层的使用：</p>
<pre><code>layer {
  name: &quot;roi_pool_conv5&quot;
  type: &quot;ROIPooling&quot;
  bottom: &quot;conv5&quot;
  bottom: &quot;rois&quot;
  top: &quot;roi_pool_conv5&quot;
  roi_pooling_param {
    pooled_w: 6
    pooled_h: 6
    spatial_scale: 0.0625 # 1/16
  }
}
</code></pre><p>即该层的输入为<code>conv5</code>的特征图和<code>rois</code>，最后输出<code>roi_pool_conv5</code>。</p>
<p>下面看以下初始化函数<code>LayerSetUp()</code>：</p>
<hr>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::LayerSetUp(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  ROIPoolingParameter roi_pool_param = <span class="keyword">this</span>-&gt;layer_param_.roi_pooling_param();</span><br><span class="line">  CHECK_GT(roi_pool_param.pooled_h(), <span class="number">0</span>)</span><br><span class="line">      &lt;&lt; <span class="string">"pooled_h must be &gt; 0"</span>;</span><br><span class="line">  CHECK_GT(roi_pool_param.pooled_w(), <span class="number">0</span>)</span><br><span class="line">      &lt;&lt; <span class="string">"pooled_w must be &gt; 0"</span>;</span><br><span class="line">  pooled_height_ = roi_pool_param.pooled_h();   <span class="comment">// pooling后的特征图的height_</span></span><br><span class="line">  pooled_width_ = roi_pool_param.pooled_w();    <span class="comment">// pooling后的特征图的width_</span></span><br><span class="line">  spatial_scale_ = roi_pool_param.spatial_scale(); <span class="comment">// 空间缩放尺度，在ZF中为1/16 = 0.0625</span></span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Spatial scale: "</span> &lt;&lt; spatial_scale_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面函数的作用是设置pooling后的特征图的尺寸<code>height_</code>和<code>width_</code>，以及pooling后的特征图相对于原图1的缩放比例scale。看一下<code>reshape</code>部分：</p>
<hr>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Reshape(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  channels_ = bottom[<span class="number">0</span>]-&gt;channels();</span><br><span class="line">  height_ = bottom[<span class="number">0</span>]-&gt;height();</span><br><span class="line">  width_ = bottom[<span class="number">0</span>]-&gt;width();</span><br><span class="line">  top[<span class="number">0</span>]-&gt;Reshape(bottom[<span class="number">1</span>]-&gt;num(), channels_, pooled_height_,</span><br><span class="line">      pooled_width_);</span><br><span class="line">  max_idx_.Reshape(bottom[<span class="number">1</span>]-&gt;num(), channels_, pooled_height_,</span><br><span class="line">      pooled_width_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过这段代码，可以看出:<br>输出的<code>top</code>个数等于<code>rois</code>的个数，<code>channels</code>等于特征图<code>conv5</code>的channels。</p>
<p>另外，注意<code>top_data</code>作为<code>top[0]</code>的指针，在每个channel上更新一次（通过下面的循环可以看出）；大小一共<code>pooled_height_*pooled_width_</code>个。这些都可以通过<code>forward()</code>中的循环得到。</p>
<hr>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Forward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line">  <span class="comment">// Number of ROIs</span></span><br><span class="line">  <span class="keyword">int</span> num_rois = bottom[<span class="number">1</span>]-&gt;num();</span><br><span class="line">  <span class="keyword">int</span> batch_size = bottom[<span class="number">0</span>]-&gt;num();</span><br><span class="line">  <span class="keyword">int</span> top_count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_cpu_data();</span><br><span class="line">  caffe_set(top_count, Dtype(-FLT_MAX), top_data);</span><br><span class="line">  <span class="keyword">int</span>* argmax_data = max_idx_.mutable_cpu_data();</span><br><span class="line">  caffe_set(top_count, <span class="number">-1</span>, argmax_data);</span><br><span class="line">	</span><br><span class="line">  <span class="comment">// For each ROI R = [batch_index x1 y1 x2 y2]: max pool over R</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; num_rois; ++n) &#123;</span><br><span class="line">    <span class="keyword">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> roi_start_w = round(bottom_rois[<span class="number">1</span>] * spatial_scale_);</span><br><span class="line">    <span class="keyword">int</span> roi_start_h = round(bottom_rois[<span class="number">2</span>] * spatial_scale_);</span><br><span class="line">    <span class="keyword">int</span> roi_end_w = round(bottom_rois[<span class="number">3</span>] * spatial_scale_);</span><br><span class="line">    <span class="keyword">int</span> roi_end_h = round(bottom_rois[<span class="number">4</span>] * spatial_scale_);</span><br><span class="line">    CHECK_GE(roi_batch_ind, <span class="number">0</span>);</span><br><span class="line">    CHECK_LT(roi_batch_ind, batch_size);</span><br><span class="line">    <span class="keyword">int</span> roi_height = max(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> roi_width = max(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<hr>
<p>由于<code>rois</code>是在原图1的尺寸下，而此处的特征图<code>conv5</code>是经过前面convolution和Pooling后被缩小的，因此需要将<code>rois</code>投影到该尺寸下。</p>
<hr>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">// 此处是求roi在每个pooling单元占据的面积，但是分height和width来计算。</span></span><br><span class="line">	<span class="comment">// pooling对‘经过scale变换，映射到特征图上的真实的roi‘的划分</span></span><br><span class="line">    <span class="keyword">const</span> Dtype bin_size_h = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                             / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_height_);</span><br><span class="line">    <span class="keyword">const</span> Dtype bin_size_w = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                             / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_width_);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">const</span> Dtype* batch_data = bottom_data + bottom[<span class="number">0</span>]-&gt;offset(roi_batch_ind);</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>; c &lt; channels_; ++c) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> ph = <span class="number">0</span>; ph &lt; pooled_height_; ++ph) &#123;                  <span class="comment">//标称值，如果pooling结果为6*6,，那么这里就是0~5的循环。</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> pw = <span class="number">0</span>; pw &lt; pooled_width_; ++pw) &#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 此处的循环以pooling中的ceil（标称值）为单位。</span></span><br><span class="line">          <span class="comment">// Compute pooling region for this output unit:</span></span><br><span class="line">          <span class="comment">//  start (included) = floor(ph * roi_height / pooled_height_)</span></span><br><span class="line">          <span class="comment">//  end (excluded) = ceil((ph + 1) * roi_height / pooled_height_)</span></span><br><span class="line">        <span class="comment">// 特征图上每个单元格，通过标称值遍历，定位在真实的特征图conv_5上</span></span><br><span class="line">          <span class="keyword">int</span> hstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph)</span><br><span class="line">                                              * bin_size_h));</span><br><span class="line">          <span class="keyword">int</span> wstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw)</span><br><span class="line">                                              * bin_size_w));</span><br><span class="line">          <span class="keyword">int</span> hend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_h));</span><br><span class="line">          <span class="keyword">int</span> wend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_w));</span><br><span class="line">	<span class="comment">// 此处的hstart、hend、wstart、wend是以ceil为前后界，以roi为基准的绝对的坐标</span></span><br><span class="line">          hstart = min(max(hstart + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          hend = min(max(hend + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          wstart = min(max(wstart + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">          wend = min(max(wend + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">	</span><br><span class="line">          <span class="keyword">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line">	</span><br><span class="line">          <span class="keyword">const</span> <span class="keyword">int</span> pool_index = ph * pooled_width_ + pw;</span><br><span class="line">          <span class="keyword">if</span> (is_empty) &#123;</span><br><span class="line">            top_data[pool_index] = <span class="number">0</span>;</span><br><span class="line">            argmax_data[pool_index] = <span class="number">-1</span>;</span><br><span class="line">          &#125;</span><br><span class="line">	<span class="comment">// 此处的循环以roi在ceil中的每个特征点为单位</span></span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> h = hstart; h &lt; hend; ++h) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> w = wstart; w &lt; wend; ++w) &#123;</span><br><span class="line">              <span class="keyword">const</span> <span class="keyword">int</span> index = h * width_ + w;</span><br><span class="line">        <span class="comment">//每个单元格只取其对应特征图区域中的一个值，这里取最大值。</span></span><br><span class="line">              <span class="keyword">if</span> (batch_data[index] &gt; top_data[pool_index]) &#123;</span><br><span class="line">                top_data[pool_index] = batch_data[index];</span><br><span class="line">                argmax_data[pool_index] = index;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//指针指向的地址需要增加1，因为每个channel是独立进行roi_pooling的。  </span></span><br><span class="line">      <span class="comment">// Increment all data pointers by one channel</span></span><br><span class="line">      batch_data += bottom[<span class="number">0</span>]-&gt;offset(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      top_data += top[<span class="number">0</span>]-&gt;offset(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      argmax_data += max_idx_.offset(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Increment ROI data pointer</span></span><br><span class="line">    bottom_rois += bottom[<span class="number">1</span>]-&gt;offset(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><hr>
<p>该网络 <strong>A：</strong> 在原图0的基础上， <strong>B：</strong> 根据前面的网络（rpn）生成的roi，在conv_5上进行pooling，相应地尺寸要通过<code>* spatial_scale_</code>调整， <strong>C：</strong> 最后得到具有固定尺寸的，在conv_5的特征图上进行pooling之后的‘pooled feature map’（输出的尺寸是作为参数设定好的）。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><hr>
<p><a href="https://blog.csdn.net/iamzhangzhuping/article/details/51500162" target="_blank" rel="noopener">https://blog.csdn.net/iamzhangzhuping/article/details/51500162</a></p>
<p><a href="https://blog.csdn.net/Charel_CHEN/article/details/78669654" target="_blank" rel="noopener">https://blog.csdn.net/Charel_CHEN/article/details/78669654</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-07-08-【faster-rcnn】网络的数据投喂——RoIDataLayer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-07-08-【faster-rcnn】网络的数据投喂——RoIDataLayer/" itemprop="url">【faster-rcnn】网络的数据投喂——RoIDataLayer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>对于caffe中的layer，主要有以下几个<a href="http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html" target="_blank" rel="noopener">性质</a>：</p>
<ul>
<li>setup</li>
<li>forward</li>
<li>backward</li>
</ul>
<p>对于所有的data layer而言，主要是前两点，这里也不例外。</p>
<h4 id="RoIDataLayer"><a href="#RoIDataLayer" class="headerlink" title="RoIDataLayer"></a>RoIDataLayer</h4><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup</span><span class="params">(self, bottom, top)</span>:</span></span><br><span class="line">    <span class="string">"""Setup the RoIDataLayer."""</span></span><br><span class="line">	</span><br><span class="line">    <span class="comment"># parse the layer parameter string, which must be valid YAML</span></span><br><span class="line">    layer_params = yaml.load(self.param_str_)</span><br><span class="line">	</span><br><span class="line">    self._num_classes = layer_params[<span class="string">'num_classes'</span>]</span><br><span class="line">	</span><br><span class="line">    self._name_to_top_map = &#123;&#125;</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># data blob: holds a batch of N images, each with 3 channels</span></span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    top[idx].reshape(cfg.TRAIN.IMS_PER_BATCH, <span class="number">3</span>,</span><br><span class="line">        max(cfg.TRAIN.SCALES), cfg.TRAIN.MAX_SIZE)</span><br><span class="line">    self._name_to_top_map[<span class="string">'data'</span>] = idx</span><br><span class="line">    idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">    <span class="keyword">if</span> cfg.TRAIN.HAS_RPN:</span><br><span class="line">        top[idx].reshape(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        self._name_to_top_map[<span class="string">'im_info'</span>] = idx</span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">        top[idx].reshape(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">        self._name_to_top_map[<span class="string">'gt_boxes'</span>] = idx</span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># not using RPN</span></span><br><span class="line">        <span class="comment"># rois blob: holds R regions of interest, each is a 5-tuple</span></span><br><span class="line">        <span class="comment"># (n, x1, y1, x2, y2) specifying an image batch index n and a</span></span><br><span class="line">        <span class="comment"># rectangle (x1, y1, x2, y2)</span></span><br><span class="line">        top[idx].reshape(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">        self._name_to_top_map[<span class="string">'rois'</span>] = idx</span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">        <span class="comment"># labels blob: R categorical labels in [0, ..., K] for K foreground</span></span><br><span class="line">        <span class="comment"># classes plus background</span></span><br><span class="line">        top[idx].reshape(<span class="number">1</span>)</span><br><span class="line">        self._name_to_top_map[<span class="string">'labels'</span>] = idx</span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">        <span class="keyword">if</span> cfg.TRAIN.BBOX_REG:</span><br><span class="line">            <span class="comment"># bbox_targets blob: R bounding-box regression targets with 4</span></span><br><span class="line">            <span class="comment"># targets per class</span></span><br><span class="line">            top[idx].reshape(<span class="number">1</span>, self._num_classes * <span class="number">4</span>)</span><br><span class="line">            self._name_to_top_map[<span class="string">'bbox_targets'</span>] = idx</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">            <span class="comment"># bbox_inside_weights blob: At most 4 targets per roi are active;</span></span><br><span class="line">            <span class="comment"># thisbinary vector sepcifies the subset of active targets</span></span><br><span class="line">            top[idx].reshape(<span class="number">1</span>, self._num_classes * <span class="number">4</span>)</span><br><span class="line">            self._name_to_top_map[<span class="string">'bbox_inside_weights'</span>] = idx</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">            top[idx].reshape(<span class="number">1</span>, self._num_classes * <span class="number">4</span>)</span><br><span class="line">            self._name_to_top_map[<span class="string">'bbox_outside_weights'</span>] = idx</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">	</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'RoiDataLayer: name_to_top:'</span>, self._name_to_top_map</span><br><span class="line">    <span class="keyword">assert</span> len(top) == len(self._name_to_top_map)</span><br></pre></td></tr></table></figure>
<p>可以看到，这里主要建立了一个字典<code>_name_to_top_map</code>，用来存放一种关系——blob的name（key）及其在top中对应的顺序。在训练rpn时候roi为gt，在训练fast-rcnn时候roi为rpn框+gt.因为我们在写网络时，可能不清楚这个顺序，只知道输入blob的name，如<code>data</code>、<code>rois</code>、<code>labels</code>等，因此在给网络中的blob（top）赋值的时候，依据的智能是作为key的name。（<strong>为什么不直接把top建立为dictionary呢？</strong>）。</p>
<p>接下来是<code>forward()</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, bottom, top)</span>:</span></span><br><span class="line">    <span class="string">"""Get blobs and copy them into this layer's top blob vector."""</span></span><br><span class="line">    blobs = self._get_next_minibatch()</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">for</span> blob_name, blob <span class="keyword">in</span> blobs.iteritems():</span><br><span class="line">        top_ind = self._name_to_top_map[blob_name]</span><br><span class="line">        <span class="comment"># Reshape net's input blobs</span></span><br><span class="line">        top[top_ind].reshape(*(blob.shape))</span><br><span class="line">        <span class="comment"># Copy data into net's input blobs</span></span><br><span class="line">        top[top_ind].data[...] = blob.astype(np.float32, copy=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>即根据blob的name找到对应的top，然后reshape为同样的size，最后赋值。这样我们就将初始的数据加载到网络中了（虽然在生成proposal时没有用到这一点，但是很快就会用到）。</p>
<p>实际上在传给网络之前，已经将roidb改过名字，然后才变成blob。<code>forward()</code>中的第一句，看一下函数<code>_get_next_minibatch()</code>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_next_minibatch</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Return the blobs to be used for the next minibatch.</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">    If cfg.TRAIN.USE_PREFETCH is True, then blobs will be computed in a</span></span><br><span class="line"><span class="string">    separate process and made available through self._blob_queue.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> cfg.TRAIN.USE_PREFETCH:</span><br><span class="line">        <span class="keyword">return</span> self._blob_queue.get()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        db_inds = self._get_next_minibatch_inds()</span><br><span class="line">        minibatch_db = [self._roidb[i] <span class="keyword">for</span> i <span class="keyword">in</span> db_inds]</span><br><span class="line">        <span class="keyword">return</span> get_minibatch(minibatch_db, self._num_classes)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_minibatch</span><span class="params">(roidb, num_classes)</span>:</span></span><br><span class="line">    <span class="string">"""Given a roidb, construct a minibatch sampled from it."""</span></span><br><span class="line">    num_images = len(roidb)</span><br><span class="line">    <span class="comment"># Sample random scales to use for each image in this batch</span></span><br><span class="line">    random_scale_inds = npr.randint(<span class="number">0</span>, high=len(cfg.TRAIN.SCALES),</span><br><span class="line">                                    size=num_images)</span><br><span class="line">    <span class="keyword">assert</span>(cfg.TRAIN.BATCH_SIZE % num_images == <span class="number">0</span>), \</span><br><span class="line">        <span class="string">'num_images (&#123;&#125;) must divide BATCH_SIZE (&#123;&#125;)'</span>. \</span><br><span class="line">        format(num_images, cfg.TRAIN.BATCH_SIZE)</span><br><span class="line">    rois_per_image = cfg.TRAIN.BATCH_SIZE / num_images</span><br><span class="line">    fg_rois_per_image = np.round(cfg.TRAIN.FG_FRACTION * rois_per_image)</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># Get the input image blob, formatted for caffe</span></span><br><span class="line">    im_blob, im_scales = _get_image_blob(roidb, random_scale_inds)</span><br><span class="line">	</span><br><span class="line">    blobs = &#123;<span class="string">'data'</span>: im_blob&#125;</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">if</span> cfg.TRAIN.HAS_RPN:</span><br><span class="line">        <span class="keyword">assert</span> len(im_scales) == <span class="number">1</span>, <span class="string">"Single batch only"</span></span><br><span class="line">        <span class="keyword">assert</span> len(roidb) == <span class="number">1</span>, <span class="string">"Single batch only"</span></span><br><span class="line">        <span class="comment"># gt boxes: (x1, y1, x2, y2, cls)</span></span><br><span class="line">        gt_inds = np.where(roidb[<span class="number">0</span>][<span class="string">'gt_classes'</span>] != <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        gt_boxes = np.empty((len(gt_inds), <span class="number">5</span>), dtype=np.float32)</span><br><span class="line">        gt_boxes[:, <span class="number">0</span>:<span class="number">4</span>] = roidb[<span class="number">0</span>][<span class="string">'boxes'</span>][gt_inds, :] * im_scales[<span class="number">0</span>]</span><br><span class="line">        gt_boxes[:, <span class="number">4</span>] = roidb[<span class="number">0</span>][<span class="string">'gt_classes'</span>][gt_inds]</span><br><span class="line">        blobs[<span class="string">'gt_boxes'</span>] = gt_boxes</span><br><span class="line">        blobs[<span class="string">'im_info'</span>] = np.array(</span><br><span class="line">            [[im_blob.shape[<span class="number">2</span>], im_blob.shape[<span class="number">3</span>], im_scales[<span class="number">0</span>]]],</span><br><span class="line">            dtype=np.float32)</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># not using RPN</span></span><br><span class="line">        <span class="comment"># Now, build the region of interest and label blobs</span></span><br><span class="line">        rois_blob = np.zeros((<span class="number">0</span>, <span class="number">5</span>), dtype=np.float32)</span><br><span class="line">        labels_blob = np.zeros((<span class="number">0</span>), dtype=np.float32)</span><br><span class="line">        bbox_targets_blob = np.zeros((<span class="number">0</span>, <span class="number">4</span> * num_classes), dtype=np.float32)</span><br><span class="line">        bbox_inside_blob = np.zeros(bbox_targets_blob.shape, dtype=np.float32)</span><br><span class="line">        <span class="comment"># all_overlaps = []</span></span><br><span class="line">        <span class="keyword">for</span> im_i <span class="keyword">in</span> xrange(num_images):</span><br><span class="line">            labels, overlaps, im_rois, bbox_targets, bbox_inside_weights \</span><br><span class="line">                = _sample_rois(roidb[im_i], fg_rois_per_image, rois_per_image,</span><br><span class="line">                               num_classes)</span><br><span class="line">	</span><br><span class="line">            <span class="comment"># Add to RoIs blob</span></span><br><span class="line">            rois = _project_im_rois(im_rois, im_scales[im_i])</span><br><span class="line">            batch_ind = im_i * np.ones((rois.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line">            rois_blob_this_image = np.hstack((batch_ind, rois))</span><br><span class="line">            rois_blob = np.vstack((rois_blob, rois_blob_this_image))</span><br><span class="line">	</span><br><span class="line">            <span class="comment"># Add to labels, bbox targets, and bbox loss blobs</span></span><br><span class="line">            labels_blob = np.hstack((labels_blob, labels))</span><br><span class="line">            bbox_targets_blob = np.vstack((bbox_targets_blob, bbox_targets))</span><br><span class="line">            bbox_inside_blob = np.vstack((bbox_inside_blob, bbox_inside_weights))</span><br><span class="line">            <span class="comment"># all_overlaps = np.hstack((all_overlaps, overlaps))</span></span><br><span class="line">	</span><br><span class="line">        <span class="comment"># For debug visualizations</span></span><br><span class="line">        <span class="comment"># _vis_minibatch(im_blob, rois_blob, labels_blob, all_overlaps)</span></span><br><span class="line">	</span><br><span class="line">        blobs[<span class="string">'rois'</span>] = rois_blob</span><br><span class="line">        blobs[<span class="string">'labels'</span>] = labels_blob</span><br><span class="line">	</span><br><span class="line">        <span class="keyword">if</span> cfg.TRAIN.BBOX_REG:</span><br><span class="line">            blobs[<span class="string">'bbox_targets'</span>] = bbox_targets_blob</span><br><span class="line">            blobs[<span class="string">'bbox_inside_weights'</span>] = bbox_inside_blob</span><br><span class="line">            blobs[<span class="string">'bbox_outside_weights'</span>] = \</span><br><span class="line">                np.array(bbox_inside_blob &gt; <span class="number">0</span>).astype(np.float32)</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">return</span> blobs</span><br><span class="line">```	</span><br><span class="line">上面这个函数 **==非常重要！==**</span><br><span class="line"></span><br><span class="line">对于原图，可以看出无论是否使用rpn，都将对图片进行规范，即由原图<span class="number">0</span> resize到原图<span class="number">1</span>，然后加载到网络中的`data`为原图<span class="number">1.</span>在使用rpn时（`cfg.TRAIN.HAS_RPN = Ture`），需要得到resize的信息，因为需要gt_boxes，而这些框的标注是基于原图<span class="number">0</span>，所以需要将其对应地规范到原图<span class="number">1</span>。在`train_rpn()`阶段如此，在`rpn_proposal()`阶段也是如此，需要将proposals还原到原图<span class="number">0</span>的尺寸，以便后面和gt_roidb合并到一起。而不使用rpn时（`cfg.TRAIN.HAS_RPN = <span class="keyword">False</span>`），虽然也对图片进行规范，但是不需要知道这些信息。因为gt_boxes和proposals都相应地规范。</span><br><span class="line"></span><br><span class="line">对于标注框：在使用rpn时，没有对标注框进行规范，因为需要求偏移量（`train_rpn`），需要根据偏移量得到proposals（`rpn_generate`），并将其和gt_roidb保存到一起，而后者是基于原图<span class="number">0</span>进行标注的，因此需要保持尺度（gt_roidb、偏移量、proposals）的一致性。在不使用rpn时（`train_fast_crnn`），由于目的是训练网络，不需要对标注性的文件、数据进行操作，因此直接对标注框进行了相应地规范。</span><br><span class="line">```python</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_project_im_rois</span><span class="params">(im_rois, im_scale_factor)</span>:</span></span><br><span class="line">    <span class="string">"""Project image RoIs into the rescaled training image."""</span></span><br><span class="line">    rois = im_rois * im_scale_factor</span><br><span class="line">    <span class="keyword">return</span> rois</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_image_blob</span><span class="params">(roidb, scale_inds)</span>:</span></span><br><span class="line">    <span class="string">"""Builds an input blob from the images in the roidb at the specified</span></span><br><span class="line"><span class="string">    scales.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    num_images = len(roidb)</span><br><span class="line">    processed_ims = []</span><br><span class="line">    im_scales = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_images):</span><br><span class="line">        im = cv2.imread(roidb[i][<span class="string">'image'</span>])</span><br><span class="line">        <span class="keyword">if</span> roidb[i][<span class="string">'flipped'</span>]:</span><br><span class="line">            im = im[:, ::<span class="number">-1</span>, :]</span><br><span class="line">        target_size = cfg.TRAIN.SCALES[scale_inds[i]]</span><br><span class="line">        im, im_scale = prep_im_for_blob(im, cfg.PIXEL_MEANS, target_size,</span><br><span class="line">                                        cfg.TRAIN.MAX_SIZE)</span><br><span class="line">        im_scales.append(im_scale)</span><br><span class="line">        processed_ims.append(im)</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># Create a blob to hold the input images</span></span><br><span class="line">    blob = im_list_to_blob(processed_ims)</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">return</span> blob, im_scales</span><br><span class="line">	</span><br><span class="line"><span class="comment">## 该函数的作用是将opencv读进来的image格式转换为caffe中的image格式，即[n,c,h,w]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im_list_to_blob</span><span class="params">(ims)</span>:</span></span><br><span class="line">    <span class="string">"""Convert a list of images into a network input.</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">    Assumes images are already prepared (means subtracted, BGR order, ...).</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    max_shape = np.array([im.shape <span class="keyword">for</span> im <span class="keyword">in</span> ims]).max(axis=<span class="number">0</span>)</span><br><span class="line">    num_images = len(ims)</span><br><span class="line">    blob = np.zeros((num_images, max_shape[<span class="number">0</span>], max_shape[<span class="number">1</span>], <span class="number">3</span>),</span><br><span class="line">                    dtype=np.float32)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_images):</span><br><span class="line">        im = ims[i]</span><br><span class="line">        blob[i, <span class="number">0</span>:im.shape[<span class="number">0</span>], <span class="number">0</span>:im.shape[<span class="number">1</span>], :] = im</span><br><span class="line">    <span class="comment"># Move channels (axis 3) to axis 1</span></span><br><span class="line">    <span class="comment"># Axis order will become: (batch elem, channel, height, width)</span></span><br><span class="line">    channel_swap = (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    blob = blob.transpose(channel_swap)</span><br><span class="line">    <span class="keyword">return</span> blob</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:center">roidb</th>
<th style="text-align:center">blob</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">‘boxes’</td>
<td style="text-align:center">‘rois’</td>
</tr>
<tr>
<td style="text-align:center">‘max_classes’</td>
<td style="text-align:center">‘labels’</td>
</tr>
<tr>
<td style="text-align:center">由函数add_bbox_regression_targets()添加</td>
<td style="text-align:center">‘bbox_targets’</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-07-07-【faster rcnn】重装caffe——caffe-fast-rcnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-07-07-【faster rcnn】重装caffe——caffe-fast-rcnn/" itemprop="url">【faster rcnn】重装caffe——caffe-fast-rcnn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近开始上手目标检测的代码，先从别人已经成功运行的例程开始：</p>
<p><a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn</a></p>
<p>参考了几篇博客：</p>
<p><a href="http://jacobkong.github.io/posts/2093106769/" target="_blank" rel="noopener">深度学习实践经验：用Faster R-CNN训练行人检测数据集Caltech——准备工作</a></p>
<p><a href="https://blog.csdn.net/sinat_30071459/article/details/51332084" target="_blank" rel="noopener">Faster-RCNN+ZF用自己的数据集训练模型(Python版本)</a></p>
<p>刚开始说需要重新编译caffe，那么之前花费功夫编译好的caffe要删掉吗？我觉得可以不用删除，甚至可以不用重新编译。后来按照教程开始运行demo.py，结果提示：</p>
<p><code>ImportError: No module named _caffe</code></p>
<p>搜了一下，需要<code>make pycaffe</code>，可是我明明编译了python的接口，并且在/tools的路径下用终端进入python，<code>import caffe</code>都没有问题。所以只好在py-faster-rcnn的路径下重新编译caffe。我很害怕折腾，刚开始很保守地尝试了几种方案：</p>
<ul>
<li>把caffe的原始包拷贝到py-faster-rcnn，按照教程配置MakeFile.Config，不行；</li>
<li>把caffe的原始包拷贝到py-faster-rcnn，把之前的MakeFile.Config替换一下，不行；</li>
<li>把自己编译好的caffe整个文件夹拷贝到py-faster-rcnn，提示<code>350:21: Message type &quot;caffe.LayerParameter&quot; has no field named &quot;roi_pooling_param&quot;.</code>；</li>
<li>后来又查找解决方案，说是最好用作者给出的caffe-fast-rcnn进行编译，因为作者可能对官方caffe进行了一些修改，比如加入自定义的layer。同时我注意到一点，这对后来成功运行代码起到决定性作用：很多教程包括作者的原始教程，都给出了MakeFile.Config，并且<strong>注明用于参考</strong>。这说明配置文件可以不一样，需要根据自己的电脑状况个性化处理，与别的修改都没关系。然后我就想用之前编译好的caffe的MakeFile.Config，放在作者给的caffe文件夹里，然后进行编译，一切OK！</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://github.com/rbgirshick/py-faster-rcnn/issues/129" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn/issues/129</a></p>
<p><a href="https://github.com/rbgirshick/py-faster-rcnn/issues/8" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn/issues/8</a></p>
<p><a href="https://github.com/rbgirshick/fast-rcnn/issues/2" target="_blank" rel="noopener">https://github.com/rbgirshick/fast-rcnn/issues/2</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-07-06-【pytorch】resnet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-07-06-【pytorch】resnet/" itemprop="url">【pytorch】resnet</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>,</span><br><span class="line">                               bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.avgpool = nn.AvgPool2d(<span class="number">7</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.BatchNorm2d):</span><br><span class="line">                m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">	<span class="comment">####_make_layer() produce layers with the same output size and channels, which contains 'blocks' block.</span></span><br><span class="line">	<span class="comment">####downsample happens in the first layer</span></span><br><span class="line">	</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, blocks, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        downsample = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.inplanes, planes * block.expansion,</span><br><span class="line">                          kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="keyword">False</span>),</span><br><span class="line">                nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.inplanes, planes, stride, downsample))     <span class="comment">#### make the 1st sublayer in given certain layer, which needs downsample. </span></span><br><span class="line">        self.inplanes = planes * block.expansion</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, blocks):                                          <span class="comment">#### make the other layers, from 1 to blocks-1 </span></span><br><span class="line">            layers.append(block(self.inplanes, planes))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><hr>
<p>PyTorch源码解读之torchvision.models</p>
<p><a href="https://blog.csdn.net/u014380165/article/details/79119664" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/79119664</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-07-06-【pycharm】import问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-07-06-【pycharm】import问题/" itemprop="url">【pycharm】import问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Pycharm下同一目录py文件不能相互调用？</p>
<p><a href="https://blog.csdn.net/candy_gl/article/details/79222115" target="_blank" rel="noopener">https://blog.csdn.net/candy_gl/article/details/79222115</a></p>
<p>caffe debug 1-Pycharm import caffe 报错 no module named caffe</p>
<p><a href="https://www.cnblogs.com/keyky/p/6600557.html" target="_blank" rel="noopener">https://www.cnblogs.com/keyky/p/6600557.html</a></p>
<p>pycharm中import caffe/caffe2</p>
<p><a href="https://blog.csdn.net/u013010889/article/details/70808866" target="_blank" rel="noopener">https://blog.csdn.net/u013010889/article/details/70808866</a></p>
<p>pycharm加入import路径 【显示当前已添加的路径】</p>
<p><a href="https://blog.csdn.net/hongxingabc/article/details/77094059" target="_blank" rel="noopener">https://blog.csdn.net/hongxingabc/article/details/77094059</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-06-30-【caffe】python接口获取网络中的数据信息/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-06-30-【caffe】python接口获取网络中的数据信息/" itemprop="url">【caffe】python接口获取网络中的数据信息</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="查看神经网络中间层的blobs和params"><a href="#查看神经网络中间层的blobs和params" class="headerlink" title="查看神经网络中间层的blobs和params"></a>查看神经网络中间层的blobs和params</h3><p>Caffe主要处理两种形式的数据流： </p>
<ol>
<li>图像和标签在网络上的传输，随着网络的传输，它们转化更高层次的表示，最终以得分或者概率值的形式输出。 </li>
<li>第二种数据流，主要保存各个网络层的参数，比如卷积层的weights和bias. 这些值是随着的网络的训练过程不断变化的。</li>
</ol>
<p><strong>第一种形式的数据流</strong>保存在net.blobs中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.blobs</span><br></pre></td></tr></table></figure></p>
<p>它是<strong>有序字典</strong>，保存了每一层前后相应的数据。每个blob保存了data和gradient:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">net.blobs[<span class="string">'data'</span>].data.shape  <span class="comment"># &gt;&gt; (64, 1, 28, 28)</span></span><br><span class="line">net.blobs[<span class="string">'data'</span>].diff.shape  <span class="comment"># &gt;&gt; (64, 1, 28, 28)</span></span><br><span class="line"></span><br><span class="line">net.blobs[<span class="string">'conv1'</span>].data.shape  <span class="comment"># &gt;&gt; (64, 20, 24, 24)</span></span><br><span class="line">net.blobs[<span class="string">'conv1'</span>].diff.shape  <span class="comment"># &gt;&gt; (64, 20, 24, 24)</span></span><br><span class="line"></span><br><span class="line">net.blobs[<span class="string">'ip1'</span>].data.shape  <span class="comment"># &gt;&gt; (64, 500)</span></span><br><span class="line">net.blobs[<span class="string">'ip1'</span>].diff.shape  <span class="comment"># &gt;&gt; (64, 500)</span></span><br></pre></td></tr></table></figure></p>
<p><strong>第二种形式的数据流</strong>，即网络层的参数，可以通过net.layers来获得：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.layers</span><br></pre></td></tr></table></figure></p>
<p>它的第一层是data layer:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(net.layers[<span class="number">0</span>].blobs)   <span class="comment"># &gt;&gt; 0</span></span><br></pre></td></tr></table></figure></p>
<p>因为输入层没有权重参数，因此blob的个数是0</p>
<p>它的第二层是卷积层：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">len(net.layers[<span class="number">1</span>].blobs)  <span class="comment"># &gt;&gt; 2</span></span><br><span class="line"></span><br><span class="line">net.layers[<span class="number">1</span>].blobs[<span class="number">0</span>].data.shape  <span class="comment"># &gt;&gt;  (20, 1, 5, 5)  conv1 weights</span></span><br><span class="line">net.layers[<span class="number">1</span>].blobs[<span class="number">1</span>].data.shape  <span class="comment"># &gt;&gt;  (20,)  bias</span></span><br></pre></td></tr></table></figure></p>
<p>表示有20个卷积核，每个卷积核的大小是5*5，处理1-channel的输入图像。</p>
<p>还有一种获得各层参数的方式就是net.params：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data.shape   <span class="comment"># (20, 1, 5, 5)  conv1 weights</span></span><br><span class="line"><span class="keyword">print</span> net.params[<span class="string">'conv1'</span>][<span class="number">1</span>].data.shape   <span class="comment"># (20,) bias</span></span><br><span class="line">```	</span><br><span class="line">---</span><br><span class="line">	</span><br><span class="line"><span class="comment">#### 实例-查看blobs</span></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># for each layer, show the output shape</span></span><br><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">    <span class="keyword">print</span> layer_name + <span class="string">'\t'</span> + str(blob.data.shape)</span><br></pre></td></tr></table></figure></p>
<p>结果大致为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data    (<span class="number">50</span>, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>)</span><br><span class="line">conv1   (<span class="number">50</span>, <span class="number">96</span>, <span class="number">55</span>, <span class="number">55</span>)</span><br><span class="line">pool1   (<span class="number">50</span>, <span class="number">96</span>, <span class="number">27</span>, <span class="number">27</span>)</span><br><span class="line">norm1   (<span class="number">50</span>, <span class="number">96</span>, <span class="number">27</span>, <span class="number">27</span>)</span><br><span class="line">conv2   (<span class="number">50</span>, <span class="number">256</span>, <span class="number">27</span>, <span class="number">27</span>)</span><br><span class="line">pool2   (<span class="number">50</span>, <span class="number">256</span>, <span class="number">13</span>, <span class="number">13</span>)</span><br><span class="line">norm2   (<span class="number">50</span>, <span class="number">256</span>, <span class="number">13</span>, <span class="number">13</span>)</span><br><span class="line">conv3   (<span class="number">50</span>, <span class="number">384</span>, <span class="number">13</span>, <span class="number">13</span>)</span><br><span class="line">conv4   (<span class="number">50</span>, <span class="number">384</span>, <span class="number">13</span>, <span class="number">13</span>)</span><br><span class="line">conv5   (<span class="number">50</span>, <span class="number">256</span>, <span class="number">13</span>, <span class="number">13</span>)</span><br><span class="line">pool5   (<span class="number">50</span>, <span class="number">256</span>, <span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">fc6 (<span class="number">50</span>, <span class="number">4096</span>)</span><br><span class="line">fc7 (<span class="number">50</span>, <span class="number">4096</span>)</span><br><span class="line">fc8 (<span class="number">50</span>, <span class="number">1000</span>)</span><br><span class="line">prob    (<span class="number">50</span>, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="实例-查看params"><a href="#实例-查看params" class="headerlink" title="实例-查看params"></a>实例-查看params</h4><p>函数为<code>net.params</code>,其中weight的样子应该是<code>（output_channels,input_channels,filter_height,flier_width）</code>, biases的形状只有一维<code>output_channels,</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name,parame <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line"><span class="keyword">print</span> layer_name+<span class="string">'\t'</span>+str(param[<span class="number">0</span>].shape),str(param[<span class="number">1</span>].data.shape) <span class="comment">#可以看出param里0为weight，1为biase</span></span><br></pre></td></tr></table></figure></p>
<p>结果为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conv1   (<span class="number">96</span>, <span class="number">3</span>, <span class="number">11</span>, <span class="number">11</span>) (<span class="number">96</span>,)   <span class="comment">#输入3通道，输出96通道</span></span><br><span class="line">conv2   (<span class="number">256</span>, <span class="number">48</span>, <span class="number">5</span>, <span class="number">5</span>) (<span class="number">256</span>,)  <span class="comment">#输入为48，因为分成了两组，group=2</span></span><br><span class="line">conv3   (<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>) (<span class="number">384</span>,) <span class="comment">#这里的输入没变</span></span><br><span class="line">conv4   (<span class="number">384</span>, <span class="number">192</span>, <span class="number">3</span>, <span class="number">3</span>) (<span class="number">384</span>,)</span><br><span class="line">conv5   (<span class="number">256</span>, <span class="number">192</span>, <span class="number">3</span>, <span class="number">3</span>) (<span class="number">256</span>,)</span><br><span class="line">fc6 (<span class="number">4096</span>, <span class="number">9216</span>) (<span class="number">4096</span>,)        <span class="comment">#9216=256*3*3</span></span><br><span class="line">fc7 (<span class="number">4096</span>, <span class="number">4096</span>) (<span class="number">4096</span>,)</span><br><span class="line">fc8 (<span class="number">1000</span>, <span class="number">4096</span>) (<span class="number">1000</span>,)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-06-15-【shell】select files from different folders and put them into subfolders/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-06-15-【shell】select files from different folders and put them into subfolders/" itemprop="url">【shell】select files from different folders and put them into subfolders</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Today, there is an emergency to deal with. Two folders are given. The first includes pure images and the second includes images with notifications and label txt. Document structure is as following:</p>
<ul>
<li>A/classes/pure images;</li>
<li>B/classes/ <ul>
<li>sub_a:  images with notifications;</li>
<li>sub_b:  corresponding label txt.</li>
</ul>
</li>
</ul>
<p>The images in folder A and B have the same file name, and there only difference is that A’s are origin but B’s are notified with ground truth.</p>
<p>Now I have to pick out origin images from folder A and its corresponding labels txt from folder B. Then rename the classes as increasing indexes from 1 to 2, 3, … And build a new pic folder and txt folder to contain images and labels respectively.</p>
<p>At beginning, I want to use a ‘pysical method’ — manully conduct these steps one by one. But there are as many as 212 classes and in every class’ folder, it usually has many subfolders in depth. So I quickly give up this method and turn to the shell code.</p>
<p>These are key points in the process:</p>
<ol>
<li>create folders from 1 to 212</li>
<li>create sub folders <code>pic</code> and <code>txt</code> in every folder</li>
<li>go through deep direction and target specific files, .jpg or .txt</li>
<li>distinguish from .jpg to .txt</li>
<li>copy file from a new folder</li>
<li>traverse class folder along A and B parallelly</li>
</ol>
<p>There are specific important commands of shell:</p>
<ol>
<li>create folders from 1 to 212</li>
<li>create sub folders <code>pic</code> and <code>txt</code> in every folder</li>
</ol>
<p>code:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for k in $( seq 1 10 )</span><br><span class="line">do</span><br><span class="line">    mkdir /media/sun/Seagate_Casia/tank/new/$&#123;k&#125;</span><br><span class="line">    dire=/media/sun/Seagate_Casia/tank/new/$&#123;k&#125;</span><br><span class="line">    mkdir $dire/pic</span><br><span class="line">    mkdir $dire/txt       </span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li>go through deep direction and target specific files, .jpg or .txt</li>
</ol>
<p>code:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function copy_pic()&#123;</span><br><span class="line">for file in `ls $1`       #the signal of system command ``</span><br><span class="line">do</span><br><span class="line">    if [ -d $1"/"$file ]  #notice the blank in this command</span><br><span class="line">    then</span><br><span class="line">        copy_pic $1"/"$file $2 $3      #this is very important for the func with more params</span><br><span class="line">    else</span><br><span class="line">        echo $1"/"$file   #handle with files there</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ol start="4">
<li>distinguish from .jpg to .txt</li>
</ol>
<p>code:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if [ "$&#123;file##*.&#125;" = "jpg" ]</span><br><span class="line">    then</span><br><span class="line">	cp $1"/"$file $3 </span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<ol start="5">
<li>copy file from a new folder</li>
</ol>
<p>code:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp $1"/"$file $3</span><br></pre></td></tr></table></figure></p>
<ol start="6">
<li>traverse class folder along A and B parallelly: This is a trick combining  above modules. Whole code is on my github.</li>
</ol>
<h3 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h3><hr>
<p>Divide whatever the problem into several sub problems, you will find it’s not that hard and not that unsolvable.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-06-10-【caffe】从命令行到函数调用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-06-10-【caffe】从命令行到函数调用/" itemprop="url">【caffe】从命令行到函数调用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>写在前面：<br>经过几天的琢磨，caffe的使用流程已经基本掌握，但我始终对一些问题感到好奇，比如写的那些文本是如何形成网络的，在命令行输入的参数是怎么调用相应程序的，网路中每个层（module）的那些参数（或说属性）是怎么定义的？等等。这种好奇让我觉得很没谱，万一某一天caffe没有按照想法进行工作，或者在caffe主体的基础上自己有了一点不一样的想法，我该怎么去改？虽然这种情况出现时，我的水平可能已经很高了，但是现在始终在心里挥之不去。因此抽时间查找了一些相关材料，汇总如下。</p>
<p>在caffe.cpp的开头，可以看到很多宏，例如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DEFINE_string(gpu, <span class="string">""</span>,</span><br><span class="line">    <span class="string">"Optional; run in GPU mode on given device IDs separated by ','."</span></span><br><span class="line">    <span class="string">"Use '-gpu all' to run on all available GPUs. The effective training "</span></span><br><span class="line">    <span class="string">"batch size is multiplied by the number of devices."</span>);</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这个宏的使用方式为DEFINE_xxx(name, default_value, instruction);，这样就定义了一个xxx类型名为FLAGS_name的标志，如果用户没有在Command Line中提供其值，那么会默认为default_value，instruction是这个标志含义的说明。因此，上面的代码定义了一个string类型的名为FLAGS_gpu的标志，如果在Command Line中用户没有提供值，那么会默认为空字符串，根据说明可以得知这个标志是提供给用户来指定caffe将使用的GPU的。</p>
</blockquote>
<p>定义了很多标志，要有相应的代码对其进行解析。</p>
<blockquote>
<p>解析这些标志的代码在caffe.cpp中的main()中调用了/CAFFE_ROOT/src/common.cpp中的GlobalInit(&amp;argc, &amp;argv)函数。</p>
</blockquote>
<p>###从命令行写入参数，到具体的调用函数</p>
<p>在调用caffe网络时，我们在命令行写入如下参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">caffe train -solver=solver.prototxt -weights=pretrained-weights.caffemodel -gpu 0</span><br></pre></td></tr></table></figure></p>
<p><strong>第一个参数</strong>是train/test/time/device_query，表示要实现的功能。对该部分参数解析的实质是GetBrewFunction函数得到四个函数的指针。当然，这四个指针首先要通过RegisterBrewFunction这个宏完成函数的注册。两个函数的定义如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RegisterBrewFunction(func) \</span></span><br><span class="line"><span class="keyword">namespace</span> &#123; \</span><br><span class="line"><span class="class"><span class="keyword">class</span> __<span class="title">Registerer_</span>##<span class="title">func</span> &#123;</span> \</span><br><span class="line"> <span class="keyword">public</span>: <span class="comment">/* NOLINT */</span> \</span><br><span class="line">  __Registerer_#<span class="meta">#func() &#123; \</span></span><br><span class="line">    g_brew_map[<span class="meta">#func] = &amp;func; \</span></span><br><span class="line">  &#125; \</span><br><span class="line">&#125;; \</span><br><span class="line">__Registerer_#<span class="meta">#func g_registerer_##func; \</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> BrewFunction <span class="title">GetBrewFunction</span><span class="params">(<span class="keyword">const</span> caffe::<span class="built_in">string</span>&amp; name)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (g_brew_map.count(name)) &#123;</span><br><span class="line">    <span class="keyword">return</span> g_brew_map[name];</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    LOG(ERROR) &lt;&lt; <span class="string">"Available caffe actions:"</span>;</span><br><span class="line">    <span class="keyword">for</span> (BrewMap::iterator it = g_brew_map.begin();</span><br><span class="line">         it != g_brew_map.end(); ++it) &#123;</span><br><span class="line">      LOG(ERROR) &lt;&lt; <span class="string">"\t"</span> &lt;&lt; it-&gt;first;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Unknown action: "</span> &lt;&lt; name;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;  <span class="comment">// not reachable, just to suppress old compiler warnings.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>以train函数为例子，RegisterBrewFunction(train)这个宏的作用是定义了一个名为__Register_train的类，在定义完这个类之后，定义了一个这个类的变量，会调用构造函数，这个类的构造函数在前面提到的g_brew_map中添加了key为”train”，value为指向train函数的指针的一个元素。</p>
</blockquote>
<p>其中<code>g_brew_map</code>为一个全局变量：</p>
<pre><code>// A simple registry for caffe commands.
typedef int (*BrewFunction)();
typedef std::map&lt;caffe::string, BrewFunction&gt; BrewMap;
BrewMap g_brew_map;
</code></pre><p>main函数内容如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Print output to stderr (while still logging).</span></span><br><span class="line">  FLAGS_alsologtostderr = <span class="number">1</span>;</span><br><span class="line">  <span class="comment">// Set version</span></span><br><span class="line">  gflags::SetVersionString(AS_STRING(CAFFE_VERSION));</span><br><span class="line">  <span class="comment">// Usage message.</span></span><br><span class="line">  gflags::SetUsageMessage(<span class="string">"command line brew\n"</span></span><br><span class="line">      <span class="string">"usage: caffe &lt;command&gt; &lt;args&gt;\n\n"</span></span><br><span class="line">      <span class="string">"commands:\n"</span></span><br><span class="line">      <span class="string">"  train           train or finetune a model\n"</span></span><br><span class="line">      <span class="string">"  test            score a model\n"</span></span><br><span class="line">      <span class="string">"  device_query    show GPU diagnostic information\n"</span></span><br><span class="line">      <span class="string">"  time            benchmark model execution time"</span>);</span><br><span class="line">  <span class="comment">// Run tool or show usage.</span></span><br><span class="line">  caffe::GlobalInit(&amp;argc, &amp;argv);</span><br><span class="line">  <span class="keyword">if</span> (argc == <span class="number">2</span>) &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> WITH_PYTHON_LAYER</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">      <span class="keyword">return</span> GetBrewFunction(caffe::<span class="built_in">string</span>(argv[<span class="number">1</span>]))();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> WITH_PYTHON_LAYER</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (bp::error_already_set) &#123;</span><br><span class="line">      PyErr_Print();</span><br><span class="line">      <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    gflags::ShowUsageWithFlagsRestrict(argv[<span class="number">0</span>], <span class="string">"tools/caffe"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>总结：RegisterBrewFunction这个宏在每一个实现主要功能的函数之后将这个函数的名字和其对应的函数指针添加到了g_brew_map中，然后在main函数中，通过GetBrewFunction得到了我们需要调用的那个函数的函数指针，并完成了调用。</p>
</blockquote>
<p><strong>这样就实现了四个函数train/test/time/device_query的调用。</strong></p>
<hr>
<p>下面以train的内部结构为例看看后续的运行流程。</p>
<p>开头：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CHECK_GT(FLAGS_solver.size(), <span class="number">0</span>) &lt;&lt; <span class="string">"Need a solver definition to train."</span>;</span><br><span class="line">CHECK(!FLAGS_snapshot.size() || !FLAGS_weights.size())</span><br><span class="line">    &lt;&lt; <span class="string">"Give a snapshot to resume training or weights to finetune "</span></span><br><span class="line">    <span class="string">"but not both."</span>;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这段代码的第一行使用了glog的CHECK_GT宏（含义为check greater than），检查FLAGS_solver的size是否大于0，如果小于或等于0则输出提示：”Need a solver definition to train”。FLAGS_solver是最开始通过DEFINE_string定义的标志，如果我们希望训练一个模型，那么自然应该应该提供对应的solver定义文件的路径，这一句话正是在确保我们提供了这样的路径。这样的检查语句在后续的代码中会经常出现，将不再一一详细解释，如果有不清楚含义的glog宏可以去看看文档。 与第一行代码类似，第二行代码是确保用户没有同时提供snapshot和weights参数，这两个参数都是继续之前的训练或者进行fine-tuning的，如果同时指明了这两个标志，则不知道到底应该从哪个路径的文件去读入模型的相关参数更为合适。</p>
</blockquote>
<p>接下来是：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; stages = get_stages_from_flags();</span><br></pre></td></tr></table></figure></p>
<p>该函数的定义：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Parse stages from flags</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; get_stages_from_flags() &#123;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; stages;</span><br><span class="line">  boost::split(stages, FLAGS_stage, boost::is_any_of(<span class="string">","</span>));</span><br><span class="line">  <span class="keyword">return</span> stages;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>需要注意stage和phase不一样，但是具体的区别暂时不清楚，以后遇到就会知道。下面是phase的定义：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Parse phase from flags</span></span><br><span class="line">caffe::<span class="function">Phase <span class="title">get_phase_from_flags</span><span class="params">(caffe::Phase default_value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (FLAGS_phase == <span class="string">""</span>)</span><br><span class="line">    <span class="keyword">return</span> default_value;</span><br><span class="line">  <span class="keyword">if</span> (FLAGS_phase == <span class="string">"TRAIN"</span>)</span><br><span class="line">    <span class="keyword">return</span> caffe::TRAIN;</span><br><span class="line">  <span class="keyword">if</span> (FLAGS_phase == <span class="string">"TEST"</span>)</span><br><span class="line">    <span class="keyword">return</span> caffe::TEST;</span><br><span class="line">  LOG(FATAL) &lt;&lt; <span class="string">"phase must be \"TRAIN\" or \"TEST\""</span>;</span><br><span class="line">  <span class="keyword">return</span> caffe::TRAIN;  <span class="comment">// Avoid warning</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来是：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  caffe::SolverParameter solver_param;</span><br><span class="line">  caffe::ReadSolverParamsFromTextFileOrDie(FLAGS_solver, &amp;solver_param);</span><br><span class="line"></span><br><span class="line">即从solver.prototxt中获取相关的配置参数。看一下这个函数：</span><br><span class="line"></span><br><span class="line"><span class="comment">// Read parameters from a file into a SolverParameter proto message.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReadSolverParamsFromTextFileOrDie</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; param_file,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       SolverParameter* param)</span> </span>&#123;</span><br><span class="line">  CHECK(ReadProtoFromTextFile(param_file, param))</span><br><span class="line">      &lt;&lt; <span class="string">"Failed to parse SolverParameter file: "</span> &lt;&lt; param_file;</span><br><span class="line">  UpgradeSolverAsNeeded(param_file, param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中又调用了另一个函数<code>ReadProtoFromTextFile(param_file, param)</code>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">ReadProtoFromTextFile</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* filename, Message* proto)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> fd = open(filename, O_RDONLY);</span><br><span class="line">  CHECK_NE(fd, <span class="number">-1</span>) &lt;&lt; <span class="string">"File not found: "</span> &lt;&lt; filename;</span><br><span class="line">  FileInputStream* input = <span class="keyword">new</span> FileInputStream(fd);</span><br><span class="line">  <span class="keyword">bool</span> success = google::protobuf::TextFormat::Parse(input, proto);</span><br><span class="line">  <span class="keyword">delete</span> input;</span><br><span class="line">  close(fd);</span><br><span class="line">  <span class="keyword">return</span> success;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一路跟踪参数<code>param_file</code>可以发现，<code>FLAGS_solver</code>是prototxt的文件路径，而<code>solver_param</code>存放从其中解析到的配置参数信息，即这一系列函数的作用是从<code>param_file</code>这个路径去读取solver的定义。</p>
<p>要想了解<strong>solver一共包含哪些参数</strong>，分别表示什么，能够修改哪些信息？可以通过<code>message SolverParameter{xxx}</code>一探究竟，路径是<code>./src/caffe/proto/caffe.proto</code>. 此外，其背后的工作原理是</p>
<blockquote>
<p>caffe通过Google Protocol Buffer来定义data schema。</p>
</blockquote>
<p>可以通过<a href="http://alanse7en.github.io/caffedai-ma-jie-xi-2/" target="_blank" rel="noopener">这篇博客</a>了解一下。</p>
<p>回到train函数，后面基本都是对参数的一些解析，如设置gpu模式、遇到系统信号时（用户按了ctrl+c或者关闭了当前的terminal）的处理方式等。具体的细节，此处先不深入探讨，以后如有需要，再做补充。这里主要提出两个函数进行分析：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">solver-&gt;SetActionFunction(signal_handler.GetActionFunction());</span><br></pre></td></tr></table></figure>
<p>和<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">solver-&gt;Solve();</span><br></pre></td></tr></table></figure></p>
<p>其中涉及到以下四个方面：</p>
<blockquote>
<ul>
<li>Solver的初始化（Register宏和构造函数）</li>
<li>SIGINT和SIGHUP信号的处理</li>
<li>Solver::Solve()具体实现</li>
<li>SGDSolver::ApplyUpdate具体实现</li>
</ul>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shared_ptr</span>&lt;caffe::Solver&lt;<span class="keyword">float</span>&gt; &gt;</span><br><span class="line">    solver(caffe::SolverRegistry&lt;<span class="keyword">float</span>&gt;::CreateSolver(solver_param));</span><br></pre></td></tr></table></figure>
<p>该段代码定义一个指向Solver的shared_ptr。其中主要是通过调用SolverRegistry这个类的静态成员函数CreateSolver得到一个指向Solver的指针来构造shared_ptr类型的solver。</p>
<p>下面具体看一下SolverRegistry这个类的代码，以便理解“如何通过同一个函数得到不同类型的Solver”：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SolverRegistry</span> &#123;</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">typedef</span> Solver&lt;Dtype&gt;* (*Creator)(<span class="keyword">const</span> SolverParameter&amp;);</span><br><span class="line">  <span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="built_in">string</span>, Creator&gt; CreatorRegistry;</span><br><span class="line">  <span class="function"><span class="keyword">static</span> CreatorRegistry&amp; <span class="title">Registry</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> CreatorRegistry* g_registry_ = <span class="keyword">new</span> CreatorRegistry();</span><br><span class="line">    <span class="keyword">return</span> *g_registry_;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">AddCreator</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; type, Creator creator)</span> </span>&#123;</span><br><span class="line">    CreatorRegistry&amp; registry = Registry();</span><br><span class="line">    CHECK_EQ(registry.count(type), <span class="number">0</span>)</span><br><span class="line">        &lt;&lt; <span class="string">"Solver type "</span> &lt;&lt; type &lt;&lt; <span class="string">" already registered."</span>;</span><br><span class="line">    registry[type] = creator;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">static</span> Solver&lt;Dtype&gt;* CreateSolver(<span class="keyword">const</span> SolverParameter&amp; param) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; type = param.type();</span><br><span class="line">    CreatorRegistry&amp; registry = Registry();</span><br><span class="line">    CHECK_EQ(registry.count(type), <span class="number">1</span>) &lt;&lt; <span class="string">"Unknown solver type: "</span> &lt;&lt; type</span><br><span class="line">        &lt;&lt; <span class="string">" (known types: "</span> &lt;&lt; SolverTypeListString() &lt;&lt; <span class="string">")"</span>;</span><br><span class="line">    <span class="keyword">return</span> registry[type](param);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">static</span> <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; SolverTypeList() &#123;</span><br><span class="line">    CreatorRegistry&amp; registry = Registry();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; solver_types;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">typename</span> CreatorRegistry::iterator iter = registry.begin();</span><br><span class="line">         iter != registry.end(); ++iter) &#123;</span><br><span class="line">      solver_types.push_back(iter-&gt;first);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> solver_types;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  SolverRegistry() &#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="built_in">string</span> <span class="title">SolverTypeListString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; solver_types = SolverTypeList();</span><br><span class="line">    <span class="built_in">string</span> solver_types_str;</span><br><span class="line">    <span class="keyword">for</span> (<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;::iterator iter = solver_types.begin();</span><br><span class="line">         iter != solver_types.end(); ++iter) &#123;</span><br><span class="line">      <span class="keyword">if</span> (iter != solver_types.begin()) &#123;</span><br><span class="line">        solver_types_str += <span class="string">", "</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      solver_types_str += *iter;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> solver_types_str;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>从<code>CreateSolver</code>函数(第15行)入手，这个函数先定义了string类型的变量type，表示Solver的类型(SGD/Nestrov等)，然后定义了一个key类型为string，value类型为Creator的map：<code>registry</code>(4、5、6、17行)，其中Creator是一个函数指针类型，指向的函数的参数为<code>SolverParameter</code>类型，返回类型为<code>Solver*</code>(见第2行和第3行)。如果是一个已经register过的Solver类型，那么registry.count(type)应该为1，然后通过registry这个map返回了我们需要类型的Solver的creator，并调用这个creator函数，将creator返回的Solver*返回。</p>
<p>上面的代码中，Registry这个函数（第5行）中定义了一个static的变量g_registry，这个变量是一个指向CreatorRegistry这个map类型的指针，然后直接返回，因为这个变量是static的，所以即使多次调用这个函数，也只会定义一个g_registry，而且在其他地方修改这个map里的内容，是存储在这个map中的。事实上各个Solver的register的过程正是往g_registry指向的那个map里添加以Solver的type为key，对应的Creator函数指针为value的内容。</p>
<p>函数<code>static void AddCreator(const string&amp; type, Creator creator)</code>在添加creator的时候调用。下面具体来看一下Solver的register的过程：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SolverRegisterer</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  SolverRegisterer(<span class="keyword">const</span> <span class="built_in">string</span>&amp; type,</span><br><span class="line">      Solver&lt;Dtype&gt;* (*creator)(<span class="keyword">const</span> SolverParameter&amp;)) &#123;</span><br><span class="line">    <span class="comment">// LOG(INFO) &lt;&lt; "Registering solver type: " &lt;&lt; type;</span></span><br><span class="line">    SolverRegistry&lt;Dtype&gt;::AddCreator(type, creator);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_SOLVER_CREATOR(type, creator)                                 \</span></span><br><span class="line">  <span class="keyword">static</span> SolverRegisterer&lt;<span class="keyword">float</span>&gt; g_creator_f_#<span class="meta">#type(#type, creator<span class="meta-string">&lt;float&gt;);    \</span></span></span><br><span class="line">  <span class="keyword">static</span> SolverRegisterer&lt;<span class="keyword">double</span>&gt; g_creator_d_#<span class="meta">#type(#type, creator<span class="meta-string">&lt;double&gt;)   \</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_SOLVER_CLASS(type)                                            \</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;                                                    \</span><br><span class="line">  Solver&lt;Dtype&gt;* Creator_#<span class="meta">#type##Solver(                                       \</span></span><br><span class="line">      <span class="keyword">const</span> SolverParameter&amp; param)                                            \</span><br><span class="line">  &#123;                                                                            \</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> type##Solver&lt;Dtype&gt;(param);                                     \</span><br><span class="line">  &#125;                                                                            \</span><br><span class="line">  REGISTER_SOLVER_CREATOR(type, Creator_##type##Solver)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// register SGD Solver</span></span><br><span class="line">REGISTER_SOLVER_CLASS(SGD);</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>在sgd_solver.cpp(SGD Solver对应的cpp文件)末尾有上面第24行的代码，使用了REGISTER_SOLVER_CLASS这个宏，这个宏会定义一个名为Creator_SGDSolver的函数，这个函数即为Creator类型的指针指向的函数，在这个函数中调用了SGDSolver的构造函数，并将构造的这个变量得到的指针返回，这也就是Creator类型函数的作用：构造一个对应类型的Solver对象，将其指针返回。然后在这个宏里又调用了REGISTER_SOLVER_CREATOR这个宏，这里分别定义了SolverRegisterer这个模板类的float和double类型的static变量，这会去调用各自的构造函数，而在SolverRegisterer的构造函数中调用了之前提到的SolverRegistry类的AddCreator函数，这个函数就是将刚才定义的Creator_SGDSolver这个函数的指针存到g_registry指向的map里面。类似地，所有的Solver对应的cpp文件的末尾都调用了这个宏来完成注册，在所有的Solver都注册之后，我们就可以通过之前描述的方式，通过g_registry得到对应的Creator函数的指针，并通过调用这个Creator函数来构造对应的Solver。</p>
</blockquote>
<h3 id="SIGINT和SIGHUP信号的处理"><a href="#SIGINT和SIGHUP信号的处理" class="headerlink" title="SIGINT和SIGHUP信号的处理"></a>SIGINT和SIGHUP信号的处理</h3><p>Caffe在train或者test的过程中都有可能会遇到系统信号(用户按下ctrl+c或者关掉了控制的terminal)，我们可以通过对<code>sigint_effect</code>和<code>sighup_effect</code>来设置遇到系统信号的时候希望进行的处理方式：</p>
<pre><code>caffe train –solver=/path/to/solver.prototxt –sigint_effect=EFFECT –sighup_effect=EFFECT
</code></pre><p>先看一下train函数的相关调用：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">caffe::<span class="function">SignalHandler <span class="title">signal_handler</span><span class="params">(</span></span></span><br><span class="line">      GetRequestedAction(FLAGS_sigint_effect),</span><br><span class="line">      GetRequestedAction(FLAGS_sighup_effect));</span><br><span class="line">solver-&gt;SetActionFunction(signal_handler.GetActionFunction());</span><br></pre></td></tr></table></figure>
<p>函数<code>GetRequesedAction</code>在caffe.cpp中定义，作用是将设置的string类型的标志转变为枚举类型的变量：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">caffe::SolverAction::<span class="function">Enum <span class="title">GetRequestedAction</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; flag_value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (flag_value == <span class="string">"stop"</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> caffe::SolverAction::STOP;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (flag_value == <span class="string">"snapshot"</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> caffe::SolverAction::SNAPSHOT;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (flag_value == <span class="string">"none"</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> caffe::SolverAction::NONE;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG(FATAL) &lt;&lt; <span class="string">"Invalid signal effect \""</span>&lt;&lt; flag_value &lt;&lt; <span class="string">"\" was specified"</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// SolverAction::Enum的定义</span></span><br><span class="line"><span class="keyword">namespace</span> SolverAction &#123;</span><br><span class="line">  <span class="keyword">enum</span> Enum &#123;</span><br><span class="line">    NONE = <span class="number">0</span>,  <span class="comment">// Take no special action.</span></span><br><span class="line">    STOP = <span class="number">1</span>,  <span class="comment">// Stop training. snapshot_after_train controls whether a</span></span><br><span class="line">               <span class="comment">// snapshot is created.</span></span><br><span class="line">    SNAPSHOT = <span class="number">2</span>  <span class="comment">// Take a snapshot, and keep training.</span></span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中<code>SolverAction::Enum</code>的定义在solver.hpp中，这是一个定义为枚举类型的数据类型，只有三个可能的值，分别对应了三种处理系统信号的方式：</p>
<ol>
<li>NONE(忽略信号什么都不做)</li>
<li>STOP(停止训练)</li>
<li>SNAPSHOT(保存当前的训练状态，继续训练)</li>
</ol>
<p>再回到train函数中设置如何处理系统信号的代码，其中：<code>FLAGS_sigint_effect</code>和<code>FLAGS_sighup_effect</code>是通过gflags定义和解析的两个Command Line Interface的输入参数，分别对应遇到sigint和sighup信号的处理方式，如果用户不设定，sigint的默认值为<code>stop</code>，sighup的默认值为<code>snapshot</code>。<code>GetRequestedAction</code>函数会将string类型的<code>FLAGS_xx</code>转为<code>SolverAction::Enum</code>类型，并用来定义一个<code>SignalHandler</code>类型的对象<code>signal_handler</code>。可以看到这部分代码都依赖于SignalHandler这个类的接口，看一下相关代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// header file</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SignalHandler</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Contructor. Specify what action to take when a signal is received.</span></span><br><span class="line">  SignalHandler(SolverAction::Enum SIGINT_action,</span><br><span class="line">                SolverAction::Enum SIGHUP_action);</span><br><span class="line">  ~SignalHandler();</span><br><span class="line">  <span class="function">ActionCallback <span class="title">GetActionFunction</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  SolverAction::<span class="function">Enum <span class="title">CheckForSignals</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">  SolverAction::Enum SIGINT_action_;</span><br><span class="line">  SolverAction::Enum SIGHUP_action_;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// source file</span></span><br><span class="line">SignalHandler::SignalHandler(SolverAction::Enum SIGINT_action,</span><br><span class="line">                             SolverAction::Enum SIGHUP_action):</span><br><span class="line">  SIGINT_action_(SIGINT_action),</span><br><span class="line">  SIGHUP_action_(SIGHUP_action) &#123;</span><br><span class="line">  HookupHandler();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">HookupHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (already_hooked_up) &#123;</span><br><span class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Tried to hookup signal handlers more than once."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  already_hooked_up = <span class="literal">true</span>;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sigaction</span> <span class="title">sa</span>;</span></span><br><span class="line">  sa.sa_handler = &amp;handle_signal;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">sig_atomic_t</span> got_sigint = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">sig_atomic_t</span> got_sighup = <span class="literal">false</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handle_signal</span><span class="params">(<span class="keyword">int</span> signal)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span> (signal) &#123;</span><br><span class="line">  <span class="keyword">case</span> SIGHUP:</span><br><span class="line">    got_sighup = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> SIGINT:</span><br><span class="line">    got_sigint = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">ActionCallback SignalHandler::GetActionFunction() &#123;</span><br><span class="line">  <span class="keyword">return</span> boost::bind(&amp;SignalHandler::CheckForSignals, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line">SolverAction::Enum SignalHandler::CheckForSignals() <span class="keyword">const</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (GotSIGHUP()) &#123;</span><br><span class="line">    <span class="keyword">return</span> SIGHUP_action_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (GotSIGINT()) &#123;</span><br><span class="line">    <span class="keyword">return</span> SIGINT_action_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> SolverAction::NONE;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">GotSIGINT</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">bool</span> result = got_sigint;</span><br><span class="line">  got_sigint = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">GotSIGHUP</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">bool</span> result = got_sighup;</span><br><span class="line">  got_sighup = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ActionCallback的含义</span></span><br><span class="line"><span class="keyword">typedef</span> boost::function&lt;SolverAction::Enum()&gt; ActionCallback;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>SignalHandler这个类有两个数据成员，都是SolverAction::Enum类型的，分别对应sigint和sighup信号，在构造函数中，用解析FLAGS_xx得到的结果分别给两个成员赋值，然后调用了HookupHandler函数，这个函数的主要作用是定义了一个sigaction类型(应该是系统级别的代码)的对象sa，然后通过sa.sa_handler = &amp;handle_signal来设置，当有遇到系统信号时，调用handle_signal函数来处理，而我们可以看到这个函数的处理很简单，就是判断一下当前的信号是什么类型，如果是sigint就将全局的static变量got_sigint变为true，sighup的处理类似。</p>
</blockquote>
<blockquote>
<p>在根据用户设置（或者默认值）的参数定义了signal_handler之后，solver通过SetActionFunction来设置了如何处理系统信号。这个函数的输入为signal_handler的GetActionFunction的返回值，根据上面的代码我们可以看到，GetActionFunction会返回signal_handler这个对象的CheckForSignals函数的地址(boost::bind的具体使用请参考boost官方文档)。而在Solver的SetActionFunction函数中只是简单的把Solver的一个成员action_request_function_赋值为输入参数的值，以当前的例子来说就是，solver对象的action_request_function_指向了signal_handler对象的CheckForSignals函数的地址。其中的ActionCallback是一个函数指针类型，指向了参数为空，返回值为SolverAction::Enum类型的函数(boost::function具体用法参考官方文档)。</p>
</blockquote>
<blockquote>
<p>总结起来，我们通过定义一个SignalHandler类型的对象，告知系统在遇到系统信号的时候回调handle_signal函数来改变全局变量got_sigint和got_sighup的值，然后通过Solver的接口设置了其遇到系统函数将调用signal_handler的Check函数，这个函数实际上就是去判断当前是否遇到了系统信号，如果遇到某个类型的信号，就返回我们之前设置的处理方式(SolverAction::Enum类型)。剩余的具体处理再交给Solver的其它函数，后面会具体分析。</p>
</blockquote>
<h3 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h3><hr>
<p>caffe，虽然内核是C++，但是其封装非常好，对于使用者来说，只需要写一个文本文档，定义网络结构和相关参数，然后就可以直接运行。运行的环境涉及到C++、Python、MATLAB的语言。所以，在不同的编译环境下，把内核的接口进行相应地转换（编译），就可以运行。</p>
<h3 id="Main-Reference"><a href="#Main-Reference" class="headerlink" title="Main Reference"></a>Main Reference</h3><hr>
<p><a href="http://alanse7en.github.io/caffedai-ma-jie-xi-4/" target="_blank" rel="noopener">http://alanse7en.github.io/caffedai-ma-jie-xi-4/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-06-14-【caffe】Brewing ImageNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-06-14-【caffe】Brewing ImageNet/" itemprop="url">【caffe】Brewing ImageNet</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>This guide is meant to <strong>get you ready to train your own model on your own data</strong>. If you just want an ImageNet-trained network, then note that since training takes a lot of energy and we hate global warming, we provide the CaffeNet model trained as described below in the <a href="http://caffe.berkeleyvision.org/model_zoo.html" target="_blank" rel="noopener">model zoo</a>.</p>
<h3 id="Data-Preparation"><a href="#Data-Preparation" class="headerlink" title="Data Preparation"></a>Data Preparation</h3><hr>
<h5 id="The-guide-specifies-all-paths-and-assumes-all-commands-are-executed-from-the-root-caffe-directory"><a href="#The-guide-specifies-all-paths-and-assumes-all-commands-are-executed-from-the-root-caffe-directory" class="headerlink" title="The guide specifies all paths and assumes all commands are executed from the root caffe directory."></a><em>The guide specifies all paths and assumes all commands are executed from the root caffe directory.</em></h5><h5 id="By-“ImageNet”-we-here-mean-the-ILSVRC12-challenge-but-you-can-easily-train-on-the-whole-of-ImageNet-as-well-just-with-more-disk-space-and-a-little-longer-training-time"><a href="#By-“ImageNet”-we-here-mean-the-ILSVRC12-challenge-but-you-can-easily-train-on-the-whole-of-ImageNet-as-well-just-with-more-disk-space-and-a-little-longer-training-time" class="headerlink" title="By “ImageNet” we here mean the ILSVRC12 challenge, but you can easily train on the whole of ImageNet as well, just with more disk space, and a little longer training time."></a><em>By “ImageNet” we here mean the ILSVRC12 challenge, but you can easily train on the whole of ImageNet as well, just with more disk space, and a little longer training time.</em></h5><p>We assume that you already have downloaded the ImageNet training data and validation data, and they are stored on your disk like:</p>
<pre><code>/path/to/imagenet/train/n01440764/n01440764_10026.JPEG
/path/to/imagenet/val/ILSVRC2012_val_00000001.JPEG
</code></pre><p>You will first need to prepare some <strong>auxiliary data</strong> for training. This data can be downloaded by:</p>
<pre><code>./data/ilsvrc12/get_ilsvrc_aux.sh
</code></pre><p>The training and validation input are described in <code>train.txt</code> and <code>val.txt</code> as text listing all the files and their labels. Note that we use a different indexing for labels than the ILSVRC devkit: we sort the synset names in their ASCII order, and then label them from 0 to 999. See <code>synset_words.txt</code> for the synset/name mapping.</p>
<p>You may want to resize the images to 256x256 in advance. By default, we do not explicitly do this because in a cluster environment, one may benefit from resizing images in a parallel fashion, using mapreduce. For example, Yangqing used his lightweight mincepie package. If you prefer things to be simpler, you can also use shell commands, something like:</p>
<pre><code>for name in /path/to/imagenet/val/*.JPEG; do
    convert -resize 256x256\! $name $name
done
</code></pre><p>Take a look at <code>examples/imagenet/create_imagenet.sh</code>:</p>
<ul>
<li>Set the paths to the train and val dirs as needed;</li>
<li>et <code>RESIZE=true</code> to resize all images to 256x256 if you haven’t resized the images in advance. </li>
</ul>
<p>Now simply create the leveldbs with <code>examples/imagenet/create_imagenet.sh</code>. Note that <code>examples/imagenet/ilsvrc12_train_leveldb</code> and <code>examples/imagenet/ilsvrc12_val_leveldb</code> should not exist before this execution. It will be created by the script. <code>GLOG_logtostderr=1</code> simply dumps more information for you to inspect, and you can safely ignore it.</p>
<h3 id="Compute-Image-Mean"><a href="#Compute-Image-Mean" class="headerlink" title="Compute Image Mean"></a>Compute Image Mean</h3><hr>
<p>The model requires us to subtract the image mean from each image, so we have to compute the mean. <code>tools/compute_image_mean.cpp</code> implements that - it is also a good example to familiarize yourself on how to manipulate the multiple components, such as <strong>protocol buffers, leveldbs, and logging</strong>, if you are not familiar with them. Anyway, the mean computation can be carried out as:</p>
<pre><code>./examples/imagenet/make_imagenet_mean.sh
</code></pre><p>which will make <code>data/ilsvrc12/imagenet_mean.binaryproto</code>.</p>
<h3 id="Model-Definition"><a href="#Model-Definition" class="headerlink" title="Model Definition"></a>Model Definition</h3><hr>
<p>We are going to describe a reference implementation for the approach first proposed by Krizhevsky, Sutskever, and Hinton in their <a href="http://books.nips.cc/papers/files/nips25/NIPS2012_0534.pdf" target="_blank" rel="noopener">NIPS 2012 paper</a>.</p>
<p>The network definition <code>models/bvlc_reference_caffenet/train_val.prototxt</code> follows the one in Krizhevsky et al. Note that if you deviated from file paths suggested in this guide, you’ll need to adjust the relevant paths in the <code>.prototxt files</code>.</p>
<p>If you look carefully at <code>models/bvlc_reference_caffenet/train_val.prototxt</code>, you will notice several <code>include sections</code> specifying either phase: TRAIN or phase: TEST. These sections allow us to <strong>define two closely related networks in one file:</strong> the network used for training and the network used for testing. These two networks are almost identical, sharing all layers except for those marked with <code>include { phase: TRAIN }</code> or <code>include { phase: TEST }</code>. <u>In this case, only the input layers and one output layer are different.</u></p>
<p><strong>Input layer differences:</strong> The training network’s data input layer draws its data from <code>examples/imagenet/ilsvrc12_train_leveldb</code> and randomly mirrors the input image. The testing network’s data layer takes data from <code>examples/imagenet/ilsvrc12_val_leveldb</code> and does not perform random mirroring.</p>
<p><strong>Output layer differences:</strong> Both networks output the <code>softmax_loss layer</code>, which <u>in training is used to compute the loss function and to initialize the backpropagation</u>, while in <u>validation this loss is simply reported</u>. The testing network also has a second output layer, <code>accuracy</code>, which is used to <u>report the accuracy on the test set</u>. <em>In the process of training, the test network will occasionally be instantiated and tested on the test set, producing lines like</em> <code>Test score #0: xxx and Test score #1: xxx.</code> In this case <strong>score 0</strong> is the accuracy (which will start around 1/1000 = 0.001 for an untrained network) and <strong>score 1</strong> is the loss (which will start around 7 for an untrained network).</p>
<p>We will also lay out a protocol buffer for running the solver. Let’s make a few plans:</p>
<ul>
<li>We will run in batches of 256, and run a total of 450,000 iterations (about 90 epochs).</li>
<li>For every 1,000 iterations, we test the learned net on the validation data.</li>
<li>We set the initial learning rate to 0.01, and decrease it every 100,000 iterations (about 20 epochs).</li>
<li>Information will be displayed every 20 iterations.</li>
<li>The network will be trained with momentum 0.9 and a weight decay of 0.0005.</li>
<li>For every 10,000 iterations, we will take a snapshot of the current status.</li>
</ul>
<p>Sound good? This is implemented in <code>models/bvlc_reference_caffenet/solver.prototxt</code>.</p>
<h3 id="Training-ImageNet"><a href="#Training-ImageNet" class="headerlink" title="Training ImageNet"></a>Training ImageNet</h3><hr>
<p>Ready? Let’s train.</p>
<pre><code>./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt
</code></pre><p>Sit back and enjoy!</p>
<p>On a K40 machine, every 20 iterations take about 26.5 seconds to run (while a on a K20 this takes 36 seconds), so effectively about 5.2 ms per image for the full forward-backward pass. About 2 ms of this is on forward, and the rest is backward. If you are interested in dissecting the computation time, you can run</p>
<pre><code>./build/tools/caffe time --model=models/bvlc_reference_caffenet/train_val.prototxt
</code></pre><h3 id="Resume-Training"><a href="#Resume-Training" class="headerlink" title="Resume Training?"></a>Resume Training?</h3><hr>
<p>We all experience times when the <u>power goes out</u>, or we feel like rewarding ourself a little by playing Battlefield (does anyone still remember Quake?). Since we are snapshotting intermediate results during training, we will be able to resume from snapshots. This can be done as easy as:</p>
<pre><code>./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt --snapshot=models/bvlc_reference_caffenet/caffenet_train_iter_10000.solverstate
</code></pre><p>where in the script <code>caffenet_train_iter_10000.solverstate</code> is the solver state snapshot that stores all necessary information to recover the exact solver state (including the parameters, <em>momentum history</em>, etc).</p>
<h3 id="Parting-Words"><a href="#Parting-Words" class="headerlink" title="Parting Words"></a>Parting Words</h3><hr>
<p>Hope you liked this recipe! Many researchers have gone further since the ILSVRC 2012 challenge, changing the network architecture and/or fine-tuning the various parameters in the network to address new data and tasks. <strong>Caffe lets you explore different network choices more easily by simply writing different prototxt files</strong> - isn’t that exciting?</p>
<p>And since now you have a trained network, check out how to use it with the Python interface for <a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb" target="_blank" rel="noopener">classifying ImageNet</a>.</p>
<h3 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h3><hr>
<p>the loss and accuracy are computed by particular layer, which is correlated to prefessional code. Generally the kind of accuracy you want to calculate is included in caffe’s inherent layer. If you want to compute come special accuracy, you can create your own kind layer and register them in caffe.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/06/2018-06-06-【caffe】interface/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/2018-06-06-【caffe】interface/" itemprop="url">【caffe】interface</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:16:33+08:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Caffe has command line, Python, and MATLAB interfaces for day-to-day usage, interfacing with research code, and rapid prototyping. While Caffe is a C++ library at heart and it exposes a modular interface for development, not every occasion calls for custom compilation. The <strong>cmdcaffe, pycaffe, and matcaffe interfaces</strong> are here for you. <em>虽然Caffe是一个C ++库，并且它提供了一个用于开发的模块化接口，但并非每次都需要自定义编译。</em></p>
<h3 id="Command-Line"><a href="#Command-Line" class="headerlink" title="Command Line"></a>Command Line</h3><hr>
<p>The command line interface – cmdcaffe – is the caffe tool for model training, scoring, and diagnostics. Run caffe without any arguments for help. This tool and others are found in caffe/build/tools. (The following example calls require completing the LeNet / MNIST example first.)</p>
<p><strong>Training:</strong> <code>caffe train</code> learns models from scratch, resumes learning from saved snapshots, and fine-tunes models to new data and tasks:</p>
<ul>
<li><p>All training requires a solver configuration through the -solver solver.prototxt argument.</p>
</li>
<li><p>Resuming requires the -snapshot model_iter_1000.solverstate argument to load the solver snapshot.</p>
</li>
<li><p>Fine-tuning requires the -weights model.caffemodel argument for the model initialization.</p>
</li>
</ul>
<p>For example, you can run:</p>
<pre><code># train LeNet
caffe train -solver examples/mnist/lenet_solver.prototxt
# train on GPU 2
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 2
# resume training from the half-way point snapshot
caffe train -solver examples/mnist/lenet_solver.prototxt -snapshot examples/mnist/lenet_iter_5000.solverstate
</code></pre><p>For a full example of fine-tuning, see examples/finetuning_on_flickr_style, but the training call alone is</p>
<pre><code># fine-tune CaffeNet model weights for style recognition
caffe train -solver examples/finetuning_on_flickr_style/solver.prototxt -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
</code></pre><p><strong>Testing:</strong> <code>caffe test</code> scores models by running them in the test phase and reports the net output as its score. The net architecture must be properly defined to output an accuracy measure or loss as its output. The per-batch score is reported and then the grand average is reported last.</p>
<pre><code># score the learned LeNet model on the validation set as defined in the
# model architeture lenet_train_test.prototxt
caffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 100
</code></pre><p><strong>Benchmarking:</strong> <code>caffe time</code> benchmarks model execution layer-by-layer through timing and synchronization. This is useful to check system performance and measure relative execution times for models.</p>
<pre><code># (These example calls require you complete the LeNet / MNIST example first.)
# time LeNet training on CPU for 10 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10
# time LeNet training on GPU for the default 50 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0
# time a model architecture with the given weights on the first GPU for 10 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 10
</code></pre><p><strong>Diagnostics:</strong> <code>caffe device_query</code> reports GPU details for reference and checking device ordinals for running on a given device in multi-GPU machines.</p>
<pre><code># query the first device
caffe device_query -gpu 0
</code></pre><p><strong>Parallelism:</strong> the -gpu flag to the caffe tool can take a comma separated list of IDs to run on multiple GPUs. A solver and net will be instantiated for each GPU so the batch size is effectively multiplied by the number of GPUs. To reproduce single GPU training, reduce the batch size in the network definition accordingly.</p>
<pre><code># train on GPUs 0 &amp; 1 (doubling the batch size)
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 0,1
# train on all GPUs (multiplying batch size by number of devices)
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all
</code></pre><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><hr>
<p>The Python interface – pycaffe – is the caffe module and its scripts in caffe/python. <code>import caffe</code> to load models, do forward and backward, handle IO, visualize networks, and even instrument model solving. All model data, derivatives, and parameters are exposed for reading and writing.</p>
<ul>
<li>caffe.Net is the central interface for loading, configuring, and running models. </li>
<li>caffe.Classifier and caffe.Detector provide convenience interfaces for common tasks.</li>
<li>caffe.SGDSolver exposes the solving interface.</li>
<li>caffe.io handles input / output with preprocessing and protocol buffers.</li>
<li>caffe.draw visualizes network architectures.</li>
<li>Caffe blobs are exposed as numpy ndarrays for ease-of-use and efficiency.</li>
</ul>
<p>Tutorial IPython notebooks are found in caffe/examples: do ipython notebook <code>caffe/examples</code> to try them. For developer reference docstrings can be found throughout the code.</p>
<p>Compile pycaffe by make pycaffe. Add the module directory to your <code>$PYTHONPATH</code> by export <code>PYTHONPATH=/path/to/caffe/python:$PYTHONPATH</code> or the like for import caffe.</p>
<h3 id="MATLAB"><a href="#MATLAB" class="headerlink" title="MATLAB"></a>MATLAB</h3><hr>
<p>The MATLAB interface <strong>matcaffe</strong> is the caffe package in caffe/matlab in which you can integrate Caffe in your Matlab code.</p>
<p>In MatCaffe, you can</p>
<ul>
<li>Creating multiple Nets in Matlab</li>
<li>Do forward and backward computation</li>
<li>Access any layer within a network, and any parameter blob in a layer</li>
<li>Get and set data or diff to any blob within a network, not restricting to input blobs or output blobs</li>
<li>Save a network’s parameters to file, and load parameters from file</li>
<li>Reshape a blob and reshape a network</li>
<li>Edit network parameter and do network surgery</li>
<li>Create multiple Solvers in Matlab for training</li>
<li>Resume training from solver snapshots</li>
<li>Access train net and test nets in a solver</li>
<li>Run for a certain number of iterations and give back control to Matlab</li>
<li>Intermingle arbitrary Matlab code with gradient steps</li>
</ul>
<p>An ILSVRC image classification demo is in caffe/matlab/demo/classification_demo.m (you need to download BAIR CaffeNet from <a href="http://caffe.berkeleyvision.org/model_zoo.html" target="_blank" rel="noopener">Model Zoo</a> to run it).</p>
<h4 id="Build-MatCaffe"><a href="#Build-MatCaffe" class="headerlink" title="Build MatCaffe"></a>Build MatCaffe</h4><hr>
<p>Build MatCaffe with <code>make all matcaffe</code>. After that, you may test it using <code>make mattest</code>.</p>
<p>Common issue: if you run into error messages like libstdc++.so.6:version ‘GLIBCXX_3.4.15’ not found during make mattest, then it usually means that your Matlab’s runtime libraries do not match your compile-time libraries. You may need to do the following before you start Matlab:</p>
<pre><code>export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64
export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
</code></pre><p>Or the equivalent based on where things are installed on your system, and do <code>make mattest</code> again to see if the issue is fixed. </p>
<p>Note: this issue is sometimes more complicated since during its startup Matlab may overwrite your <code>LD_LIBRARY_PATH</code> environment variable. You can run <code>!ldd ./matlab/+caffe/private/caffe_.mexa64</code> (the mex extension may differ on your system) in Matlab to see its runtime libraries, and preload your compile-time libraries by exporting them to your <code>LD_PRELOAD</code> environment variable.</p>
<p>After successful building and testing, <u>add this package to Matlab search PATH by starting matlab from caffe root folder</u> and running the following commands in Matlab command window.</p>
<pre><code>addpath ./matlab
</code></pre><p>You can save your Matlab search PATH by running <code>savepath</code> so that you don’t have to run the command above again every time you use MatCaffe.</p>
<h4 id="Use-MatCaffe"><a href="#Use-MatCaffe" class="headerlink" title="Use MatCaffe"></a>Use MatCaffe</h4><hr>
<p>MatCaffe is very similar to PyCaffe in usage.</p>
<p>Examples below shows detailed usages and assumes you have downloaded BAIR CaffeNet from <a href="http://caffe.berkeleyvision.org/model_zoo.html" target="_blank" rel="noopener">Model Zoo</a> and started matlab from caffe root folder.</p>
<pre><code>model = &apos;./models/bvlc_reference_caffenet/deploy.prototxt&apos;;
weights = &apos;./models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&apos;;
</code></pre><h5 id="Set-mode-and-device"><a href="#Set-mode-and-device" class="headerlink" title="Set mode and device"></a>Set mode and device</h5><p>Mode and device should always be set BEFORE you create a net or a solver.</p>
<p>Use CPU:</p>
<pre><code>caffe.set_mode_cpu();
</code></pre><p>Use GPU and specify its gpu_id:</p>
<pre><code>caffe.set_mode_gpu();
caffe.set_device(gpu_id);
</code></pre><h5 id="Create-a-network-and-access-its-layers-and-blobs"><a href="#Create-a-network-and-access-its-layers-and-blobs" class="headerlink" title="Create a network and access its layers and blobs"></a>Create a network and access its layers and blobs</h5><p>Create a network:</p>
<pre><code>net = caffe.Net(model, weights, &apos;test&apos;); % create net and load weights
</code></pre><p>Or</p>
<pre><code>net = caffe.Net(model, &apos;test&apos;); % create net but not load weights
net.copy_from(weights); % load weights
</code></pre><p>which creates net object as</p>
<pre><code>Net with properties:

         layer_vec: [1x23 caffe.Layer]
          blob_vec: [1x15 caffe.Blob]
            inputs: {&apos;data&apos;}
           outputs: {&apos;prob&apos;}
  name2layer_index: [23x1 containers.Map]
   name2blob_index: [15x1 containers.Map]
       layer_names: {23x1 cell}
        blob_names: {15x1 cell}
</code></pre><p>The two containers.Map objects are useful to find <u>the index of a layer or a blob by its name</u>.</p>
<p>You have access to every blob in this network. To fill blob ‘data’ with all ones:</p>
<pre><code>net.blobs(&apos;data&apos;).set_data(ones(net.blobs(&apos;data&apos;).shape));
</code></pre><p>To multiply all values in blob ‘data’ by 10:</p>
<pre><code>net.blobs(&apos;data&apos;).set_data(net.blobs(&apos;data&apos;).get_data() * 10);
</code></pre><p><strong>Be aware that since Matlab is 1-indexed and column-major, the usual 4 blob dimensions in Matlab are [width, height, channels, num], and width is the fastest dimension. Also be aware that images are in BGR channels.</strong> Also, Caffe uses single-precision float data. If your data is not single, <code>set_data</code> will automatically convert it to single.</p>
<p>You also have access to every layer, so you can do network surgery. For example, to multiply conv1 parameters by 10:</p>
<pre><code>net.params(&apos;conv1&apos;, 1).set_data(net.params(&apos;conv1&apos;, 1).get_data() * 10); % set weights
net.params(&apos;conv1&apos;, 2).set_data(net.params(&apos;conv1&apos;, 2).get_data() * 10); % set bias
</code></pre><p>Alternatively, you can use</p>
<pre><code>net.layers(&apos;conv1&apos;).params(1).set_data(net.layers(&apos;conv1&apos;).params(1).get_data() * 10);
net.layers(&apos;conv1&apos;).params(2).set_data(net.layers(&apos;conv1&apos;).params(2).get_data() * 10);
</code></pre><p>To save the network you just modified:</p>
<pre><code>net.save(&apos;my_net.caffemodel&apos;);
</code></pre><p>To get a layer’s type (string):</p>
<pre><code>layer_type = net.layers(&apos;conv1&apos;).type;
</code></pre><h5 id="Forward-and-backward"><a href="#Forward-and-backward" class="headerlink" title="Forward and backward"></a>Forward and backward</h5><p>Forward pass can be done using <code>net.forward</code> or <code>net.forward_prefilled</code>. Function <code>net.forward</code> takes in a cell array of N-D arrays containing data of input blob(s) and outputs a cell array containing data from output blob(s). Function <code>net.forward_prefilled</code> uses existing data in input blob(s) during forward pass, takes no input and produces no output. After creating some data for input blobs like <code>data = rand(net.blobs(&#39;data&#39;).shape);</code> you can run</p>
<pre><code>res = net.forward({data});
prob = res{1};
</code></pre><p>Or</p>
<pre><code>net.blobs(&apos;data&apos;).set_data(data);
net.forward_prefilled();
prob = net.blobs(&apos;prob&apos;).get_data();
</code></pre><p>Backward is similar using <code>net.backward</code> or <code>net.backward_prefilled</code> and replacing <code>get_data</code> and <code>set_data</code> with <code>get_diff</code> and <code>set_diff</code>. After creating some gradients for output blobs like <code>prob_diff = rand(net.blobs(&#39;prob&#39;).shape);</code> you can run</p>
<pre><code>res = net.backward({prob_diff});
data_diff = res{1};
</code></pre><p>Or</p>
<pre><code>net.blobs(&apos;prob&apos;).set_diff(prob_diff);
net.backward_prefilled();
data_diff = net.blobs(&apos;data&apos;).get_diff();
</code></pre><p><strong>However, the backward computation above doesn’t get correct results, because Caffe decides that the network does not need backward computation. To get correct backward results, you need to set ‘force_backward: true’ in your network prototxt.</strong></p>
<p>After performing forward or backward pass, you can also <u>get the <strong>data or diff</strong></u> in internal blobs. For example, to extract pool5 features after forward pass:</p>
<pre><code>pool5_feat = net.blobs(&apos;pool5&apos;).get_data();
</code></pre><p>Reshape</p>
<p>Assume you want to run 1 image at a time instead of 10:</p>
<pre><code>net.blobs(&apos;data&apos;).reshape([227 227 3 1]); % reshape blob &apos;data&apos;
net.reshape();
</code></pre><p>Then the whole network is reshaped (the second command?), and now net.blobs(‘prob’).shape should be [1000 1];</p>
<h5 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h5><p>Assume you have created training and validation lmdbs following our ImageNET Tutorial, to create a solver and train on ILSVRC 2012 classification dataset:</p>
<pre><code>solver = caffe.Solver(&apos;./models/bvlc_reference_caffenet/solver.prototxt&apos;);
</code></pre><p>which creates solver object as</p>
<pre><code>Solver with properties:

        net: [1x1 caffe.Net]
  test_nets: [1x1 caffe.Net]
</code></pre><p>To train:</p>
<pre><code>solver.solve();
</code></pre><p>Or train for only 1000 iterations (so that you can do something to its net before training more iterations)</p>
<pre><code>solver.step(1000);
</code></pre><p>To get iteration number:</p>
<pre><code>iter = solver.iter();
</code></pre><p>To get its network:</p>
<pre><code>train_net = solver.net;
test_net = solver.test_nets(1);
</code></pre><p>To resume from a snapshot  your_snapshot.solverstate:</p>
<pre><code>solver.restore(&apos;your_snapshot.solverstate&apos;);
</code></pre><h5 id="Input-and-output"><a href="#Input-and-output" class="headerlink" title="Input and output"></a>Input and output</h5><p>caffe.io class provides basic input functions <code>load_image</code> and <code>read_mean</code>. For example, to read ILSVRC 2012 mean file (assume you have downloaded imagenet example auxiliary files by running <code>./data/ilsvrc12/get_ilsvrc_aux.sh</code>):</p>
<pre><code>mean_data = caffe.io.read_mean(&apos;./data/ilsvrc12/imagenet_mean.binaryproto&apos;);
</code></pre><p>To read Caffe’s example image and resize to [width, height] and suppose we want width = 256; height = 256;</p>
<pre><code>im_data = caffe.io.load_image(&apos;./examples/images/cat.jpg&apos;);
im_data = imresize(im_data, [width, height]); % resize using Matlab&apos;s imresize
</code></pre><p><strong>Keep in mind that width is the fastest dimension and channels are BGR, which is different from the usual way that Matlab stores an image.</strong> If you don’t want to use <code>caffe.io.load_image</code> and prefer to load an image by yourself, you can do</p>
<pre><code>im_data = imread(&apos;./examples/images/cat.jpg&apos;); % read image
im_data = im_data(:, :, [3, 2, 1]); % convert from RGB to BGR
im_data = permute(im_data, [2, 1, 3]); % permute width and height
im_data = single(im_data); % convert to single precision
</code></pre><p>Also, you may take a look at <code>caffe/matlab/demo/classification_demo.m</code> to see how to prepare input by taking crops from an image.</p>
<p>We show in <code>caffe/matlab/hdf5creation</code> how to read and write HDF5 data with Matlab. We do not provide extra functions for data output as Matlab itself is already quite powerful in output.</p>
<h5 id="Clear-nets-and-solvers"><a href="#Clear-nets-and-solvers" class="headerlink" title="Clear nets and solvers"></a>Clear nets and solvers</h5><p>Call <code>caffe.reset_all()</code> to clear all solvers and stand-alone nets you have created.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><hr>
<p><a href="http://caffe.berkeleyvision.org/tutorial/interfaces.html" target="_blank" rel="noopener">http://caffe.berkeleyvision.org/tutorial/interfaces.html</a></p>
<h3 id="caffe学习与当前的任务"><a href="#caffe学习与当前的任务" class="headerlink" title="caffe学习与当前的任务"></a>caffe学习与当前的任务</h3><hr>
<p>caffe本质上仍是C++，只不过提供了很多借口，使得在不同环境下可以运行（训练和测试），</p>
<p>什么才是不同的语言呢？主要还是看网络的实现方式，如果用python编写，例如用到很多nn的函数；caffe的网络虽然在prototxt中定义，看起来像一个纯文本，但是他是要送到后方经过C++处理的。</p>
<p>对于目前的任务，我想，一个是自己fine-tuning数据公司提供的数据，看看质量如何；另一个就是等到数据发布后，选手们会提交自己的框架、算法、代码，到时候会对他们进行测试，即调用网络并计算出一定的指标。除此之外，说的稍微远一点，detection和segmentation也要看一些，到时候万一用得着呢？反正以后一定会用得着。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
