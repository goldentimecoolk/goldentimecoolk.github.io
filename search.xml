<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【pytorh】optimizer and lr_scheduler]]></title>
    <url>%2F2018%2F08%2F12%2F%E3%80%90pytorh%E3%80%91optimizer-and-lr-scheduler%2F</url>
    <content type="text"><![CDATA[This pair of conception, optimizer and lr_scheduler, has been confusing me when the first time I learned the official example code. So I write this blog to distinguish them. Let’s see official statement about torch.optim.lr_scheduler: torch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs. about step()【as a method of class torch.optim.Optimizer(params, defaults)】: Performs a single optimization step (parameter update). In generally, optimizer represents a kind of optimization algorithm. Most commonly used methods are already supported, including SGD, Momentum, RMSprop, Adam, etc. lr_scheduleris just used to schedule learning rate in certain method. And learning rate is widely used in optimization algorithms. So at every step, we need to use lr_scheduler to update learning rate, then set the updated learning rate as an parameter of optimizer. After calling loss.backward(), we can use optimizer.step() to update network’s parameters. This is about all “update operations” in one integral epoch. Additionally, there are some high quality instructions helping to select optimizer. https://ptorch.com/news/54.htmlhttps://ptorch.com/docs/4/pytorch-video-optimizerhttps://blog.csdn.net/blue_jjw/article/details/50650248 reference https://pytorch.org/docs/stable/optim.html#algorithmshttps://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-ratehttps://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】数据预处理torchvision.transforms]]></title>
    <url>%2F2018%2F08%2F12%2F%E3%80%90pytorch%E3%80%91%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86torchvision-transforms%2F</url>
    <content type="text"><![CDATA[在使用网络训练数据之前，需要对数据进行预处理，这几乎不可避免，（关于与处理的作用可以查看这篇博客）因此写文章总结torch中数据预处理的方式，并重点介绍几种预处理的方式。 在源码的开头，有如下一段代码： 1__all__ = ["Compose", "ToTensor", "ToPILImage", "Normalize", "Resize", "Scale", "CenterCrop", "Pad", "Lambda", "RandomApply", "RandomChoice", "RandomOrder", "RandomCrop", "RandomHorizontalFlip", "RandomVerticalFlip", "RandomResizedCrop", "RandomSizedCrop", "FiveCrop", "TenCrop", "LinearTransformation", "ColorJitter", "RandomRotation", "RandomAffine", "Grayscale", "RandomGrayscale"] 关于__all__，可以参考这些博客：1，2，3. 首先介绍一种粘合剂，将所有的变换按照给定顺序粘合起来： 1234567891011121314151617181920212223242526class Compose(object): """Composes several transforms together. Args: transforms (list of ``Transform`` objects): list of transforms to compose. Example: &gt;&gt;&gt; transforms.Compose([ &gt;&gt;&gt; transforms.CenterCrop(10), &gt;&gt;&gt; transforms.ToTensor(), &gt;&gt;&gt; ]) """ def __init__(self, transforms): self.transforms = transforms def __call__(self, img): for t in self.transforms: img = t(img) return img def __repr__(self): format_string = self.__class__.__name__ + '(' for t in self.transforms: format_string += '\n' format_string += ' &#123;0&#125;'.format(t) format_string += '\n)' return format_string 可以看到所有的Transform构成一个list，Compose(object)是将所有的变换按照这个列表的顺序兑现。在上述繁杂的变换中，变换ToTensor(object)的作作用是转换数据类型，他可以当做是变换的分水岭，因为有一部分变换的操作对象是torch.*Tensor，另一部分变化的操作对象是PIL Image。下面看一下该变换： 1234567891011121314151617class ToTensor(object): """Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]. """ def __call__(self, pic): """ Args: pic (PIL Image or numpy.ndarray): Image to be converted to tensor. Returns: Tensor: Converted image. """ return F.to_tensor(pic) def __repr__(self): return self.__class__.__name__ + '()' 转换ToTensor()实现了两个功能： 将图像的像素范围由[0,255]映射为[0,1]； 将像素的组织顺序由numpy.ndarray的(H x W x C)或PIL格式的图像转换为 (C x H x W)。 对应地有另一种转换ToPILImage： 12345678910111213141516171819202122232425262728293031class ToPILImage(object): """Convert a tensor or an ndarray to PIL Image. Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape H x W x C to a PIL Image while preserving the value range. Args: mode (`PIL.Image mode`_): color space and pixel depth of input data (optional). If ``mode`` is ``None`` (default) there are some assumptions made about the input data: 1. If the input has 3 channels, the ``mode`` is assumed to be ``RGB``. 2. If the input has 4 channels, the ``mode`` is assumed to be ``RGBA``. 3. If the input has 1 channel, the ``mode`` is determined by the data type (i,e, ``int``, ``float``, ``short``). .. _PIL.Image mode: https://pillow.readthedocs.io/en/latest/handbook/concepts.html#concept-modes """ def __init__(self, mode=None): self.mode = mode def __call__(self, pic): """ Args: pic (Tensor or numpy.ndarray): Image to be converted to PIL Image. Returns: PIL Image: Image converted to PIL Image. """ return F.to_pil_image(pic, self.mode) def __repr__(self): format_string = self.__class__.__name__ + '(' if self.mode is not None: format_string += 'mode=&#123;0&#125;'.format(self.mode) format_string += ')' return format_string 关于归一化： 123456789101112131415161718192021222324252627class Normalize(object): """Normalize a tensor image with mean and standard deviation. Given mean: ``(M1,...,Mn)`` and std: ``(S1,..,Sn)`` for ``n`` channels, this transform will normalize each channel of the input ``torch.*Tensor`` i.e. ``input[channel] = (input[channel] - mean[channel]) / std[channel]`` .. note:: This transform acts in-place, i.e., it mutates the input tensor. Args: mean (sequence): Sequence of means for each channel. std (sequence): Sequence of standard deviations for each channel. """ def __init__(self, mean, std): self.mean = mean self.std = std def __call__(self, tensor): """ Args: tensor (Tensor): Tensor image of size (C, H, W) to be normalized. Returns: Tensor: Normalized Tensor image. """ return F.normalize(tensor, self.mean, self.std) def __repr__(self): return self.__class__.__name__ + '(mean=&#123;0&#125;, std=&#123;1&#125;)'.format(self.mean, self.std) 可以看出需要先通过ToTensor()进行规范，然后才能通过Normalize()实现归一化。【主要是调整顺序】 看一下class Resize(object):的说明： 12345678910"""Resize the input PIL Image to the given size. Args: size (sequence or int): Desired output size. If size is a sequence like (h, w), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size) interpolation (int, optional): Desired interpolation. Default is PIL.Image.BILINEAR""" 该变换用于调整图像的尺寸，调整对象为PIL Image。所以需要在变换ToTensor()之前。 接下来有个类似的变换class Scale(Resize)，文档中的说法是： Note: This transform is deprecated in favor of Resize. 然后是裁剪： 12345678910111213141516171819202122232425class CenterCrop(object): """Crops the given PIL Image at the center. Args: size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. """ def __init__(self, size): if isinstance(size, numbers.Number): self.size = (int(size), int(size)) else: self.size = size def __call__(self, img): """ Args: img (PIL Image): Image to be cropped. Returns: PIL Image: Cropped image. """ return F.center_crop(img, self.size) def __repr__(self): return self.__class__.__name__ + '(size=&#123;0&#125;)'.format(self.size) 变换CenterCrop(object)是从中心位置裁剪，对象为PIL Image。还有一个类似的变换RandomCrop(object)，实现从任意位置的裁剪： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class RandomCrop(object): """Crop the given PIL Image at a random location. Args: size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. padding (int or sequence, optional): Optional padding on each border of the image. Default is None, i.e no padding. If a sequence of length 4 is provided, it is used to pad left, top, right, bottom borders respectively. If a sequence of length 2 is provided, it is used to pad left/right, top/bottom borders, respectively. pad_if_needed (boolean): It will pad the image if smaller than the desired size to avoid raising an exception. fill: Pixel fill value for constant fill. Default is 0. If a tuple of length 3, it is used to fill R, G, B channels respectively. This value is only used when the padding_mode is constant padding_mode: Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant. - constant: pads with a constant value, this value is specified with fill - edge: pads with the last value on the edge of the image - reflect: pads with reflection of image (without repeating the last value on the edge) padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2] - symmetric: pads with reflection of image (repeating the last value on the edge) padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3] """ def __init__(self, size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'): if isinstance(size, numbers.Number): self.size = (int(size), int(size)) else: self.size = size self.padding = padding self.pad_if_needed = pad_if_needed self.fill = fill self.padding_mode = padding_mode @staticmethod def get_params(img, output_size): """Get parameters for ``crop`` for a random crop. Args: img (PIL Image): Image to be cropped. output_size (tuple): Expected output size of the crop. Returns: tuple: params (i, j, h, w) to be passed to ``crop`` for random crop. """ w, h = img.size th, tw = output_size if w == tw and h == th: return 0, 0, h, w i = random.randint(0, h - th) j = random.randint(0, w - tw) return i, j, th, tw def __call__(self, img): """ Args: img (PIL Image): Image to be cropped. Returns: PIL Image: Cropped image. """ if self.padding is not None: img = F.pad(img, self.padding, self.fill, self.padding_mode) # pad the width if needed if self.pad_if_needed and img.size[0] &lt; self.size[1]: img = F.pad(img, (self.size[1] - img.size[0], 0), self.fill, self.padding_mode) # pad the height if needed if self.pad_if_needed and img.size[1] &lt; self.size[0]: img = F.pad(img, (0, self.size[0] - img.size[1]), self.fill, self.padding_mode) i, j, h, w = self.get_params(img, self.size) return F.crop(img, i, j, h, w) def __repr__(self): return self.__class__.__name__ + '(size=&#123;0&#125;, padding=&#123;1&#125;)'.format(self.size, self.padding) 除了上述两种常用的裁剪，剩下的裁剪方式有： RandomResizedCrop(object)： Crop the given PIL Image to random size and aspect ratio. RandomSizedCrop(RandomResizedCrop)： This transform is deprecated in favor of RandomResizedCrop. FiveCrop(object)： Crop the given PIL Image into four corners and the central crop. TenCrop(object)： Crop the given PIL Image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default). 关于变换Pad(object)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Pad(object): """Pad the given PIL Image on all sides with the given "pad" value. Args: padding (int or tuple): Padding on each border. If a single int is provided this is used to pad all borders. If tuple of length 2 is provided this is the padding on left/right and top/bottom respectively. If a tuple of length 4 is provided this is the padding for the left, top, right and bottom borders respectively. fill (int or tuple): Pixel fill value for constant fill. Default is 0. If a tuple of length 3, it is used to fill R, G, B channels respectively. This value is only used when the padding_mode is constant padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant. - constant: pads with a constant value, this value is specified with fill - edge: pads with the last value at the edge of the image - reflect: pads with reflection of image without repeating the last value on the edge For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2] - symmetric: pads with reflection of image repeating the last value on the edge For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3] """ def __init__(self, padding, fill=0, padding_mode='constant'): assert isinstance(padding, (numbers.Number, tuple)) assert isinstance(fill, (numbers.Number, str, tuple)) assert padding_mode in ['constant', 'edge', 'reflect', 'symmetric'] if isinstance(padding, collections.Sequence) and len(padding) not in [2, 4]: raise ValueError("Padding must be an int or a 2, or 4 element tuple, not a " + "&#123;&#125; element tuple".format(len(padding))) self.padding = padding self.fill = fill self.padding_mode = padding_mode def __call__(self, img): """ Args: img (PIL Image): Image to be padded. Returns: PIL Image: Padded image. """ return F.pad(img, self.padding, self.fill, self.padding_mode) def __repr__(self): return self.__class__.__name__ + '(padding=&#123;0&#125;, fill=&#123;1&#125;, padding_mode=&#123;2&#125;)'.\ format(self.padding, self.fill, self.padding_mode) 除了官方提供的变换操作，还可以自定义变化： 123456789101112131415class Lambda(object): """Apply a user-defined lambda as a transform. Args: lambd (function): Lambda/function to be used for transform. """ def __init__(self, lambd): assert isinstance(lambd, types.LambdaType) self.lambd = lambd def __call__(self, img): return self.lambd(img) def __repr__(self): return self.__class__.__name__ + '()' 上述都是比较常用的变换。为了增加数据的多样性，随机性，使得训练更充分，具有更强的generalization，官方还提供了一系列的操作，主要是随机操作： class RandomTransforms(object)： Base class for a list of transformations with randomness. class RandomApply(RandomTransforms)： Apply randomly a list of transformations with a given probability. class RandomOrder(RandomTransforms)： Apply a list of transformations in a random order. class RandomChoice(RandomTransforms)： Apply single transformation randomly picked from a list. class RandomHorizontalFlip(object)： Horizontally flip the given PIL Image randomly with a given probability. class RandomVerticalFlip(object)： Vertically flip the given PIL Image randomly with a given probability. class RandomResizedCrop(object)： Crop the given PIL Image to random size and aspect ratio. class RandomSizedCrop(RandomResizedCrop)： This transform is deprecated in favor of RandomResizedCrop. class LinearTransformation(object)： Transform a tensor image with a square transformation matrix computed offline. class ColorJitter(object)： Randomly change the brightness, contrast and saturation of an image. class RandomRotation(object)： Rotate the image by angle. class RandomAffine(object)： Random affine transformation of the image keeping center invariant. class Grayscale(object)： Convert image to grayscale. class RandomGrayscale(object)： Randomly convert image to grayscale with a probability of p (default 0.1). Reference： https://github.com/pytorch/vision/blob/master/torchvision/transforms/transforms.py https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Compose https://blog.csdn.net/u014380165/article/details/79167753 另外，关于__init__，__call__和__repr__的说明，可以参考：http://funhacks.net/explore-python/Class/magic_method.html，https://www.cnblogs.com/shengulong/p/7456435.html。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】fine tune on your own dataset]]></title>
    <url>%2F2018%2F08%2F12%2F%E3%80%90pytorch%E3%80%91fine-tune-on-your-own-dataset%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192from __future__ import print_function, divisionimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.optim import lr_schedulerimport numpy as npimport torchvisionfrom torchvision import datasets, models, transformsimport matplotlib.pyplot as pltimport timeimport osimport copyfrom torch.autograd import Variableplt.ion() # interactive mode# Data augmentation and normalization for training# Just normalization for validationdata_transforms = &#123; 'train': transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),&#125;data_dir = '/home/jsk/s/prcv/dataset/v2'image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']&#125;dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=32) for x in ['train', 'val']&#125;dataset_sizes = &#123;x: len(image_datasets[x]) for x in ['train', 'val']&#125;class_names = image_datasets['train'].classesdevice = torch.device("cuda:2" if torch.cuda.is_available() else "cpu")def imshow(inp, title=None): """Imshow for Tensor.""" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(10) # pause a bit so that plots are updateddef train_model(model, criterion, optimizer, scheduler, num_epochs=10): since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(1,num_epochs+1): print('Epoch &#123;&#125;/&#123;&#125;'.format(epoch, num_epochs)) print('-' * 10) # Each epoch has a training and validation phase for phase in ['train', 'val']: if phase == 'train': scheduler.step() model.train() # Set model to training mode else: model.eval() # Set model to evaluate mode running_loss = 0.0 running_corrects = 0 # Iterate over data. for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) # zero the parameter gradients optimizer.zero_grad() # forward # track history if only in train with torch.set_grad_enabled(phase == 'train'): outputs = model(inputs) _, preds = torch.max(outputs, 1) loss = criterion(outputs, labels) # backward + optimize only if in training phase if phase == 'train': loss.backward() optimizer.step() # statistics running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds == labels.data) epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects.double() / dataset_sizes[phase] print('&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'.format( phase, epoch_loss, epoch_acc)) # deep copy the model if phase == 'val' and epoch_acc &gt; best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) print() time_elapsed = time.time() - since print('Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'.format( time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: &#123;:4f&#125;'.format(best_acc)) # load best model weights model.load_state_dict(best_model_wts) return modeldef visualize_model(model, num_images=6): was_training = model.training model.eval() images_so_far = 0 fig = plt.figure() with torch.no_grad(): for i, (inputs, labels) in enumerate(dataloaders['val']): inputs = inputs.to(device) labels = labels.to(device) outputs = model(inputs) _, preds = torch.max(outputs, 1) for j in range(inputs.size()[0]): images_so_far += 1 ax = plt.subplot(num_images//2, 2, images_so_far) ax.axis('off') ax.set_title('predicted: &#123;&#125;'.format(class_names[preds[j]])) imshow(inputs.cpu().data[j]) if images_so_far == num_images: model.train(mode=was_training) return model.train(mode=was_training)# Finetuning the convnetif __name__ == '__main__': model_ft = models.resnet50(pretrained=True) print(model_ft) LAST = 0 if LAST: for param in model_ft.parameters(): param.requires_grad = False num_ftrs = model_ft.fc.in_features model_ft.fc = nn.Linear(num_ftrs, 205) model_ft = model_ft.to(device) criterion = nn.CrossEntropyLoss() # Observe that all parameters are being optimized if LAST: # fine tune the parameters of the last layer optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9) print('optimized params is: last layer') else: # fine tune all parameters optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9) print('optimized params is: all') # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30) #visualize_model(model_ft) #plt.ioff() #plt.show() torch.save(model_ft.state_dict(),'resnet50_epoch30_ft_batch4.pkl') From line 65, the model(vgg, resnet, ect.) as an input of the function train_model is with parameters (weights, bias). line 21~34: transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. From here As the official docs explain, the mean and std used to normalize inputs should be consistent in train, val and even test period. Theoretically we can set any number to mean and val, just keeping it consistent in all periods. But it won’t lead data to and normalization distribution, thus not result in an efficient improvement (in training). Further details about transform operation, you could consult this blog. line 72~78, model.train() and model.eval(): Some models use modules which have different training and evaluation behavior, such as batch normalization. To switch between these modes, use model.train() or model.eval() as appropriate. See train() or eval() for details.From here line 88,89: optimizer.zero_grad():At every batch cycle, we should Clears the gradients of all optimized torch.Tensor s. Because we will update network’s params every batch cycle. When new batch is put into net, it should base on previous updated params and have a new start on it own (generate a new delta, where new_params = pre_params+delta simply). line 93: with torch.set_grad_enabled(phase == &#39;train&#39;):This is a context manager, where we can control whether to enable or disable grads based on its argument mode. If we are sure not to call Tensor.backward(), i.e. in reference process, we choose to disable gradient calculation, (This is like a gate to control the whole graph.), so that it will reduce memory consumption for computations. line 95: _, preds = torch.max(outputs, 1) Returns the maximum value of each row of the input tensor in the given dimension dim. The second return value is the index location of each maximum value found (argmax). From here 1234print(torch.max(outputs, 1))&gt;&gt;&gt; (tensor([1.9105, 1.5765, 1.7810, 1.8969, 1.7162, 2.5723, 1.8377, 1.8657], device='cuda:2', grad_fn=&lt;MaxBackward0&gt;), tensor([146, 146, 146, 146, 146, 146, 19, 146], device='cuda:2')) data structureset batch size = 8: line 84, 85, 86: 123456789print(type(inputs))print(type(labels))print(inputs.shape)print(labels.shape)&gt;&gt;&gt; &lt;class 'torch.Tensor'&gt;&gt;&gt;&gt; &lt;class 'torch.Tensor'&gt;&gt;&gt;&gt; torch.Size([8, 3, 224, 224])&gt;&gt;&gt; torch.Size([8]) line 94, 95, 96: 1234567print(outputs.shape)print(preds.shape)print(loss) &gt;&gt;&gt; torch.Size([8, 205])&gt;&gt;&gt; torch.Size([8])&gt;&gt;&gt; tensor(5.3540, device='cuda:2', grad_fn=&lt;NllLossBackward&gt;) line 37~42: 12345print(type(dataloaders['train']))print(type(image_datasets['train']))&gt;&gt;&gt; &lt;class 'torch.utils.data.dataloader.DataLoader'&gt;&gt;&gt;&gt; &lt;class 'torchvision.datasets.folder.ImageFolder'&gt; Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.All datasets are subclasses of torch.utils.data.Dataset i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be passed to a torch.utils.data.DataLoader which can load multiple samples parallelly using torch.multiprocessing workers. line 85, 86, 168: 123model_ft = model_ft.to(device)inputs = inputs.to(device)labels = labels.to(device) Move all data into certain GPU(device). Recursively go over all modules and convert their parameters and buffers to CUDA tensors.Remember that you will have to send the inputs and targets at every step to the GPU too.From here reference 【pytorch】模型的搭建保存加载 all methods for torch.tensor Locally disabling gradient computation context managers I context managers II]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】with (context_managers)]]></title>
    <url>%2F2018%2F08%2F12%2F%E3%80%90pytorch%E3%80%91with%20(context_managers)%2F</url>
    <content type="text"><![CDATA[Context Managers (REFERENCE: http://book.pythontips.com/en/latest/context_managers.html) Context managers allow you to allocate and release resources precisely when you want to. The most widely used example of context managers is the with statement. Suppose you have two related operations which you’d like to execute as a pair, with a block of code in between. Context managers allow you to do specifically that. For example: 12with open('some_file', 'w') as opened_file: opened_file.write('Hola!') The above code opens the file, writes some data to it and then closes it. If an error occurs while writing the data to the file, it tries to close it. The above code is equivalent to: 12345file = open('some_file', 'w')try: file.write('Hola!')finally: file.close() While comparing it to the first example we can see that a lot of boilerplate code is eliminated just by using with. The main advantage of using a with statement is that it makes sure our file is closed without paying attention to how the nested block exits. A common use case of context managers is locking and unlocking resources and closing opened files (as I have already shown you). Let’s see how we can implement our own Context Manager. This should allow us to understand exactly what’s going on behind the scenes. 1. Implementing a Context Manager as a Class:At the very least a context manager has an __enter__ and __exit__ method defined. Let’s make our own file-opening Context Manager and learn the basics. 1234567class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): self.file_obj.close() Just by defining __enter__ and __exit__ methods we can use our new class in a with statement. Let’s try: 12with File('demo.txt', 'w') as opened_file: opened_file.write('Hola!') Our __exit__ method accepts three arguments. They are required by every __exit__ method which is a part of a Context Manager class. Let’s talk about what happens under-the-hood. The with statement stores the __exit__ method of the File class. It calls the __enter__ method of the File class. The __enter__ method opens the file and returns it. The opened file handle is passed to opened_file. We write to the file using .write(). The with statement calls the stored __exit__ method. The __exit__ method closes the file. 2. Handling ExceptionsWe did not talk about the type, value and traceback arguments of the __exit__ method. Between the 4th and 6th step, ifan exception occurs, Python passes the type, value and traceback of the exception to the __exit__ method. It allows the __exit__ methodto decide how to close the file and if any further steps are required. In our case we are not paying any attention to them. What if our file object raises an exception? We might be trying to access a method on the file object which it does not supports. For instance: 12with File('demo.txt', 'w') as opened_file: opened_file.undefined_function('Hola!') Let’s list the steps which are taken by the with statement when an error is encountered: It passes the type, value and traceback of the error to the __exit__ method. It allows the __exit__ method to handle the exception. If __exit__ returns True then the exception was gracefully handled. If anything other than True is returned by the __exit__ method then the exception is raised by the with statement. In our case the __exit__ method returns None (when no return statement is encountered then the method returns None). Therefore, the with statement raises the exception: 123Traceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt;AttributeError: 'file' object has no attribute 'undefined_function' Let’s try handling the exception in the __exit__ method: 1234567891011121314class File(object): def __init__(self, file_name, method): self.file_obj = open(file_name, method) def __enter__(self): return self.file_obj def __exit__(self, type, value, traceback): print("Exception has been handled") self.file_obj.close() return Truewith File('demo.txt', 'w') as opened_file: opened_file.undefined_function() # Output: Exception has been handled Our __exit__ method returned True, therefore no exception was raised by the with statement. This is not the only way to implement Context Managers. There is another way and we will be looking at it in the next section. 3. Implementing a Context Manager as a GeneratorWe can also implement Context Managers using decorators and generators. Python has a contextlib module for this very purpose. Instead of a class, we can implement a Context Manager using a generator function. Let’s see a basic, useless example: 1234567from contextlib import contextmanager@contextmanagerdef open_file(name): f = open(name, 'w') yield f f.close() Okay! This way of implementing Context Managers appear to be more intuitive and easy. However, this method requires some knowledge about generators, yield and decorators. In this example we have not caught any exceptions which might occur. It works in mostly the same way as the previous method. Let’s dissect this method a little. Python encounters the yield keyword. Due to this it creates a generator instead of a normal function. Due to the decoration, contextmanager is called with the function name (open\_file) as it’s argument. The contextmanager decorator returns the generator wrapped by the GeneratorContextManager object. The GeneratorContextManager is assigned to the open_file function. Therefore, when we later call the open_file function, we are actually calling the GeneratorContextManager object. So now that we know all this, we can use the newly generated Context Manager like this: 12with open_file('some_file') as f: f.write('hola!')]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】torch.nn]]></title>
    <url>%2F2018%2F08%2F08%2F%E3%80%90pytorch%E3%80%91torch-nn%2F</url>
    <content type="text"><![CDATA[torch.nnParametersclass torch.nn.Parameter data (Tensor) – parameter tensor. requires_grad (bool, optional) – if the parameter requires gradient. Default: True A kind of Tensor that is to be considered a module parameter.Parameters are Tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator. Assigning a Tensor doesn’t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as Parameter, these temporaries would get registered too. SUMMARY: This is a class, whose objects can be acquired through methods of torch.nn.Module, i.e. parameters(). 一切接对象，class，方法。具体操作的是对象，通过class实例化得到，得到的过程需要初始化，在网络中有很多需要配置的地方，简便起见，很多都有默认值，使得在多数情况下不需要特别地初始化。方法使得操作更加丰富、规范和便利。class—(initionize, default)—object torch.optimHow to use an optimizer?To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients. #Constructing it# To construct an Optimizer you have to give it an iterable containing the parameters (all should be Variable s) to optimize. Then, you can specify optimizer-specific options such as the learning rate, weight decay, etc.【If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. Parameters of a model after .cuda() will be different objects with those before the call. In general, you should make sure that optimized parameters live in consistent locations when optimizers are constructed and used.】 #Per-parameter options# Optimizers also support specifying per-parameter options. To do this, instead of passing an iterable of Variables, pass in an iterable of dicts. Each of them will define a separate parameter group, and should contain a params key, containing a list of parameters belonging to it. Other keys should match the keyword arguments accepted by the optimizers, and will be used as optimization options for this group. #Taking an optimization step# All optimizers implement a step() method, that updates the parameters. It can be used in two ways: optimizer.step() optimizer.step(closure) Algorithms class torch.optim.Optimizer(params, defaults): Base class for all optimizers. add_param_group(param_group) load_state_dict(state_dict) state_dict() step(closure) zero_grad() class torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) class torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0) class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False) class torch.optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08) class torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False) class torch.optim.SGD(params, lr=&lt;object object&gt;, momentum=0, dampening=0, weight_decay=0, nesterov=False) … ####How to adjust Learning Rate? torch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs.【learning rate is the function of epochs】 torch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic learning rate reducing based on some validation measurements.【learning rateis the function of some kind of measurements】. class torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1) Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1) Sets the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs. When last_epoch=-1, sets initial lr as lr. class torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1) Set the learning rate of each parameter group to the initial lr decayed by gamma once the number of epoch reaches one of the milestones. When last_epoch=-1, sets initial lr as lr. … class torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0, eps=1e-08) Reduce learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced. SUMMARY: construct an optimizer object, and mainly pay attention to these points: 1. which part of params need to be optimized and which not. 2. which algorithm to choose? 3. adjust learning rate in different period of training.]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】Loss functions]]></title>
    <url>%2F2018%2F08%2F08%2F%E3%80%90pytorch%E3%80%91Loss-functions%2F</url>
    <content type="text"><![CDATA[Before you can see the whole, it’s sea.Before you organize the whole, it’s universe.See the whole and organize it, it’s a transparent box.——Sky. J. torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction=&#39;elementwise_mean&#39;) Function that measures the Binary Cross Entropy between the target and the output. input – Tensor of arbitrary shape target – Tensor of the same shape as input size_average (bool, optional) – By default, the losses are averaged over each loss element in the batch. torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction=&#39;elementwise_mean&#39;) Poisson negative log likelihood loss. input – expectation of underlying Poisson distribution. target – random sample target∼Poisson(input). torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=&#39;elementwise_mean&#39;)]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ops for tensor]]></title>
    <url>%2F2018%2F08%2F07%2F%E3%80%90pytorch%E3%80%91ops%20for%20tensor%2F</url>
    <content type="text"><![CDATA[Before you can see the whole, it’s sea.Before you organize the whole, it’s universe.See the whole and organize it, it’s a transparent box.——Sky. J. tensortorch.is_tensor(obj)Returns True if obj is a PyTorch tensor.torch.is_storage(obj)Returns True if obj is a PyTorch storage object.torch.set_default_dtype(d)Sets the default floating point dtype to d. The default floating point dtype is initially torch.float32.torch.get_default_dtype()Get the current default floating point torch.dtype.creation opstorch.tensor(data, dtype=None, device=None, requires_grad=False)Constructs a tensor with data.torch.from_numpy(ndarray)Creates a Tensor from a numpy.ndarray. The returned tensor and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. The returned tensor is not resizable.torch.zeros(sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a tensor filled with the scalar value 0, with the shape defined by the variable argument sizes.torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False) Returns a tensor filled with the scalar value 0, with the same size as input. torch.ones(sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) Returns a tensor filled with the scalar value 1, with the shape defined by the variable argument sizes.torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False)Returns a tensor filled with the scalar value 1, with the same size as input. torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)[start(=0):step(=1):end) (favor)torch.range(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)[start(=0):step(=1):end]torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a one-dimensional tensor of steps equally spaced points between start and end. The output tensor is 1-D of size steps.torch.logspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a one-dimensional tensor of steps points logarithmically spaced between 10^start and 10^endtorch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.torch.empty(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a tensor filled with uninitialized data. The shape of the tensor is defined by the variable argument sizes.torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False)Returns an uninitialized tensor with the same size as input.torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a tensor of size size filled with fill_value.torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)Returns a tensor with the same size as input filled with fill_value.Indexing, Slicing, Joining, Mutating Opstorch.cat(seq, dim=0, out=None)Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.torch.chunk(tensor, chunks, dim=0)Splits a tensor into a specific number of chunks. Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.torch.gather(input, dim, index, out=None) Gathers values along an axis specified by dim.torch.index_select(input, dim, index, out=None)Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor.torch.masked_select(input, mask, out=None)Returns a new 1-D tensor which indexes the input tensor according to the binary mask mask which is a ByteTensor. The shapes of the mask tensor and the input tensor don’t need to match, but they must be broadcastable.torch.nonzero(input, out=None)Returns a tensor containing the indices of all non-zero elements of input. Each row in the result contains the indices of a non-zero element in input. If input has n dimensions, then the resulting indices tensor out is of size (z×n), where z is the total number of non-zero elements in the input tensor.torch.reshape(input, shape)Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. torch.split(tensor, split_size_or_sections, dim=0)Splits the tensor into chunks.torch.squeeze(input, dim=None, out=None)Returns a tensor with all the dimensions of input of size 1 removed.torch.stack(seq, dim=0, out=None)Concatenates sequence of tensors along a new dimension. All tensors need to be of the same size. seq (sequence of Tensors) – sequence of tensors to concatenatetorch.t(input)Expects input to be a matrix (2-D tensor) and transposes dimensions 0 and 1.torch.take(input, indices)Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.torch.transpose(input, dim0, dim1)Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.torch.unbind(tensor, dim=0)Removes a tensor dimension. Returns a tuple of all slices along a given dimension, already without it.torch.unsqueeze(input, dim, out=None)Returns a new tensor with a dimension of size one inserted at the specified position. The returned tensor shares the same underlying data with this tensor.torch.where(condition, x, y)Return a tensor of elements selected from either x or y, depending on condition. The tensors condition, x, y must be broadcastable. UPDATING…PICK FROM https://pytorch.org/docs/stable/torch.html#tensors]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重装系统]]></title>
    <url>%2F2018%2F08%2F01%2F%E3%80%90Ubuntu%E3%80%91%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[最近三天全都在折腾系统，各种奇葩的问题，比如电脑莫名其妙地连接到别人的路由器上导致无法上网，同样的问题按照别人的解决方法一步步走却把电脑装坏了。导致三天一共重装了三次系统，一把辛酸泪。下面将重装系统的一些步骤列举一下，以后重装时有个参考： 下载nvidia 驱动 安装anaconda 安装cuda 安装opencv 安装matlab 安装caffe 安装pycharm… Review 开机后，先依次点击（加载）自己分的硬盘，否则相关的路径无法到达。 最好一开始就按照教程，多参考几个，分析现象背后的原因，不要自己瞎鼓捣，否则越装问题越多。 先装重要的、难度大的大软件，然后容易的、琐碎的小软件，最后个性化设置。如果前面没有装好，可以直接重装；]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster rcnn】roi_pooling_layer]]></title>
    <url>%2F2018%2F07%2F13%2F%E3%80%90faster%20rcnn%E3%80%91roi_pooling_layer%2F</url>
    <content type="text"><![CDATA[之前说过，caffe中的layer层，主要有以下几个函数： setup reshape forward backward 在roi_pooling_layer.cpp中，主要是前三个函数，在分别对其进行解析之前，先看一下该层的使用： layer { name: &quot;roi_pool_conv5&quot; type: &quot;ROIPooling&quot; bottom: &quot;conv5&quot; bottom: &quot;rois&quot; top: &quot;roi_pool_conv5&quot; roi_pooling_param { pooled_w: 6 pooled_h: 6 spatial_scale: 0.0625 # 1/16 } } 即该层的输入为conv5的特征图和rois，最后输出roi_pool_conv5。 下面看以下初始化函数LayerSetUp()： 12345678910111213template &lt;typename Dtype&gt;void ROIPoolingLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123; ROIPoolingParameter roi_pool_param = this-&gt;layer_param_.roi_pooling_param(); CHECK_GT(roi_pool_param.pooled_h(), 0) &lt;&lt; "pooled_h must be &gt; 0"; CHECK_GT(roi_pool_param.pooled_w(), 0) &lt;&lt; "pooled_w must be &gt; 0"; pooled_height_ = roi_pool_param.pooled_h(); // pooling后的特征图的height_ pooled_width_ = roi_pool_param.pooled_w(); // pooling后的特征图的width_ spatial_scale_ = roi_pool_param.spatial_scale(); // 空间缩放尺度，在ZF中为1/16 = 0.0625 LOG(INFO) &lt;&lt; "Spatial scale: " &lt;&lt; spatial_scale_;&#125; 上面函数的作用是设置pooling后的特征图的尺寸height_和width_，以及pooling后的特征图相对于原图1的缩放比例scale。看一下reshape部分： 1234567891011template &lt;typename Dtype&gt;void ROIPoolingLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123; channels_ = bottom[0]-&gt;channels(); height_ = bottom[0]-&gt;height(); width_ = bottom[0]-&gt;width(); top[0]-&gt;Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_); max_idx_.Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_);&#125; 通过这段代码，可以看出:输出的top个数等于rois的个数，channels等于特征图conv5的channels。 另外，注意top_data作为top[0]的指针，在每个channel上更新一次（通过下面的循环可以看出）；大小一共pooled_height_*pooled_width_个。这些都可以通过forward()中的循环得到。 12345678910111213141516171819202122232425template &lt;typename Dtype&gt;void ROIPoolingLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123; const Dtype* bottom_data = bottom[0]-&gt;cpu_data(); const Dtype* bottom_rois = bottom[1]-&gt;cpu_data(); // Number of ROIs int num_rois = bottom[1]-&gt;num(); int batch_size = bottom[0]-&gt;num(); int top_count = top[0]-&gt;count(); Dtype* top_data = top[0]-&gt;mutable_cpu_data(); caffe_set(top_count, Dtype(-FLT_MAX), top_data); int* argmax_data = max_idx_.mutable_cpu_data(); caffe_set(top_count, -1, argmax_data); // For each ROI R = [batch_index x1 y1 x2 y2]: max pool over R for (int n = 0; n &lt; num_rois; ++n) &#123; int roi_batch_ind = bottom_rois[0]; int roi_start_w = round(bottom_rois[1] * spatial_scale_); int roi_start_h = round(bottom_rois[2] * spatial_scale_); int roi_end_w = round(bottom_rois[3] * spatial_scale_); int roi_end_h = round(bottom_rois[4] * spatial_scale_); CHECK_GE(roi_batch_ind, 0); CHECK_LT(roi_batch_ind, batch_size); int roi_height = max(roi_end_h - roi_start_h + 1, 1); int roi_width = max(roi_end_w - roi_start_w + 1, 1); 由于rois是在原图1的尺寸下，而此处的特征图conv5是经过前面convolution和Pooling后被缩小的，因此需要将rois投影到该尺寸下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 // 此处是求roi在每个pooling单元占据的面积，但是分height和width来计算。 // pooling对‘经过scale变换，映射到特征图上的真实的roi‘的划分 const Dtype bin_size_h = static_cast&lt;Dtype&gt;(roi_height) / static_cast&lt;Dtype&gt;(pooled_height_); const Dtype bin_size_w = static_cast&lt;Dtype&gt;(roi_width) / static_cast&lt;Dtype&gt;(pooled_width_); const Dtype* batch_data = bottom_data + bottom[0]-&gt;offset(roi_batch_ind); for (int c = 0; c &lt; channels_; ++c) &#123; for (int ph = 0; ph &lt; pooled_height_; ++ph) &#123; //标称值，如果pooling结果为6*6,，那么这里就是0~5的循环。 for (int pw = 0; pw &lt; pooled_width_; ++pw) &#123; // 此处的循环以pooling中的ceil（标称值）为单位。 // Compute pooling region for this output unit: // start (included) = floor(ph * roi_height / pooled_height_) // end (excluded) = ceil((ph + 1) * roi_height / pooled_height_) // 特征图上每个单元格，通过标称值遍历，定位在真实的特征图conv_5上 int hstart = static_cast&lt;int&gt;(floor(static_cast&lt;Dtype&gt;(ph) * bin_size_h)); int wstart = static_cast&lt;int&gt;(floor(static_cast&lt;Dtype&gt;(pw) * bin_size_w)); int hend = static_cast&lt;int&gt;(ceil(static_cast&lt;Dtype&gt;(ph + 1) * bin_size_h)); int wend = static_cast&lt;int&gt;(ceil(static_cast&lt;Dtype&gt;(pw + 1) * bin_size_w)); // 此处的hstart、hend、wstart、wend是以ceil为前后界，以roi为基准的绝对的坐标 hstart = min(max(hstart + roi_start_h, 0), height_); hend = min(max(hend + roi_start_h, 0), height_); wstart = min(max(wstart + roi_start_w, 0), width_); wend = min(max(wend + roi_start_w, 0), width_); bool is_empty = (hend &lt;= hstart) || (wend &lt;= wstart); const int pool_index = ph * pooled_width_ + pw; if (is_empty) &#123; top_data[pool_index] = 0; argmax_data[pool_index] = -1; &#125; // 此处的循环以roi在ceil中的每个特征点为单位 for (int h = hstart; h &lt; hend; ++h) &#123; for (int w = wstart; w &lt; wend; ++w) &#123; const int index = h * width_ + w; //每个单元格只取其对应特征图区域中的一个值，这里取最大值。 if (batch_data[index] &gt; top_data[pool_index]) &#123; top_data[pool_index] = batch_data[index]; argmax_data[pool_index] = index; &#125; &#125; &#125; &#125; &#125; //指针指向的地址需要增加1，因为每个channel是独立进行roi_pooling的。 // Increment all data pointers by one channel batch_data += bottom[0]-&gt;offset(0, 1); top_data += top[0]-&gt;offset(0, 1); argmax_data += max_idx_.offset(0, 1); &#125; // Increment ROI data pointer bottom_rois += bottom[1]-&gt;offset(1); &#125;&#125; 总结 该网络 A： 在原图0的基础上， B： 根据前面的网络（rpn）生成的roi，在conv_5上进行pooling，相应地尺寸要通过* spatial_scale_调整， C： 最后得到具有固定尺寸的，在conv_5的特征图上进行pooling之后的‘pooled feature map’（输出的尺寸是作为参数设定好的）。 reference https://blog.csdn.net/iamzhangzhuping/article/details/51500162 https://blog.csdn.net/Charel_CHEN/article/details/78669654]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster-rcnn】anchortargetlayer]]></title>
    <url>%2F2018%2F07%2F11%2F%E3%80%90faster-rcnn%E3%80%91anchortargetlayer%2F</url>
    <content type="text"><![CDATA[该层用于rpn的训练阶段。 看一下该层的使用方法： layer { name: &apos;rpn-data&apos; type: &apos;Python&apos; bottom: &apos;rpn_cls_score&apos; bottom: &apos;gt_boxes&apos; bottom: &apos;im_info&apos; bottom: &apos;data&apos; top: &apos;rpn_labels&apos; top: &apos;rpn_bbox_targets&apos; top: &apos;rpn_bbox_inside_weights&apos; top: &apos;rpn_bbox_outside_weights&apos; python_param { module: &apos;rpn.anchor_target_layer&apos; layer: &apos;AnchorTargetLayer&apos; param_str: &quot;&apos;feat_stride&apos;: 16&quot; } } 在AnchorTargetLayer的具体实现中，只用到三个输入信息。该层的作用是根据gt_boxes（结构为1 × 4）和原图0到原图1的resize信息im_info，和conv_5特征图的尺寸（1,2*9,H,W）,通过rpn_cls_score获得，得到anchor需要的修正量以及有效anchor的fg/bg的labels。关于原始图片数据data并没有看到有被利用。 看一下setup()部分：1234567891011121314151617181920212223242526272829303132333435363738def setup(self, bottom, top): layer_params = yaml.load(self.param_str_) anchor_scales = layer_params.get('scales', (8, 16, 32)) self._anchors = generate_anchors(scales=np.array(anchor_scales)) self._num_anchors = self._anchors.shape[0] self._feat_stride = layer_params['feat_stride'] if DEBUG: print 'anchors:' print self._anchors print 'anchor shapes:' print np.hstack(( self._anchors[:, 2::4] - self._anchors[:, 0::4], self._anchors[:, 3::4] - self._anchors[:, 1::4], )) self._counts = cfg.EPS self._sums = np.zeros((1, 4)) self._squared_sums = np.zeros((1, 4)) self._fg_sum = 0 self._bg_sum = 0 self._count = 0 # allow boxes to sit over the edge by a small amount self._allowed_border = layer_params.get('allowed_border', 0) height, width = bottom[0].data.shape[-2:] if DEBUG: print 'AnchorTargetLayer: height', height, 'width', width A = self._num_anchors # labels top[0].reshape(1, 1, A * height, width) # bbox_targets top[1].reshape(1, A * 4, height, width) # bbox_inside_weights top[2].reshape(1, A * 4, height, width) # bbox_outside_weights top[3].reshape(1, A * 4, height, width) 这里重点是记住top的shape。 然后看forward()： 1234567891011121314151617181920212223242526272829303132333435363738394041424344def forward(self, bottom, top): # Algorithm: # # for each (H, W) location i # generate 9 anchor boxes centered on cell i # apply predicted bbox deltas at cell i to each of the 9 anchors # filter out-of-image anchors # measure GT overlap assert bottom[0].data.shape[0] == 1, \ 'Only single item batches are supported' # map of shape (..., H, W) height, width = bottom[0].data.shape[-2:] # GT boxes (x1, y1, x2, y2, label) gt_boxes = bottom[1].data # im_info im_info = bottom[2].data[0, :] if DEBUG: print '' print 'im_size: (&#123;&#125;, &#123;&#125;)'.format(im_info[0], im_info[1]) print 'scale: &#123;&#125;'.format(im_info[2]) print 'height, width: (&#123;&#125;, &#123;&#125;)'.format(height, width) print 'rpn: gt_boxes.shape', gt_boxes.shape print 'rpn: gt_boxes', gt_boxes # 1. Generate proposals from bbox deltas and shifted anchors shift_x = np.arange(0, width) * self._feat_stride shift_y = np.arange(0, height) * self._feat_stride shift_x, shift_y = np.meshgrid(shift_x, shift_y) shifts = np.vstack((shift_x.ravel(), shift_y.ravel(), shift_x.ravel(), shift_y.ravel())).transpose() # add A anchors (1, A, 4) to # cell K shifts (K, 1, 4) to get # shift anchors (K, A, 4) # reshape to (K*A, 4) shifted anchors A = self._num_anchors K = shifts.shape[0] all_anchors = (self._anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2))) all_anchors = all_anchors.reshape((K * A, 4)) total_anchors = int(K * A) 此处同“proposal layer制作基于原图1的框架shifts，以及将框架与一套相对性的anchor相结合”如出一辙。12345678910111213141516# only keep anchors inside the imageinds_inside = np.where( (all_anchors[:, 0] &gt;= -self._allowed_border) &amp; (all_anchors[:, 1] &gt;= -self._allowed_border) &amp; (all_anchors[:, 2] &lt; im_info[1] + self._allowed_border) &amp; # width (all_anchors[:, 3] &lt; im_info[0] + self._allowed_border) # height)[0] if DEBUG: print 'total_anchors', total_anchors print 'inds_inside', len(inds_inside) # keep only inside anchorsanchors = all_anchors[inds_inside, :]if DEBUG: print 'anchors.shape', anchors.shape anchor的shape较all_anchors的shape有所缩小。123# label: 1 is positive, 0 is negative, -1 is dont carelabels = np.empty((len(inds_inside), ), dtype=np.float32)labels.fill(-1) labels的规模等于剩下的anchor，即在允许范围内的anchor。1234567891011# overlaps between the anchors and the gt boxes# overlaps (ex, gt)overlaps = bbox_overlaps( np.ascontiguousarray(anchors, dtype=np.float), np.ascontiguousarray(gt_boxes, dtype=np.float))argmax_overlaps = overlaps.argmax(axis=1)max_overlaps = overlaps[np.arange(len(inds_inside)), argmax_overlaps]gt_argmax_overlaps = overlaps.argmax(axis=0)gt_max_overlaps = overlaps[gt_argmax_overlaps, np.arange(overlaps.shape[1])]gt_argmax_overlaps = np.where(overlaps == gt_max_overlaps)[0] 此处是anchor与gt_boxes的overlaps，和之前计算boxes与gt_boxes的overlaps如出一辙。最后一句的作用： 前两句的作用是找到每个gt_box的overlaps最大时的boxes序号以及相应的overlaps；注意这个序号只能是第一个出现的max的序号，以后如果出现等于max的元素，则无法统计（这是argmax在这里的一个弊端），所以需要最后一句，根据overlaps，找到所有值为max的boxes序号。12345678910111213if not cfg.TRAIN.RPN_CLOBBER_POSITIVES: # assign bg labels first so that positive labels can clobber them labels[max_overlaps &lt; cfg.TRAIN.RPN_NEGATIVE_OVERLAP] = 0 # fg label: for each gt, anchor with highest overlaplabels[gt_argmax_overlaps] = 1 # fg label: above threshold IOUlabels[max_overlaps &gt;= cfg.TRAIN.RPN_POSITIVE_OVERLAP] = 1 if cfg.TRAIN.RPN_CLOBBER_POSITIVES: # assign bg labels last so that negative labels can clobber positives labels[max_overlaps &lt; cfg.TRAIN.RPN_NEGATIVE_OVERLAP] = 0 先将gt对应的最大boxes设置为前景，然后对所有的boxes，如果overlaps&gt;thresh，同样设置为前景。其实只需要后者即可，加上前者更加保险，因为有一种小概率事件是所有boxes的max_overlaps都很小。注意：虽然gt_boxes里面background属于一类，但是在xml中标注的boxes并没有标出这一类，也就是说标注的boxes全都属于background之外的具体的类别。1234567891011121314151617# subsample positive labels if we have too manynum_fg = int(cfg.TRAIN.RPN_FG_FRACTION * cfg.TRAIN.RPN_BATCHSIZE)fg_inds = np.where(labels == 1)[0]if len(fg_inds) &gt; num_fg: disable_inds = npr.choice( fg_inds, size=(len(fg_inds) - num_fg), replace=False) labels[disable_inds] = -1 # subsample negative labels if we have too manynum_bg = cfg.TRAIN.RPN_BATCHSIZE - np.sum(labels == 1)bg_inds = np.where(labels == 0)[0]if len(bg_inds) &gt; num_bg: disable_inds = npr.choice( bg_inds, size=(len(bg_inds) - num_bg), replace=False) labels[disable_inds] = -1 #print "was %s inds, disabling %s, now %s inds" % ( #len(bg_inds), len(disable_inds), np.sum(labels == 0)) 统计fg/bg的数量，将其控制在一定范围内。（这么做是否对训练有影响？不考虑？）1234567bbox_targets = np.zeros((len(inds_inside), 4), dtype=np.float32)bbox_targets = _compute_targets(anchors, gt_boxes[argmax_overlaps, :]) bbox_inside_weights = np.zeros((len(inds_inside), 4), dtype=np.float32)bbox_inside_weights[labels == 1, :] = np.array(cfg.TRAIN.RPN_BBOX_INSIDE_WEIGHTS) bbox_outside_weights = np.zeros((len(inds_inside), 4), dtype=np.float32) bbox_targets：计算gt_boxes相对于anchors的偏移量，以用于后面生成proposals时的校正信息。 12345678910111213141516171819202122232425262728293031if cfg.TRAIN.RPN_POSITIVE_WEIGHT &lt; 0: # uniform weighting of examples (given non-uniform sampling) num_examples = np.sum(labels &gt;= 0) positive_weights = np.ones((1, 4)) * 1.0 / num_examples negative_weights = np.ones((1, 4)) * 1.0 / num_exampleselse: assert ((cfg.TRAIN.RPN_POSITIVE_WEIGHT &gt; 0) &amp; (cfg.TRAIN.RPN_POSITIVE_WEIGHT &lt; 1)) positive_weights = (cfg.TRAIN.RPN_POSITIVE_WEIGHT / np.sum(labels == 1)) negative_weights = ((1.0 - cfg.TRAIN.RPN_POSITIVE_WEIGHT) / np.sum(labels == 0))bbox_outside_weights[labels == 1, :] = positive_weightsbbox_outside_weights[labels == 0, :] = negative_weights if DEBUG: self._sums += bbox_targets[labels == 1, :].sum(axis=0) self._squared_sums += (bbox_targets[labels == 1, :] ** 2).sum(axis=0) self._counts += np.sum(labels == 1) means = self._sums / self._counts stds = np.sqrt(self._squared_sums / self._counts - means ** 2) print 'means:' print means print 'stdevs:' print stds # map up to original set of anchorslabels = _unmap(labels, total_anchors, inds_inside, fill=-1)bbox_targets = _unmap(bbox_targets, total_anchors, inds_inside, fill=0)bbox_inside_weights = _unmap(bbox_inside_weights, total_anchors, inds_inside, fill=0)bbox_outside_weights = _unmap(bbox_outside_weights, total_anchors, inds_inside, fill=0) 因为之前对anchor有过筛选，现在需要对应到原来每一个anchor的信息（共K * A个），该过程的原理如下： 123456789101112def _unmap(data, count, inds, fill=0): """ Unmap a subset of item (data) back to the original set of items (of size count) """ if len(data.shape) == 1: ret = np.empty((count, ), dtype=np.float32) ret.fill(fill) ret[inds] = data else: ret = np.empty((count, ) + data.shape[1:], dtype=np.float32) ret.fill(fill) ret[inds, :] = data return ret 先生成一共有count的ret（axis=0），然后将data按照inds进行填充，剩下的用fill补充。接下来是对这些结果进行reshape和transpose整理，用于最后输出。12345678910111213141516171819202122232425262728293031323334353637if DEBUG: print 'rpn: max max_overlap', np.max(max_overlaps) print 'rpn: num_positive', np.sum(labels == 1) print 'rpn: num_negative', np.sum(labels == 0) self._fg_sum += np.sum(labels == 1) self._bg_sum += np.sum(labels == 0) self._count += 1 print 'rpn: num_positive avg', self._fg_sum / self._count print 'rpn: num_negative avg', self._bg_sum / self._count # labelslabels = labels.reshape((1, height, width, A)).transpose(0, 3, 1, 2)labels = labels.reshape((1, 1, A * height, width))top[0].reshape(*labels.shape)top[0].data[...] = labels # bbox_targetsbbox_targets = bbox_targets \ .reshape((1, height, width, A * 4)).transpose(0, 3, 1, 2)top[1].reshape(*bbox_targets.shape)top[1].data[...] = bbox_targets # bbox_inside_weightsbbox_inside_weights = bbox_inside_weights \ .reshape((1, height, width, A * 4)).transpose(0, 3, 1, 2)assert bbox_inside_weights.shape[2] == heightassert bbox_inside_weights.shape[3] == widthtop[2].reshape(*bbox_inside_weights.shape)top[2].data[...] = bbox_inside_weights # bbox_outside_weightsbbox_outside_weights = bbox_outside_weights \ .reshape((1, height, width, A * 4)).transpose(0, 3, 1, 2)assert bbox_outside_weights.shape[2] == heightassert bbox_outside_weights.shape[3] == widthtop[3].reshape(*bbox_outside_weights.shape)top[3].data[...] = bbox_outside_weights 总结 只有在训练的时候，我们可以提前标注好boxes的位置和类别，但是在实际应用时预先不知道这些信息，这也正是我们期望网络能够自动化完成的任务，因此在train_rpn阶段，利用anchortargetlayer，通过标注的gt_boxes和resize信息，对标准的anchor进行操作，生成‘答案’，即得到用于‘生成proposals’时的修正量和labels，用这些信息训练fast rcnn。 最后的labels等输出，没有用在别的网络，仅仅用在rpn_train阶段，以构成局部闭环，用于反馈rpn的主体网络，如conv_1至scores和pred，然后训练这个主体网络，以便后面更好地生成proposals。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster-rcnn】网络的数据投喂——RoIDataLayer]]></title>
    <url>%2F2018%2F07%2F08%2F%E3%80%90faster-rcnn%E3%80%91%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8A%95%E5%96%82%E2%80%94%E2%80%94RoIDataLayer%2F</url>
    <content type="text"><![CDATA[对于caffe中的layer，主要有以下几个性质： setup forward backward 对于所有的data layer而言，主要是前两点，这里也不例外。 RoIDataLayer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758def setup(self, bottom, top): """Setup the RoIDataLayer.""" # parse the layer parameter string, which must be valid YAML layer_params = yaml.load(self.param_str_) self._num_classes = layer_params['num_classes'] self._name_to_top_map = &#123;&#125; # data blob: holds a batch of N images, each with 3 channels idx = 0 top[idx].reshape(cfg.TRAIN.IMS_PER_BATCH, 3, max(cfg.TRAIN.SCALES), cfg.TRAIN.MAX_SIZE) self._name_to_top_map['data'] = idx idx += 1 if cfg.TRAIN.HAS_RPN: top[idx].reshape(1, 3) self._name_to_top_map['im_info'] = idx idx += 1 top[idx].reshape(1, 4) self._name_to_top_map['gt_boxes'] = idx idx += 1 else: # not using RPN # rois blob: holds R regions of interest, each is a 5-tuple # (n, x1, y1, x2, y2) specifying an image batch index n and a # rectangle (x1, y1, x2, y2) top[idx].reshape(1, 5) self._name_to_top_map['rois'] = idx idx += 1 # labels blob: R categorical labels in [0, ..., K] for K foreground # classes plus background top[idx].reshape(1) self._name_to_top_map['labels'] = idx idx += 1 if cfg.TRAIN.BBOX_REG: # bbox_targets blob: R bounding-box regression targets with 4 # targets per class top[idx].reshape(1, self._num_classes * 4) self._name_to_top_map['bbox_targets'] = idx idx += 1 # bbox_inside_weights blob: At most 4 targets per roi are active; # thisbinary vector sepcifies the subset of active targets top[idx].reshape(1, self._num_classes * 4) self._name_to_top_map['bbox_inside_weights'] = idx idx += 1 top[idx].reshape(1, self._num_classes * 4) self._name_to_top_map['bbox_outside_weights'] = idx idx += 1 print 'RoiDataLayer: name_to_top:', self._name_to_top_map assert len(top) == len(self._name_to_top_map) 可以看到，这里主要建立了一个字典_name_to_top_map，用来存放一种关系——blob的name（key）及其在top中对应的顺序。在训练rpn时候roi为gt，在训练fast-rcnn时候roi为rpn框+gt.因为我们在写网络时，可能不清楚这个顺序，只知道输入blob的name，如data、rois、labels等，因此在给网络中的blob（top）赋值的时候，依据的智能是作为key的name。（为什么不直接把top建立为dictionary呢？）。 接下来是forward()： 12345678910def forward(self, bottom, top): """Get blobs and copy them into this layer's top blob vector.""" blobs = self._get_next_minibatch() for blob_name, blob in blobs.iteritems(): top_ind = self._name_to_top_map[blob_name] # Reshape net's input blobs top[top_ind].reshape(*(blob.shape)) # Copy data into net's input blobs top[top_ind].data[...] = blob.astype(np.float32, copy=False) 即根据blob的name找到对应的top，然后reshape为同样的size，最后赋值。这样我们就将初始的数据加载到网络中了（虽然在生成proposal时没有用到这一点，但是很快就会用到）。 实际上在传给网络之前，已经将roidb改过名字，然后才变成blob。forward()中的第一句，看一下函数_get_next_minibatch()：123456789101112def _get_next_minibatch(self): """Return the blobs to be used for the next minibatch. If cfg.TRAIN.USE_PREFETCH is True, then blobs will be computed in a separate process and made available through self._blob_queue. """ if cfg.TRAIN.USE_PREFETCH: return self._blob_queue.get() else: db_inds = self._get_next_minibatch_inds() minibatch_db = [self._roidb[i] for i in db_inds] return get_minibatch(minibatch_db, self._num_classes) 接下来这个函数 非常重要！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def get_minibatch(roidb, num_classes): """Given a roidb, construct a minibatch sampled from it.""" num_images = len(roidb) # Sample random scales to use for each image in this batch random_scale_inds = npr.randint(0, high=len(cfg.TRAIN.SCALES), size=num_images) assert(cfg.TRAIN.BATCH_SIZE % num_images == 0), \ 'num_images (&#123;&#125;) must divide BATCH_SIZE (&#123;&#125;)'. \ format(num_images, cfg.TRAIN.BATCH_SIZE) rois_per_image = cfg.TRAIN.BATCH_SIZE / num_images fg_rois_per_image = np.round(cfg.TRAIN.FG_FRACTION * rois_per_image) # Get the input image blob, formatted for caffe im_blob, im_scales = _get_image_blob(roidb, random_scale_inds) blobs = &#123;'data': im_blob&#125; if cfg.TRAIN.HAS_RPN: assert len(im_scales) == 1, "Single batch only" assert len(roidb) == 1, "Single batch only" # gt boxes: (x1, y1, x2, y2, cls) gt_inds = np.where(roidb[0]['gt_classes'] != 0)[0] gt_boxes = np.empty((len(gt_inds), 5), dtype=np.float32) gt_boxes[:, 0:4] = roidb[0]['boxes'][gt_inds, :] * im_scales[0] gt_boxes[:, 4] = roidb[0]['gt_classes'][gt_inds] blobs['gt_boxes'] = gt_boxes blobs['im_info'] = np.array( [[im_blob.shape[2], im_blob.shape[3], im_scales[0]]], dtype=np.float32) else: # not using RPN # Now, build the region of interest and label blobs rois_blob = np.zeros((0, 5), dtype=np.float32) labels_blob = np.zeros((0), dtype=np.float32) bbox_targets_blob = np.zeros((0, 4 * num_classes), dtype=np.float32) bbox_inside_blob = np.zeros(bbox_targets_blob.shape, dtype=np.float32) # all_overlaps = [] for im_i in xrange(num_images): labels, overlaps, im_rois, bbox_targets, bbox_inside_weights \ = _sample_rois(roidb[im_i], fg_rois_per_image, rois_per_image, num_classes) # Add to RoIs blob rois = _project_im_rois(im_rois, im_scales[im_i]) batch_ind = im_i * np.ones((rois.shape[0], 1)) rois_blob_this_image = np.hstack((batch_ind, rois)) rois_blob = np.vstack((rois_blob, rois_blob_this_image)) # Add to labels, bbox targets, and bbox loss blobs labels_blob = np.hstack((labels_blob, labels)) bbox_targets_blob = np.vstack((bbox_targets_blob, bbox_targets)) bbox_inside_blob = np.vstack((bbox_inside_blob, bbox_inside_weights)) # all_overlaps = np.hstack((all_overlaps, overlaps)) # For debug visualizations # _vis_minibatch(im_blob, rois_blob, labels_blob, all_overlaps) blobs['rois'] = rois_blob blobs['labels'] = labels_blob if cfg.TRAIN.BBOX_REG: blobs['bbox_targets'] = bbox_targets_blob blobs['bbox_inside_weights'] = bbox_inside_blob blobs['bbox_outside_weights'] = \ np.array(bbox_inside_blob &gt; 0).astype(np.float32) return blobs 对于原图，可以看出无论是否使用rpn，都将对图片进行规范，即由原图0 resize到原图1，然后加载到网络中的data为原图1.在使用rpn时（cfg.TRAIN.HAS_RPN = Ture），需要得到resize的信息，因为需要gt_boxes，而这些框的标注是基于原图0，所以需要将其对应地规范到原图1。在train_rpn()阶段如此，在rpn_proposal()阶段也是如此，需要将proposals还原到原图0的尺寸，以便后面和gt_roidb合并到一起。而不使用rpn时（cfg.TRAIN.HAS_RPN = False），虽然也对图片进行规范，但是不需要知道这些信息。因为gt_boxes和proposals都相应地规范。 对于标注框：在使用rpn时，没有对标注框进行规范，因为需要求偏移量（train_rpn），需要根据偏移量得到proposals（rpn_generate），并将其和gt_roidb保存到一起，而后者是基于原图0进行标注的，因此需要保持尺度（gt_roidb、偏移量、proposals）的一致性。在不使用rpn时（train_fast_crnn），由于目的是训练网络，不需要对标注性的文件、数据进行操作，因此直接对标注框进行了规范。 1234def _project_im_rois(im_rois, im_scale_factor): """Project image RoIs into the rescaled training image.""" rois = im_rois * im_scale_factor return rois 12345678910111213141516171819202122232425262728293031323334353637383940def _get_image_blob(roidb, scale_inds): """Builds an input blob from the images in the roidb at the specified scales. """ num_images = len(roidb) processed_ims = [] im_scales = [] for i in range(num_images): im = cv2.imread(roidb[i]['image']) if roidb[i]['flipped']: im = im[:, ::-1, :] target_size = cfg.TRAIN.SCALES[scale_inds[i]] im, im_scale = prep_im_for_blob(im, cfg.PIXEL_MEANS, target_size, cfg.TRAIN.MAX_SIZE) im_scales.append(im_scale) processed_ims.append(im) # Create a blob to hold the input images blob = im_list_to_blob(processed_ims) return blob, im_scales ## 该函数的作用是将opencv读进来的image格式转换为caffe中的image格式，即[n,c,h,w]def im_list_to_blob(ims): """Convert a list of images into a network input. Assumes images are already prepared (means subtracted, BGR order, ...). """ max_shape = np.array([im.shape for im in ims]).max(axis=0) num_images = len(ims) blob = np.zeros((num_images, max_shape[0], max_shape[1], 3), dtype=np.float32) for i in range(num_images): im = ims[i] blob[i, 0:im.shape[0], 0:im.shape[1], :] = im # Move channels (axis 3) to axis 1 # Axis order will become: (batch elem, channel, height, width) channel_swap = (0, 3, 1, 2) blob = blob.transpose(channel_swap) return blob roidb blob ‘boxes’ ‘rois’ ‘max_classes’ ‘labels’ 由函数add_bbox_regression_targets()添加 ‘bbox_targets’]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster rcnn】主函数]]></title>
    <url>%2F2018%2F07%2F08%2F%E3%80%90faster%20rcnn%E3%80%91%E4%B8%BB%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[今天开始写faster rcnn的源码解析。从主函数开始，如果中间的一些细节需要展开，会单独写成一篇文章，主要的流程还是在这篇文章。 首先定义：最原始的图像记为原图0，经过resize的、作为网络输入的图像记为原图1。1234567891011121314151617181920212223if __name__ == '__main__': args = parse_args() print('Called with args:') print(args) if args.cfg_file is not None: cfg_from_file(args.cfg_file) if args.set_cfgs is not None: cfg_from_list(args.set_cfgs) cfg.GPU_ID = args.gpu_id # -------------------------------------------------------------------------- # Pycaffe doesn't reliably free GPU memory when instantiated nets are # discarded (e.g. "del net" in Python code). To work around this issue, each # training stage is executed in a separate process using # multiprocessing.Process. # -------------------------------------------------------------------------- # queue for communicated results between processes mp_queue = mp.Queue() # solves, iters, etc. for each training stage solvers, max_iters, rpn_test_prototxt = get_solvers(args.net_name) 看一下函数get_solvers(net_name)： 12345678910111213141516def get_solvers(net_name): # Faster R-CNN Alternating Optimization n = 'faster_rcnn_alt_opt' # Solver for each training stage solvers = [[net_name, n, 'stage1_rpn_solver60k80k.pt'], [net_name, n, 'stage1_fast_rcnn_solver30k40k.pt'], [net_name, n, 'stage2_rpn_solver60k80k.pt'], [net_name, n, 'stage2_fast_rcnn_solver30k40k.pt']] solvers = [os.path.join(cfg.MODELS_DIR, *s) for s in solvers] # Iterations for each training stage max_iters = [80000, 40000, 80000, 40000] # max_iters = [100, 100, 100, 100] # Test prototxt for the RPN rpn_test_prototxt = os.path.join( cfg.MODELS_DIR, net_name, n, 'rpn_test.pt') return solvers, max_iters, rpn_test_prototxt 该函数针对faster-rcnn训练的四个阶段，将每个阶段用到的solver、训练参数max_iters、以及用于测试的网络模型等信息进行相应地提取。回到main函数： 12345678910111213141516print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 1 RPN, init from ImageNet model')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~') cfg.TRAIN.SNAPSHOT_INFIX = 'stage1'mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, init_model=args.pretrained_model, solver=solvers[0], max_iters=max_iters[0], cfg=cfg)p = mp.Process(target=train_rpn, kwargs=mp_kwargs)p.start()rpn_stage1_out = mp_queue.get()p.join() 上述代码段的作用是：根据原始的gt_roidb训练rpn。该部分主要是设置参数，如给定网络结构信息、参数信息、训练信息等，然后通过mp.Process执行函数。进入train_rpn()函数： 12345678910111213141516171819202122232425262728293031def train_rpn(queue=None, imdb_name=None, init_model=None, solver=None, max_iters=None, cfg=None): """Train a Region Proposal Network in a separate training process. """ # Not using any proposals, just ground-truth boxes cfg.TRAIN.HAS_RPN = True cfg.TRAIN.BBOX_REG = False # applies only to Fast R-CNN bbox regression cfg.TRAIN.PROPOSAL_METHOD = 'gt' cfg.TRAIN.IMS_PER_BATCH = 1 print ('Init model: &#123;&#125;'.format(init_model)) print('Using config:') pprint.pprint(cfg) import caffe _init_caffe(cfg) roidb, imdb = get_roidb(imdb_name) print ('roidb len: &#123;&#125;'.format(len(roidb))) output_dir = get_output_dir(imdb) print ('Output will be saved to `&#123;:s&#125;`'.format(output_dir)) model_paths = train_net(solver, roidb, output_dir, pretrained_model=init_model, max_iters=max_iters) # Cleanup all but the final model for i in model_paths[:-1]: os.remove(i) rpn_model_path = model_paths[-1] # Send final model path through the multiprocessing queue queue.put(&#123;'model_path': rpn_model_path&#125;) 该函数的前面部分是仍然是设置参数，然后得到训练数据roidb和原始数据的classimdb，具体可以看get_roidb的解析。接下来利用数据roidb训练网络，roidb的格式如下：1234567891011roidb = [dic]dic_i = &#123;'boxes' : boxes, 'gt_classes': gt_classes, 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : seg_areas 'image' : imdb.image_path_at(i) 'width' : sizes[i][0] 'height' : sizes[i][1] 'max_classes' : max_classes 'max_overlaps' : max_overlaps&#125; 进入函数train_net()：123456789101112131415161718192021222324252627282930313233343536373839def train_net(solver_prototxt, roidb, output_dir, pretrained_model=None, max_iters=40000): """Train a Fast R-CNN network.""" roidb = filter_roidb(roidb) sw = SolverWrapper(solver_prototxt, roidb, output_dir, pretrained_model=pretrained_model) print ('Solving...') model_paths = sw.train_model(max_iters) print ('done solving') return model_paths ##-----------------------------------------------------------------##----------------------------------------------------------------- def filter_roidb(roidb): """Remove roidb entries that have no usable RoIs.""" def is_valid(entry): # Valid images have: # (1) At least one foreground RoI OR # (2) At least one background RoI overlaps = entry['max_overlaps'] # find boxes with sufficient overlap fg_inds = np.where(overlaps &gt;= cfg.TRAIN.FG_THRESH)[0] # Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI) bg_inds = np.where((overlaps &lt; cfg.TRAIN.BG_THRESH_HI) &amp; (overlaps &gt;= cfg.TRAIN.BG_THRESH_LO))[0] # image is only valid if such boxes exist valid = len(fg_inds) &gt; 0 or len(bg_inds) &gt; 0 return valid num = len(roidb) filtered_roidb = [entry for entry in roidb if is_valid(entry)] num_after = len(filtered_roidb) print ('Filtered &#123;&#125; roidb entries: &#123;&#125; -&gt; &#123;&#125;'.format(num - num_after, num, num_after)) return filtered_roidb 再说roidb的数据结构，其中的max_overlaps是（一张）图片中每个obj对应的最大overlaps，维度是(num_objs,)，在这里先粗略判断图片是否有效，仅加载有效的图片用于训练。‘有效’的定义是：至少有一个前景或者一个背景box。具体看一下SolverWrapper这个类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293class SolverWrapper(object): """A simple wrapper around Caffe's solver. This wrapper gives us control over he snapshotting process, which we use to unnormalize the learned bounding-box regression weights. """ def __init__(self, solver_prototxt, roidb, output_dir, pretrained_model=None): """Initialize the SolverWrapper.""" self.output_dir = output_dir if (cfg.TRAIN.HAS_RPN and cfg.TRAIN.BBOX_REG and cfg.TRAIN.BBOX_NORMALIZE_TARGETS): # RPN can only use precomputed normalization because there are no # fixed statistics to compute a priori assert cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED if cfg.TRAIN.BBOX_REG: print ('Computing bounding-box regression targets...') self.bbox_means, self.bbox_stds = \ rdl_roidb.add_bbox_regression_targets(roidb) print ('done') self.solver = caffe.SGDSolver(solver_prototxt) if pretrained_model is not None: print ('Loading pretrained model ' 'weights from &#123;:s&#125;').format(pretrained_model) self.solver.net.copy_from(pretrained_model) self.solver_param = caffe_pb2.SolverParameter() with open(solver_prototxt, 'rt') as f: pb2.text_format.Merge(f.read(), self.solver_param) # 根据roi_data_layer.layer文件中的set_roidb函数来对roidb进行随机打乱 self.solver.net.layers[0].set_roidb(roidb) def snapshot(self): """Take a snapshot of the network after unnormalizing the learned bounding-box regression weights. This enables easy use at test-time. """ net = self.solver.net scale_bbox_params = (cfg.TRAIN.BBOX_REG and cfg.TRAIN.BBOX_NORMALIZE_TARGETS and net.params.has_key('bbox_pred')) if scale_bbox_params: # save original values orig_0 = net.params['bbox_pred'][0].data.copy() orig_1 = net.params['bbox_pred'][1].data.copy() # scale and shift with bbox reg unnormalization; then save snapshot net.params['bbox_pred'][0].data[...] = \ (net.params['bbox_pred'][0].data * self.bbox_stds[:, np.newaxis]) net.params['bbox_pred'][1].data[...] = \ (net.params['bbox_pred'][1].data * self.bbox_stds + self.bbox_means) infix = ('_' + cfg.TRAIN.SNAPSHOT_INFIX if cfg.TRAIN.SNAPSHOT_INFIX != '' else '') filename = (self.solver_param.snapshot_prefix + infix + '_iter_&#123;:d&#125;'.format(self.solver.iter) + '.caffemodel') filename = os.path.join(self.output_dir, filename) net.save(str(filename)) print ('Wrote snapshot to: &#123;:s&#125;'.format(filename)) if scale_bbox_params: # restore net to original state net.params['bbox_pred'][0].data[...] = orig_0 net.params['bbox_pred'][1].data[...] = orig_1 return filename def train_model(self, max_iters): """Network training loop.""" last_snapshot_iter = -1 timer = Timer() model_paths = [] while self.solver.iter &lt; max_iters: # Make one SGD update timer.tic() self.solver.step(1) timer.toc() if self.solver.iter % (10 * self.solver_param.display) == 0: print ('speed: &#123;:.3f&#125;s / iter'.format(timer.average_time)) if self.solver.iter % cfg.TRAIN.SNAPSHOT_ITERS == 0: last_snapshot_iter = self.solver.iter model_paths.append(self.snapshot()) if last_snapshot_iter != self.solver.iter: model_paths.append(self.snapshot()) return model_paths 上述代码的主要作用： 在特定的iterations进行display； 在特定的iterations提取snapshot的结果，然后加载到model_path。最后返回包含一系列snapshot存储的model参数的路径model_paths。取最后一次存储的model_path作为后续生成proposals的网络参数：rpn_model_path = model_paths[-1]。 这个函数在后面每个训练阶段都会用到。 小结： 上述代码的作用主要是：根据原始数据imdb，训练rpn，其中用到的特殊的自定义网络有RoIDataLayer（cfg.TRAIN.HAS_RPN = True），AnchorTargetLayer。前者是为了更好地加载数据，后者的作用是： 通过标注的gt_boxes，对标准的原图1尺度下的一套anchors进行筛选、标注（fg/bg）和修正（regression），这些信息用于rpn的反馈，以便构成闭环，训练rpn。 该步骤之后，得到一个功能性网络。该网络能够能够自主判断feature map上每个像素点（特征点）为fg还是bg；能够在标准anchor（与shifts框架结合之后）的基础上对其进行修正，生成更加符合实际的boxes，即proposals。接下来用上一步训练的rpn生成proposal： 1234567891011121314print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 1 RPN, generate proposals')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~') mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, rpn_model_path=str(rpn_stage1_out['model_path']), cfg=cfg, rpn_test_prototxt=rpn_test_prototxt)p = mp.Process(target=rpn_generate, kwargs=mp_kwargs)p.start()rpn_stage1_out['proposal_path'] = mp_queue.get()['proposal_path']p.join() 主要看一下函数rpn_generate：1234567891011121314151617181920212223242526272829303132333435def rpn_generate(queue=None, imdb_name=None, rpn_model_path=None, cfg=None, rpn_test_prototxt=None): """Use a trained RPN to generate proposals. """ cfg.TEST.RPN_PRE_NMS_TOP_N = -1 # no pre NMS filtering cfg.TEST.RPN_POST_NMS_TOP_N = 2000 # limit top boxes after NMS print ('RPN model: &#123;&#125;'.format(rpn_model_path)) print('Using config:') pprint.pprint(cfg) import caffe _init_caffe(cfg) # NOTE: the matlab implementation computes proposals on flipped images, too. # We compute them on the image once and then flip the already computed # proposals. This might cause a minor loss in mAP (less proposal jittering). imdb = get_imdb(imdb_name) print ('Loaded dataset `&#123;:s&#125;` for proposal generation'.format(imdb.name)) # Load RPN and configure output directory rpn_net = caffe.Net(rpn_test_prototxt, rpn_model_path, caffe.TEST) output_dir = get_output_dir(imdb) print ('Output will be saved to `&#123;:s&#125;`'.format(output_dir)) # Generate proposals on the imdb rpn_proposals = imdb_proposals(rpn_net, imdb) # Write proposals to disk and send the proposal file path through the # multiprocessing queue rpn_net_name = os.path.splitext(os.path.basename(rpn_model_path))[0] rpn_proposals_path = os.path.join( output_dir, rpn_net_name + '_proposals.pkl') with open(rpn_proposals_path, 'wb') as f: cPickle.dump(rpn_proposals, f, cPickle.HIGHEST_PROTOCOL) print ('Wrote RPN proposals to &#123;&#125;'.format(rpn_proposals_path)) queue.put(&#123;'proposal_path': rpn_proposals_path&#125;) 注意该函数的两个参数：rpn_model_path是网络的参数，即.caffemodel文件，由上一步训练得出；rpn_test_prototxt是网络结构的定义【该网络的主体结构与train_rpn完全相同】。该函数前半部分是得到原始数据集的classimdb（同上一阶段），根据rpn网络的地址加载网络rpn_net。接下来是函数imdb_proposals(rpn_net, imdb)，进入该函数发现其主要作用是加载数据集imdb，并对每张图片通过函数im_proposals(net, im)得到proposals。（该部分具体可以参考proposals）。 该阶段后，生成fg/bg特征明显的，面积较大的roi。 1234567891011121314151617print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 1 Fast R-CNN using RPN proposals, init from ImageNet model')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~') cfg.TRAIN.SNAPSHOT_INFIX = 'stage1'mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, init_model=args.pretrained_model, solver=solvers[1], max_iters=max_iters[1], cfg=cfg, rpn_file=rpn_stage1_out['proposal_path'])p = mp.Process(target=train_fast_rcnn, kwargs=mp_kwargs)p.start()fast_rcnn_stage1_out = mp_queue.get()p.join() 该步骤利用rpn生成的proposals和标注的gt框，对fast rcnn进行训练。（主要看网络的输入、输入以及数据流的分支、汇合部分。） 在训练阶段，该部分（fast rcnn）的网络结构为： 在测试阶段，以及最后的应用的阶段，faster rcnn的网络结构为： 可以看到相较于之前，这里新出现了一个roi_pooling_layer，这是caffe官方所没有的、由作者新添加的层，在roi_pooling_layer.cpp中实现（位于~/py-faster-rcnn/caffe-fast-rcnn/src/caffe/layers/roi_pooling_layer.cpp）。关于这个layer的理解，可以参考roi_pooling_layer。 看一下函数train_fast_rcnn()： 1234567891011121314151617181920212223242526272829def train_fast_rcnn(queue=None, imdb_name=None, init_model=None, solver=None, max_iters=None, cfg=None, rpn_file=None): """Train a Fast R-CNN using proposals generated by an RPN. """ cfg.TRAIN.HAS_RPN = False # not generating prosals on-the-fly cfg.TRAIN.PROPOSAL_METHOD = 'rpn' # use pre-computed RPN proposals instead cfg.TRAIN.IMS_PER_BATCH = 2 print ('Init model: &#123;&#125;'.format(init_model)) print ('RPN proposals: &#123;&#125;'.format(rpn_file)) print('Using config:') pprint.pprint(cfg) import caffe _init_caffe(cfg) roidb, imdb = get_roidb(imdb_name, rpn_file=rpn_file) output_dir = get_output_dir(imdb) print ('Output will be saved to `&#123;:s&#125;`'.format(output_dir)) # Train Fast R-CNN model_paths = train_net(solver, roidb, output_dir, pretrained_model=init_model, max_iters=max_iters) # Cleanup all but the final model for i in model_paths[:-1]: os.remove(i) fast_rcnn_model_path = model_paths[-1] # Send Fast R-CNN model path over the multiprocessing queue queue.put(&#123;'model_path': fast_rcnn_model_path&#125;) 小结 该函数同train_rpn()套路一样，都是先通过特定的方法（此处为rpn_roidb）得到roidb，然后加载网络结构、网络参数、以及roidb进行训练，最终返回最后一次iter保存的.caffemodel文件。该阶段用到的特殊的自定义的网络有RoIDataLayer（cfg.TRAIN.HAS_RPN = False），和roi_pooling_layer。 下面是stage2的训练流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 2 RPN, init from stage 1 Fast R-CNN model')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')cfg.TRAIN.SNAPSHOT_INFIX = 'stage2'mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, init_model=str(fast_rcnn_stage1_out['model_path']), solver=solvers[2], max_iters=max_iters[2], cfg=cfg)p = mp.Process(target=train_rpn, kwargs=mp_kwargs)p.start()rpn_stage2_out = mp_queue.get()p.join()print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 2 RPN, generate proposals')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, rpn_model_path=str(rpn_stage2_out['model_path']), cfg=cfg, rpn_test_prototxt=rpn_test_prototxt)p = mp.Process(target=rpn_generate, kwargs=mp_kwargs)p.start()rpn_stage2_out['proposal_path'] = mp_queue.get()['proposal_path']p.join()print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')print ('Stage 2 Fast R-CNN, init from stage 2 RPN R-CNN model')print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')cfg.TRAIN.SNAPSHOT_INFIX = 'stage2'mp_kwargs = dict( queue=mp_queue, imdb_name=args.imdb_name, init_model=str(rpn_stage2_out['model_path']), solver=solvers[3], max_iters=max_iters[3], cfg=cfg, rpn_file=rpn_stage2_out['proposal_path'])p = mp.Process(target=train_fast_rcnn, kwargs=mp_kwargs)p.start()fast_rcnn_stage2_out = mp_queue.get()p.join() # Create final model (just a copy of the last stage)final_path = os.path.join( os.path.dirname(fast_rcnn_stage2_out['model_path']), args.net_name + '_faster_rcnn_final.caffemodel')print ('cp &#123;&#125; -&gt; &#123;&#125;'.format( fast_rcnn_stage2_out['model_path'], final_path))shutil.copy(fast_rcnn_stage2_out['model_path'], final_path)print ('Final model: &#123;&#125;'.format(final_path)) stage2的训练流程与stage1大同小异，不再赘述。只强调一点： 通过.prototxt文件可以看出，训练流程的控制可以通过lr（learning rate）来实现： conv1-2 conv3-4-5 rpn fc6-7 stage1-1 0 !0 !0 0 stage1-2 0 !0 0 !0 stage2-1 0 0 !0 0 stage2-2 0 0 0 !0 在训练的全过程，conv1和conv2的参数都采用pretrained获取的参数； conv3、4、5的参数在stage1进行调整，stage2保持固定； rpn在每个阶段的前半部分进行调整，fc6-7在每个阶段的后半部分进行调整； 这里的rpn是指其相对于fast rcnn所独有的网络层。 一定要对数据本身有具体的概念，贯穿整个算法，数据流如何变化，这点很重要。 算法中常用算子的数据结构； 每一部分的作用，对数据流的改变。 对数据结构的理解，可以带动对算法本身的理解。 小结 阶段与网络：每个阶段，准备数据，加载网络，训练网络，网络输出，提取有用信息，保存。 总结与展望 faster rcnn是我在machine learning和deep learning仔细研读的第一篇文章，其源码规模之大也是我第一次认真研读的。之所以从faster rcnn入手，我觉得有一下几个原因： 作为一个two stage的方法，对于新人而言，足够折腾，所以弄清楚这个过程对于后面其他算法的学习有很大帮助； detection作为recognition和segmentation的过渡，可以起到承上启下的作用，通过他可以了解那些著名的网络，比如Resnet，是如何脱离recognition问题广泛地应用到ML的其他问题。同时，还有一个用于segmentation的算法，mask-rcnn，作为kaiming出品，这一系列算法本身也具有连续性，Resnet——Faster Rcnn——Mask Rcnn。 有些东西，要想去雕琢，总会有新东西呈现，这个系列的文章也是如此。该文章是我在现有水平下对这篇文章尽力地研读，文章是写完了，但还有一些疑问和不解有待攻克，有些是我现在能够意识到的，比如数据流、数据结构的统一总结，输出层损失函数的对比等，受限于时间和精力只好暂时搁置，等到面对的时候有信心解决。还有一些是因为水平和眼界有限，我没有意识到的，这些需要以后的长久积累，我相信有一天会拿他当艺术品一样去慢慢欣赏。 一点情怀：这个系列的文章是我学习深度学习以来的第一部“巨作”，加上这篇文章一共有七篇。以前没想过会写一个系列，也不相信能写出来，单最后还是写出来了，我觉得有几个原因： ML这个方向对我的冲击非常强烈，有很多奇妙的思想、算法，以及他们背后的巧妙如工艺品一般的实现，让我有很强的分享欲； 在学习的过程中，参考了很多前辈总结的教程，有关于论文的、源码的，有关于整体宏观把握的，也有对某个细节详尽分析的，他们就像一个个领路人，让我倍感鼓舞。 因此最后决定把欲望落地为文章，把文章进行规范，第一部“巨作”由此诞生。 PS：本系列文章参考教程巨多，期间由于重装系统，导致浏览器书签丢失，无法一一列出，在此一并表示感谢。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster rcnn】proposal]]></title>
    <url>%2F2018%2F07%2F08%2F%E3%80%90faster%20rcnn%E3%80%91proposal%2F</url>
    <content type="text"><![CDATA[首先看一下函数imdb_proposals： 1234567891011121314151617def imdb_proposals(net, imdb): """Generate RPN proposals on all images in an imdb.""" _t = Timer() imdb_boxes = [[] for _ in range(imdb.num_images)] for i in range(imdb.num_images): im = cv2.imread(imdb.image_path_at(i)) _t.tic() imdb_boxes[i], scores = im_proposals(net, im) _t.toc() print 'im_proposals: &#123;:d&#125;/&#123;:d&#125; &#123;:.3f&#125;s' \ .format(i + 1, imdb.num_images, _t.average_time) if 0: dets = np.hstack((imdb_boxes[i], scores)) # from IPython import embed; embed() _vis_proposals(im, dets[:3, :], thresh=0.9) plt.show() return imdb_boxes 其主要作用是加载数据集imdb，并对每张图片通过函数im_proposals(net, im)得到proposals。 这里的im即为每张图片。然后是im_proposals(net, im)函数。进入该函数之前，先看一下函数_get_image_blob：根据设定的训练参数cfg.TEST.SCALES[0]和cfg.TEST.MAX_SIZE对图像resize，在满足“最大尺寸不超过标准”的情况下（原因？），使得图片尽可能大，同时存储resize的尺寸scale： 1234567891011121314151617181920212223242526272829303132333435def _get_image_blob(im): """Converts an image into a network input. Arguments: im (ndarray): a color image in BGR order Returns: blob (ndarray): a data blob holding an image pyramid im_scale_factors (list): list of image scales (relative to im) used in the image pyramid """ im_orig = im.astype(np.float32, copy=True) im_orig -= cfg.PIXEL_MEANS im_shape = im_orig.shape im_size_min = np.min(im_shape[0:2]) im_size_max = np.max(im_shape[0:2]) processed_ims = [] assert len(cfg.TEST.SCALES) == 1 target_size = cfg.TEST.SCALES[0] im_scale = float(target_size) / float(im_size_min) # Prevent the biggest axis from being more than MAX_SIZE if np.round(im_scale * im_size_max) &gt; cfg.TEST.MAX_SIZE: im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max) im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR) im_info = np.hstack((im.shape[:2], im_scale))[np.newaxis, :] processed_ims.append(im) # Create a blob to hold the input images blob = im_list_to_blob(processed_ims) return blob, im_info 其中im_size_min和im_size_max分别为图片的最大边和最小边，之所以用im_shape[0:2]，应该是和opencv的图像存储格式有关。 im_info的数据结构可以通过下列尝试看出： 这个函数的最后，im_info存放了经过resize的图片的尺寸信息（width、length）和缩放尺寸（scale）；blob存放经过resize的图片序列（因为每个数据集，训练集、验证集、测试集都不止一张图片）。 注意： 原图resize后放入网络开始训练，注意与feature_stride的区别； 由于每张图片的大小不一样，但是标准一样，所以scale也不一样。 接下来进入函数im_proposals(net, im)： 1234567891011121314def im_proposals(net, im): """Generate RPN proposals on a single image.""" blobs = &#123;&#125; blobs['data'], blobs['im_info'] = _get_image_blob(im) net.blobs['data'].reshape(*(blobs['data'].shape)) net.blobs['im_info'].reshape(*(blobs['im_info'].shape)) blobs_out = net.forward( data=blobs['data'].astype(np.float32, copy=False), im_info=blobs['im_info'].astype(np.float32, copy=False)) scale = blobs['im_info'][0, 2] boxes = blobs_out['rois'][:, 1:].copy() / scale scores = blobs_out['scores'].copy() return boxes, scores 通过这段代码，可以看出生成的proposals是原图0的尺寸，因为他在后面要和gt_boxes合并到一起，所以需要同gt_boxes处于同一个尺度。 在得到经过resize的image以及resize操作的相关信息im_info后，利用这些信息对网络的数据层进行reshape。因为我们想以网路的形式输出数据（image、gt_box、roidb等）。关于blob的调用方式net.blobs[&#39;data&#39;]和net.blobs[&#39;im_info&#39;]，可以参看python接口获取网络中的数据信息。这里的net是根据前面的代码rpn_net = caffe.Net(rpn_test_prototxt, rpn_model_path, caffe.TEST)来定义的，rpn_test_prototxt由get_solvers()输出，在这里为rpn_test.pt文件。接下来是函数net.forward()，一度让我很头疼，因为在pycharm中查看其定义，结果弹出来几十条。后来想到这跟具体的网络有关，而网络的前向函数net.forward()又调用到了每个层的layer.forward()。（参考）所以接下来要查看rpn_test.pt中的第一层——数据层： input: &quot;data&quot; input_shape { dim: 1 dim: 3 dim: 224 dim: 224 } input: &quot;im_info&quot; input_shape { dim: 1 dim: 3 } 再看一下stage1_fast_rcnn_train.pt的数据层： name: &quot;ZF&quot; layer { name: &apos;data&apos; type: &apos;Python&apos; top: &apos;data&apos; top: &apos;rois&apos; top: &apos;labels&apos; top: &apos;bbox_targets&apos; top: &apos;bbox_inside_weights&apos; top: &apos;bbox_outside_weights&apos; python_param { module: &apos;roi_data_layer.layer&apos; layer: &apos;RoIDataLayer&apos; param_str: &quot;&apos;num_classes&apos;: 21&quot; } } 可以看到它是一个自定义的层，就是layer.py中的class RoIDataLayer(caffe.Layer)，具体细节可以参考网络数据的投喂。 回到函数im_proposals(net, im)，通过net.forward()得到blobs_out（blobs_out=self.outputs()，返回的应该是网络输出所有的blob，key和value解读_caffe.cpp和pycaffe.py）之后，提取我们想要的信息boxes和scores： 1234scale = blobs['im_info'][0, 2]boxes = blobs_out['rois'][:, 1:].copy() / scalescores = blobs_out['scores'].copy()return boxes, scores 要理解这一点，还得回到网络，先看一下这一部分（blob的key为&#39;rois&#39;和&#39;scores&#39;）的数据流： 在红框标注，18ch表示有18个channels，15 15 表示feature map的尺寸。经过reshape层，变为2channels，15 135 的大小。其中reshape层的使用方法如下： layer { name: &quot;reshape&quot; type: &quot;Reshape&quot; bottom: &quot;input&quot; top: &quot;output&quot; reshape_param { shape { dim: 0 # copy the dimension from below dim: 2 dim: 3 dim: -1 # infer it from the other dimensions } } } 经过conv_1~conv_5之后，在经过rpn_conv，得到两路数据，一路是4 9(anchors)的boxes_regression，另一路是2(bg/fg) 9(anchors)的scores。 anchor的数据结构，在generate_anchors.py中可以获得。 然后看一下最后的输出层，如何根据rpn_cls_prob_reshape、rpn_bbox_pred和im_info得到最后的结果:rois和scores。主要看ProposalLayer的forward()部分： 12345678910111213141516171819202122232425262728def forward(self, bottom, top): # Algorithm: # # for each (H, W) location i # generate A anchor boxes centered on cell i # apply predicted bbox deltas at cell i to each of the A anchors # clip predicted boxes to image # remove predicted boxes with either height or width &lt; threshold # sort all (proposal, score) pairs by score from highest to lowest # take top pre_nms_topN proposals before NMS # apply NMS with threshold 0.7 to remaining proposals # take after_nms_topN proposals after NMS # return the top proposals (-&gt; RoIs top, scores top) assert bottom[0].data.shape[0] == 1, \ 'Only single item batches are supported' cfg_key = str(self.phase) # either 'TRAIN' or 'TEST' pre_nms_topN = cfg[cfg_key].RPN_PRE_NMS_TOP_N post_nms_topN = cfg[cfg_key].RPN_POST_NMS_TOP_N nms_thresh = cfg[cfg_key].RPN_NMS_THRESH min_size = cfg[cfg_key].RPN_MIN_SIZE # the first set of _num_anchors channels are bg probs # the second set are the fg probs, which we want scores = bottom[0].data[:, self._num_anchors:, :, :] bbox_deltas = bottom[1].data im_info = bottom[2].data[0, :] 这里bottom[0]为rpn_cls_prob_reshape，bottom[1]为rpn_bbox_pred，bottom[2]为im_info，在bottom[0]中，共有2*_num_anchors个channels，其中_num_anchors=9，所以bottom[0].data的前9个通道为背景概率，后9个为前景的概率，这里我们只取前景概率。另外，info有两个维度，但是只有一组数据（对应一个图片），所以采用.data[0,:]的索引方式。(另猜想：bottom中的变量顺序的含义，由前面网络生成变量的顺序确定？)1234567891011121314151617181920 if DEBUG: print 'im_size: (&#123;&#125;, &#123;&#125;)'.format(im_info[0], im_info[1]) print 'scale: &#123;&#125;'.format(im_info[2]) # 1. Generate proposals from bbox deltas and shifted anchors#### the shape of feature map. #### score is [1,2*9,H,W]height, width = scores.shape[-2:] if DEBUG: print 'score map size: &#123;&#125;'.format(scores.shape) # Enumerate all shifts### the shape of shifts is (width*height)*4shift_x = np.arange(0, width) * self._feat_strideshift_y = np.arange(0, height) * self._feat_strideshift_x, shift_y = np.meshgrid(shift_x, shift_y)shifts = np.vstack((shift_x.ravel(), shift_y.ravel(), shift_x.ravel(), shift_y.ravel())).transpose() 这一段代码的作用是根据feature map以及其相对于原图的缩放尺寸_feat_stride，得到对应于原图的图片框架。shifts的shape为K * 4, K=width * height。 函数ravel()将数组按照行展开（多维情况下按照axis递减的方式展开），并且不改变原数组。 1234567891011# Enumerate all shifted anchors:## add A anchors (1, A, 4) to# cell K shifts (K, 1, 4) to get# shift anchors (K, A, 4)# reshape to (K*A, 4) shifted anchorsA = self._num_anchorsK = shifts.shape[0]anchors = self._anchors.reshape((1, A, 4)) + \ shifts.reshape((1, K, 4)).transpose((1, 0, 2))anchors = anchors.reshape((K * A, 4)) 这一段代码将一套anchor与图片框架相结合，得到了基于框架的anchor。此前的anchor只是一个模板，相对于原点。而框架shifts是基于原图尺寸的、绝对的坐标，之所以将其前两列复制，因为anchor的排列为[左上x，左上y,右上x，右上y]，都需要根据这个基准得到基于原图的anchor。anchor的数据结构： self._anchor由函数generate_anchors()产生，该函数的结果格式如下： 代码方面，这里用到了python的broadcast机制，见附录。 接下来看函数generate_anchors()： 123456789101112def generate_anchors(base_size=16, ratios=[0.5, 1, 2], scales=2**np.arange(3, 6)): """ Generate anchor (reference) windows by enumerating aspect ratios X scales wrt a reference (0, 0, 15, 15) window. """ base_anchor = np.array([1, 1, base_size, base_size]) - 1 ratio_anchors = _ratio_enum(base_anchor, ratios) anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales) for i in range(ratio_anchors.shape[0])]) return anchors 返回结果的排列格式，可以由下面这个函数看出： 12345678910def _whctrs(anchor): """ Return width, height, x center, and y center for an anchor (window). """ w = anchor[2] - anchor[0] + 1 h = anchor[3] - anchor[1] + 1 x_ctr = anchor[0] + 0.5 * (w - 1) y_ctr = anchor[1] + 0.5 * (h - 1) return w, h, x_ctr, y_ctr 可以推断，anchor的排列为：[左上x，左上y,右上x，右上y]；123456789array([[ -83., -39., 100., 56.], # w=184, h=96, ratio=0.5, scale=8 [-175., -87., 192., 104.], # w=368, h=192, ratio=0.5, scale=16 [-359., -183., 376., 200.], # w=736, h=384, ratio=0.5, scale=32 [ -55., -55., 72., 72.], # w=128, h=128, ratio=1.0, scale=8 [-119., -119., 136., 136.], # w=256, h=256, ratio=1.0, scale=16 [-247., -247., 264., 264.], # w=512, h=512, ratio=1.0, scale=32 [ -35., -79., 52., 96.], # w=88, h=176, ratio=2.0, scale=8 [ -79., -167., 96., 184.], # w=176, h=352, ratio=2.0, scale=16 [-167., -343., 184., 360.]]) # w=352, h=704, ratio=2.0, scale=32 123456789101112131415# Transpose and reshape predicted bbox transformations to get them# into the same order as the anchors:## bbox deltas will be (1, 4 * A, H, W) format# transpose to (1, H, W, 4 * A)# reshape to (1 * H * W * A, 4) where rows are ordered by (h, w, a)# in slowest to fastest orderbbox_deltas = bbox_deltas.transpose((0, 2, 3, 1)).reshape((-1, 4)) # Same story for the scores:## scores are (1, A, H, W) format# transpose to (1, H, W, A)# reshape to (1 * H * W * A, 1) where rows are ordered by (h, w, a)scores = scores.transpose((0, 2, 3, 1)).reshape((-1, 1)) 此时的bbox_deltas和scores的存储含义是一致的，第一个axis都对应每个cell的每个anchor。（可参考anchortargetlayer，最后为每个特征点都赋予了fg/bg的概率和偏移量，以便在格式上进行统一）。bbox_deltas由之前的网络的运算结果，作为bottom[1]传递到该层。12# Convert anchors into proposals via bbox transformationsproposals = bbox_transform_inv(anchors, bbox_deltas) anchors作为标准的预测框，bbox_deltas作为标准预测框相对于期待预测框的偏差，然后得到经过修正的框的坐标，即proposals。进入函数bbox_transform_inv()： 1234567891011121314151617181920212223242526272829303132def bbox_transform_inv(boxes, deltas): if boxes.shape[0] == 0: return np.zeros((0, deltas.shape[1]), dtype=deltas.dtype) boxes = boxes.astype(deltas.dtype, copy=False) widths = boxes[:, 2] - boxes[:, 0] + 1.0 heights = boxes[:, 3] - boxes[:, 1] + 1.0 ctr_x = boxes[:, 0] + 0.5 * widths ctr_y = boxes[:, 1] + 0.5 * heights dx = deltas[:, 0::4] dy = deltas[:, 1::4] dw = deltas[:, 2::4] dh = deltas[:, 3::4] pred_ctr_x = dx * widths[:, np.newaxis] + ctr_x[:, np.newaxis] pred_ctr_y = dy * heights[:, np.newaxis] + ctr_y[:, np.newaxis] pred_w = np.exp(dw) * widths[:, np.newaxis] pred_h = np.exp(dh) * heights[:, np.newaxis] pred_boxes = np.zeros(deltas.shape, dtype=deltas.dtype) # x1 pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w # y1 pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h # x2 pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w # y2 pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h return pred_boxes 该段代码对应论文中给出的式子： 可以看出proposals的格式为：N * 4，N一开始为（feature map中特征点个数）×9，后面随着筛选不断减小。 另外，双冒号::的作用可以参考这篇博客。 12345678# 2. clip predicted boxes to imageproposals = clip_boxes(proposals, im_info[:2]) # 3. remove predicted boxes with either height or width &lt; threshold# (NOTE: convert min_size to input image scale stored in im_info[2])keep = _filter_boxes(proposals, min_size * im_info[2])proposals = proposals[keep, :]scores = scores[keep] 得到修正的roi的坐标后【基于所有特征点的完整的一套anchor】，要对其进行修剪（clip），使之在图像的边界范围内，即超过边界的坐标应该被赋予边界值。然后对规范过的roi进行过滤，如果有一个边小于阈值，就将其舍弃，然后得到剩下的proposal的索引keep。然后得到符合要求的proposals的框的坐标proposals和得分scores。 函数clip_boxes()和_filter_boxes()： 123456789101112131415161718192021def clip_boxes(boxes, im_shape): """ Clip boxes to image boundaries. """ # x1 &gt;= 0 boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0) # y1 &gt;= 0 boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0) # x2 &lt; im_shape[1] boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0) # y2 &lt; im_shape[0] boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0) return boxes def _filter_boxes(boxes, min_size): """Remove all boxes with any side smaller than min_size.""" ws = boxes[:, 2] - boxes[:, 0] + 1 hs = boxes[:, 3] - boxes[:, 1] + 1 keep = np.where((ws &gt;= min_size) &amp; (hs &gt;= min_size))[0] return keep 上面只是根据roi的面积对其筛选，接下来是通过scores进行内容层面的筛选，即对规范过的proposals进行筛选——先根据scores筛选一次，然后进行NMS（见附录），接下来再挑选出前面的一部分作为最终的proposals。屡次筛选可以减小后面的计算量。 12345678910111213141516# 4. sort all (proposal, score) pairs by score from highest to lowest# 5. take top pre_nms_topN (e.g. 6000)order = scores.ravel().argsort()[::-1]if pre_nms_topN &gt; 0: order = order[:pre_nms_topN]proposals = proposals[order, :]scores = scores[order] # 6. apply nms (e.g. threshold = 0.7)# 7. take after_nms_topN (e.g. 300)# 8. return the top proposals (-&gt; RoIs top)keep = nms(np.hstack((proposals, scores)), nms_thresh)if post_nms_topN &gt; 0: keep = keep[:post_nms_topN]proposals = proposals[keep, :]scores = scores[keep] 最后，整理计算结果，放入top实现输出。 注意：利用rpn生成proposals时，一次只能输入一张图片。123456789101112# Output rois blob# Our RPN implementation only supports a single input image, # so all batch inds are 0, but it's normal to have more than one proposals.batch_inds = np.zeros((proposals.shape[0], 1), dtype=np.float32)blob = np.hstack((batch_inds, proposals.astype(np.float32, copy=False)))top[0].reshape(*(blob.shape))top[0].data[...] = blob # [Optional] output scores blobif len(top) &gt; 1: top[1].reshape(*(scores.shape)) top[1].data[...] = scores 总结 关于网络： 回到rpn网络结构，定位到最后的输出层： layer { name: &apos;proposal&apos; type: &apos;Python&apos; bottom: &apos;rpn_cls_prob_reshape&apos; bottom: &apos;rpn_bbox_pred&apos; bottom: &apos;im_info&apos; top: &apos;rois&apos; top: &apos;scores&apos; python_param { module: &apos;rpn.proposal_layer&apos; layer: &apos;ProposalLayer&apos; param_str: &quot;&apos;feat_stride&apos;: 16&quot; } } 最原始的图像记为原图0，经过resize的作为网络输入的图像记为原图1.该层的输入为feature map上每个点（此处共15 * 15个）对应的： fg/bg概率：用于后续NMS前后挑选proposals的依据； 相对于标准框的偏移量：根据原图1框架shifts和一套标准的anchor，计算proposals（未经剪裁）； 从原图0到原图1进行resize的操作信息im_info：原图1相对于原图0的比例和原图1的尺寸，作为剪裁和过滤boxes的依据。 输出： rois：参考系为原图1，经过算法修正，NMS等操作后剩余的proposals，作为roi； scores：上述rois对应的fg概率。 另外，由于ProposalLayer没有需要调整的参数，也就是说根据前面网络输出的fg/bg概率（2 9）和框的偏移量（4 9）,就可以得到精简的roi作为proposals，所以该层网络在train_rpn中并不存在，是generate_rpn所独有的网络层。 关于这个stage： 通过语句rpn_proposals = imdb_proposals(rpn_net, imdb)可以看出，在&#39;Stage 1 RPN, generate proposals&#39;这个阶段，由rpn自主生成了一些标注框，但仅仅是这些框的位置信息，别的信息都没有，需要在后续rpn_roidb中得到。 附录 数组的broadcast机制 NMS（non-maximun supress） 其主要思想是依据每个候选框的scores，对其从高到低排序，越靠前的box越重要，然后去除掉‘与重要的框重复过多的候选框’，即如果box_a与box_b相交超过一定比例，并且score_a&gt;score_b，那么保留box_a，舍弃box_b。通过函数cpu_nms()看一下其具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def cpu_nms(np.ndarray[np.float32_t, ndim=2] dets, np.float thresh): cdef np.ndarray[np.float32_t, ndim=1] x1 = dets[:, 0] cdef np.ndarray[np.float32_t, ndim=1] y1 = dets[:, 1] cdef np.ndarray[np.float32_t, ndim=1] x2 = dets[:, 2] cdef np.ndarray[np.float32_t, ndim=1] y2 = dets[:, 3] cdef np.ndarray[np.float32_t, ndim=1] scores = dets[:, 4] cdef np.ndarray[np.float32_t, ndim=1] areas = (x2 - x1 + 1) * (y2 - y1 + 1) cdef np.ndarray[np.int_t, ndim=1] order = scores.argsort()[::-1] cdef int ndets = dets.shape[0] cdef np.ndarray[np.int_t, ndim=1] suppressed = \ np.zeros((ndets), dtype=np.int) # nominal indices cdef int _i, _j # sorted indices cdef int i, j # temp variables for box i's (the box currently under consideration) cdef np.float32_t ix1, iy1, ix2, iy2, iarea # variables for computing overlap with box j (lower scoring box) cdef np.float32_t xx1, yy1, xx2, yy2 cdef np.float32_t w, h cdef np.float32_t inter, ovr keep = [] for _i in range(ndets): i = order[_i] if suppressed[i] == 1: continue keep.append(i) ix1 = x1[i] iy1 = y1[i] ix2 = x2[i] iy2 = y2[i] iarea = areas[i] for _j in range(_i + 1, ndets): j = order[_j] if suppressed[j] == 1: continue xx1 = max(ix1, x1[j]) yy1 = max(iy1, y1[j]) xx2 = min(ix2, x2[j]) yy2 = min(iy2, y2[j]) w = max(0.0, xx2 - xx1 + 1) h = max(0.0, yy2 - yy1 + 1) inter = w * h ovr = inter / (iarea + areas[j] - inter) if ovr &gt;= thresh: suppressed[j] = 1 return keep 由代码可以看出，先根据scores将boxes排序，然后选定前面的box，计算他和后面的box的重叠面积ovr，如果超过阈值thresh，则抑制掉后面的box。其后半部分计算overlaps与之前的代码完全一样，同样地这里的参数thresh范围是0~1.]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster rcnn 】get_roidb]]></title>
    <url>%2F2018%2F07%2F07%2F%E3%80%90faster%20rcnn%E3%80%91get_roidb%2F</url>
    <content type="text"><![CDATA[在faster-rcnn训练的第一个阶段： stage 1 train_rpn() stage1_rpn_solver60k80k.pt 在train_rpn()中，首先需要加载数据——得到roidb：1roidb, imdb = get_roidb(imdb_name) 函数get_roidb()的定义：123456789def get_roidb(imdb_name, rpn_file=None): imdb = get_imdb(imdb_name) print ('Loaded dataset `&#123;:s&#125;` for training'.format(imdb.name)) imdb.set_proposal_method(cfg.TRAIN.PROPOSAL_METHOD) print ('Set proposal method: &#123;:s&#125;'.format(cfg.TRAIN.PROPOSAL_METHOD)) if rpn_file is not None: imdb.config['rpn_file'] = rpn_file roidb = get_training_roidb(imdb) return roidb, imdb 可以看到该函数主要干了三件事： 根据imdb_name初始化变量imdb（这里的imdb_name可以确定后面不同数据集的加载方式），此时的imdb只是一个class； 设置产生proposal的方法：imdb.set_proposal_method(cfg.TRAIN.PROPOSAL_METHOD)，此时只是配置一下class imdb的参数 根据上述配置，运行先关函数，加载数据集，得到roidb 看一下函数get_imdb()：12345def get_imdb(name): """Get an imdb (image database) by name.""" if not __sets.has_key(name): raise KeyError('Unknown dataset: &#123;&#125;'.format(name)) return __sets[name]() 当然这之前有铺垫，即写好_sets这个dictionary：1234567891011121314151617# Set up voc_&lt;year&gt;_&lt;split&gt; using selective search "fast" modefor year in ['2007', '2012']: for split in ['train', 'val', 'trainval', 'test']: name = 'voc_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: pascal_voc(split, year)) # Set up coco_2014_&lt;split&gt;for year in ['2014']: for split in ['train', 'val', 'minival', 'valminusminival']: name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: coco(split, year)) # Set up coco_2015_&lt;split&gt;for year in ['2015']: for split in ['test', 'test-dev']: name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: coco(split, year)) 在调用函数get_imdb()时，根据不同的name调用不同的数据集对应的class，对应各自的解析方式，以pascal_voc()为例，进入这个文件，看一下初始化部分：12345678910111213141516171819202122232425262728293031323334class pascal_voc(imdb):def __init__(self, image_set, year, devkit_path=None): imdb.__init__(self, 'voc_' + year + '_' + image_set) self._year = year self._image_set = image_set self._devkit_path = self._get_default_path() if devkit_path is None \ else devkit_path self._data_path = os.path.join(self._devkit_path, 'VOC' + self._year) self._classes = ('__background__', # always index 0 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor') self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes))) self._image_ext = '.jpg' self._image_index = self._load_image_set_index() # Default to roidb handler self._roidb_handler = self.selective_search_roidb self._salt = str(uuid.uuid4()) self._comp_id = 'comp4' # PASCAL specific config options self.config = &#123;'cleanup' : True, 'use_salt' : True, 'use_diff' : False, 'matlab_eval' : False, 'rpn_file' : None, 'min_size' : 2&#125; assert os.path.exists(self._devkit_path), \ 'VOCdevkit path does not exist: &#123;&#125;'.format(self._devkit_path) assert os.path.exists(self._data_path), \ 'Path does not exist: &#123;&#125;'.format(self._data_path) 可以看出pascal_voc是imdb的子类，同时上面只是根据imdb_name调用对应的split=split, year=year，然后初始化class pascal_voc。再看执行部分（在这里应该没有执行?）：12345if __name__ == '__main__': from datasets.pascal_voc import pascal_voc d = pascal_voc('trainval', '2007') res = d.roidb from IPython import embed; embed() 接下来是第二部分，设置得到roi的方法：1imdb.set_proposal_method(cfg.TRAIN.PROPOSAL_METHOD) 此处METHOD为gt，对应着函数gt_roidb（在文件pascal_voc.py中）：1234567891011121314151617181920def gt_roidb(self): """ Return the database of ground-truth regions of interest. This function loads/saves from/to a cache file to speed up future calls. """ cache_file = os.path.join(self.cache_path, self.name + '_gt_roidb.pkl') if os.path.exists(cache_file): with open(cache_file, 'rb') as fid: roidb = cPickle.load(fid) print ('&#123;&#125; gt roidb loaded from &#123;&#125;'.format(self.name, cache_file)) return roidb gt_roidb = [self._load_pascal_annotation(index) for index in self.image_index] with open(cache_file, 'wb') as fid: cPickle.dump(gt_roidb, fid, cPickle.HIGHEST_PROTOCOL) print ('wrote gt roidb to &#123;&#125;'.format(cache_file)) return gt_roidb 这里面的函数_load_pascal_annotation()是解析xml文件的，可以收藏：123456789101112131415161718192021222324252627282930313233343536373839404142434445def _load_pascal_annotation(self, index): """ Load image and bounding boxes info from XML file in the PASCAL VOC format. """ filename = os.path.join(self._data_path, 'Annotations', index + '.xml') tree = ET.parse(filename) objs = tree.findall('object') if not self.config['use_diff']: # Exclude the samples labeled as difficult non_diff_objs = [ obj for obj in objs if int(obj.find('difficult').text) == 0] # if len(non_diff_objs) != len(objs): # print 'Removed &#123;&#125; difficult objects'.format( # len(objs) - len(non_diff_objs)) objs = non_diff_objs num_objs = len(objs) boxes = np.zeros((num_objs, 4), dtype=np.uint16) gt_classes = np.zeros((num_objs), dtype=np.int32) overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32) # "Seg" area for pascal is just the box area seg_areas = np.zeros((num_objs), dtype=np.float32) # Load object bounding boxes into a data frame. for ix, obj in enumerate(objs): bbox = obj.find('bndbox') # Make pixel indexes 0-based x1 = float(bbox.find('xmin').text) - 1 y1 = float(bbox.find('ymin').text) - 1 x2 = float(bbox.find('xmax').text) - 1 y2 = float(bbox.find('ymax').text) - 1 cls = self._class_to_ind[obj.find('name').text.lower().strip()] boxes[ix, :] = [x1, y1, x2, y2] gt_classes[ix] = cls overlaps[ix, cls] = 1.0 seg_areas[ix] = (x2 - x1 + 1) * (y2 - y1 + 1) overlaps = scipy.sparse.csr_matrix(overlaps) return &#123;'boxes' : boxes, 'gt_classes': gt_classes, 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : seg_areas&#125; 注意该函数的输入为index，单位为每个image，也就是说每次加载一个图像的xml，解析出里面所有的boxes（boxes个数为objects的个数）。该函数的作用是将xml中的有用信息包装为字典，然后return。 roidb字典里的key值对应的数据结构： boxes: num_objs × 4 gt_classes: num_objs gt_overlaps: num_objs × num_classes （存储时进行压缩，用到的时候再解压） seg_areas: num_objs 有具体的数据，对数据集的结构有一定概念，程序中的一些地方就很好落地，否则只是空中楼阁。 顺便说一下，还有一种与gt方法相对应的是通过rpn方法得到roidb：123456789def rpn_roidb(self): if int(self._year) == 2007 or self._image_set != 'test': gt_roidb = self.gt_roidb() rpn_roidb = self._load_rpn_roidb(gt_roidb) roidb = imdb.merge_roidbs(gt_roidb, rpn_roidb) else: roidb = self._load_rpn_roidb(None) return roidb 可以看出在该方法中，gt_roidb仍然用原来的方法——即从xml中解析得到ground truth roi，rpn_roidb由之前生成的rpn得到。进入函数_load_rpn_roidb()：12345678def _load_rpn_roidb(self, gt_roidb): filename = self.config['rpn_file'] print ('loading &#123;&#125;'.format(filename)) assert os.path.exists(filename), \ 'rpn data not found at: &#123;&#125;'.format(filename) with open(filename, 'rb') as f: box_list = cPickle.load(f) return self.create_roidb_from_box_list(box_list, gt_roidb) 其中create_roidb_from_box_list()函数在Imdb.py中（该函数在pascal_voc.py没有定义，也找不到相关的import命令，因为在pascal_voc.py的开头有一句话：from datasets.imdb import imdb，所以可以直接通过self调用）： 12345678910111213141516171819202122232425262728def create_roidb_from_box_list(self, box_list, gt_roidb): assert len(box_list) == self.num_images, \ 'Number of boxes must match number of ground-truth images' roidb = [] for i in xrange(self.num_images): boxes = box_list[i] num_boxes = boxes.shape[0] overlaps = np.zeros((num_boxes, self.num_classes), dtype=np.float32) if gt_roidb is not None and gt_roidb[i]['boxes'].size &gt; 0: gt_boxes = gt_roidb[i]['boxes'] gt_classes = gt_roidb[i]['gt_classes'] gt_overlaps = bbox_overlaps(boxes.astype(np.float), gt_boxes.astype(np.float)) argmaxes = gt_overlaps.argmax(axis=1) maxes = gt_overlaps.max(axis=1) I = np.where(maxes &gt; 0)[0] overlaps[I, gt_classes[argmaxes[I]]] = maxes[I] overlaps = scipy.sparse.csr_matrix(overlaps) roidb.append(&#123; 'boxes' : boxes, 'gt_classes' : np.zeros((num_boxes,), dtype=np.int32), 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : np.zeros((num_boxes,), dtype=np.float32), &#125;) return roidb 注意该函数的参数box_list和gt_roidb都是元素为dictionary的list。list的长度为图片个数num_images。其中box_list由上一步rpn生成的proposals组成，当时只是保存了proposals的序号和四个坐标： (n, x1, y1, x2, y2) specifying an image batch index n and a rectangle (x1, y1, x2, y2)。 因此需要根据box_list这个最原始的信息，得到更加深刻的信息，如overlaps、对应的gt_cls等。所以该函数首先计算box_list（由前面的rpn得到）中的box和gt_roidb的ground truth的overlap，以此作为后续操作的铺垫，得到这些信息后，将其放入dictionary，以生成roidb。 顺便总结以下roidb的流水线：先由proposals得到原始的框的四个坐标点，然后通过rpn_roidb()中的create_roidb_from_box_list函数得到初始的（同xml中得到的一样）roidb，最后通过prepare_roidb将其丰富，得到最终的roidb。 看一下函数bbox_overlaps()的说明：1234567Parameters#----------boxes: (N, 4) ndarray of floatquery_boxes: (K, 4) ndarray of floatReturns#-------overlaps: (N, K) ndarray of overlap between boxes and query_boxes 并且在该函数的最后：1overlaps[n, k] = iw * ih / ua 同时注意到overlaps的初始化为zeros：1cdef np.ndarray[DTYPE_t, ndim=2] overlaps = np.zeros((N, K), dtype=DTYPE) 所以，overlaps中元素的值域为[0,1]，两个box没有交集时为0，完全重叠时为1. 后面紧接着两个max的参数axis=1（表示沿着改维度进行操作）：表示保留boxes，并找出每一个box对应的最大的gt_box面积值/索引；I表示与gt_box有交集的boxes索引数组。 总结一下：argmaxes存放每个box对应的最大overlaps的gt值，也就是类别；maxes存放每个box能够生成的最大的overlap；I筛选出了与gt_box有交集的boxes。overlaps[I, gt_classes[argmaxes[I]]] = maxes[I]表示将最大的overlaps挑选出来，按照对应的boxes和gt_classes放入新的数组，该数组每一行最多有一个为非零，剩下的全是0.后面的overlaps = scipy.sparse.csr_matrix(overlaps)表示将overlaps这个稀疏矩阵压缩，以节省存储空间。后面需要用到overlaps的时候，用到以下语句（在roidb.py的prepare_roidb(imdb)里）： gt_overlaps = roidb[i][&apos;gt_overlaps&apos;].toarray() 最后将两种roi——ground truth和rpn生成的与gt_roi有交集的boxes合并：1234567891011def merge_roidbs(a, b):assert len(a) == len(b)for i in xrange(len(a)): a[i]['boxes'] = np.vstack((a[i]['boxes'], b[i]['boxes'])) a[i]['gt_classes'] = np.hstack((a[i]['gt_classes'], b[i]['gt_classes'])) a[i]['gt_overlaps'] = scipy.sparse.vstack([a[i]['gt_overlaps'], b[i]['gt_overlaps']]) a[i]['seg_areas'] = np.hstack((a[i]['seg_areas'], b[i]['seg_areas']))return a 其中的函数vstack和hstack可以参考这篇博客 至于如何根据METHOD调用对应的函数，重点看class imdb中的成员函数roidb()（在Imdb.py中）：1234567891011121314151617181920212223@propertydef roidb_handler(self):return self._roidb_handler@roidb_handler.setterdef roidb_handler(self, val):self._roidb_handler = valdef set_proposal_method(self, method):method = eval('self.' + method + '_roidb')self.roidb_handler = method@propertydef roidb(self):# A roidb is a list of dictionaries, each with the following keys:# boxes# gt_overlaps# gt_classes# flippedif self._roidb is not None: return self._roidbself._roidb = self.roidb_handler()return self._roidb 上述只是配置class，接下来是调用。进入函数get_training_roidb(imdb)：12345678910def get_training_roidb(imdb): """Returns a roidb (Region of Interest database) for use in training.""" if cfg.TRAIN.USE_FLIPPED: print ('Appending horizontally-flipped training examples...') imdb.append_flipped_images() print ('done') print ('Preparing training data...') rdl_roidb.prepare_roidb(imdb) print ('done') 该函数主要通过上面配置好的class，得到具体的数据。首先判断是否需要翻转，这样可以增加数据的多样性（使数据增加一倍），使网络训练地更充分。进入函数append_flipped_images()：12345678910111213141516def append_flipped_images(self):num_images = self.num_imageswidths = self._get_widths()for i in xrange(num_images): boxes = self.roidb[i]['boxes'].copy() oldx1 = boxes[:, 0].copy() oldx2 = boxes[:, 2].copy() boxes[:, 0] = widths[i] - oldx2 - 1 boxes[:, 2] = widths[i] - oldx1 - 1 assert (boxes[:, 2] &gt;= boxes[:, 0]).all() entry = &#123;'boxes' : boxes, 'gt_overlaps' : self.roidb[i]['gt_overlaps'], 'gt_classes' : self.roidb[i]['gt_classes'], 'flipped' : True&#125; self.roidb.append(entry)self._image_index = self._image_index * 2 该函数将图片以中心线为轴进行翻转，把新的框的坐标存入字典，剩余信息不变，然后作为新的图片存入整个list，同时图片数量翻倍（最后一句）。 进入函数prepare_roidb(imdb)：1234567891011121314151617181920212223242526272829def prepare_roidb(imdb): """Enrich the imdb's roidb by adding some derived quantities that are useful for training. This function precomputes the maximum overlap, taken over ground-truth boxes, between each ROI and each ground-truth box. The class with maximum overlap is also recorded. """ sizes = [PIL.Image.open(imdb.image_path_at(i)).size for i in xrange(imdb.num_images)] roidb = imdb.roidb for i in xrange(len(imdb.image_index)): roidb[i]['image'] = imdb.image_path_at(i) roidb[i]['width'] = sizes[i][0] roidb[i]['height'] = sizes[i][1] # need gt_overlaps as a dense array for argmax gt_overlaps = roidb[i]['gt_overlaps'].toarray() # max overlap with gt over classes (columns) max_overlaps = gt_overlaps.max(axis=1) # gt class that had the max overlap max_classes = gt_overlaps.argmax(axis=1) roidb[i]['max_classes'] = max_classes roidb[i]['max_overlaps'] = max_overlaps # sanity checks # max overlap of 0 =&gt; class should be zero (background) zero_inds = np.where(max_overlaps == 0)[0] assert all(max_classes[zero_inds] == 0) # max overlap &gt; 0 =&gt; class should not be zero (must be a fg class) nonzero_inds = np.where(max_overlaps &gt; 0)[0] assert all(max_classes[nonzero_inds] != 0) 可以看出通过roidb = imdb.roidb，进行具体的函数调用——gt_roidb()或rnp_roidb()，重新回顾一下这两个函数的末尾。gt_roidb()：12gt_roidb = [self._load_pascal_annotation(index) for index in self.image_index] 而函数_load_pascal_annotation(index)的末尾：12345return &#123;'boxes' : boxes, 'gt_classes': gt_classes, 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : seg_areas&#125; 以及rnp_roidb()：12345678roidb.append(&#123; 'boxes' : boxes, 'gt_classes' : np.zeros((num_boxes,), dtype=np.int32), 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : np.zeros((num_boxes,), dtype=np.float32), &#125;)return roidb roidb字典里的key值对应的数据结构： boxes: num_objs × 4 gt_classes: num_objs gt_overlaps: num_objs × num_classes （存储时进行压缩，用到的时候再解压） seg_areas: num_objs 可以看出这两个函数的返回值roidb格式都是一致的：均为元素为dictionary的列表list，列表的长度为图片样本个数num_images；每个dictionary都有5个key：boxes、gt_classes、gt_overlaps、flipped、seg_areas。并且每个key的value为array类型，存放每一个框对应的属性。这是faster-rcnn中非常重要的一个数据结构。 重新回到函数prepare_roidb(imdb)，其作用是丰富dictionary的内容，增加了一些key：路径image、图片尺寸width和length，以及每张图片中每个box对应的最大的IOUmax_overlaps及对应的类max_classes。（在函数create_roidb_from_box_list(self, box_list, gt_roidb)中也有类似操作，但当时是为了得到稀疏矩阵overlaps，这里是将这些信息针对性地提取出来，以和overlaps同样的身份放入dictionary。）此时，roidb的数据结构为：12345678910&#123;'boxes' : boxes,'gt_classes': gt_classes,'gt_overlaps' : overlaps,'flipped' : False,'seg_areas' : seg_areas'image' : imdb.image_path_at(i)'width' : sizes[i][0]'height' : sizes[i][1]'max_classes' : max_classes'max_overlaps' : max_overlaps&#125; 其中，max_classes为(num_objs,),max_overlaps与之对应，为(num_objs,)。 至此，就得到了原始数据集对应的类imdb（包含相应的数据处理方法）和训练数据roidb（以dictionary为元素的list，存放具体的boxes的信息）。 附录 python中的axis 在python中，axis的顺序为矩阵从外到内，对应的shape顺序从左到右： 在上图中，2代表的axis=0； 3代表的axis=1； 4代表的axis=2。 当操作的参数为axis=m时，表示操作沿着m维度进行，或者说操作的结果消掉了m维度，以sum为例： 上述从shape层面的解释，对理解代码中的类似操作很有作用，下面将四个数组展开： 再验证以下max操作： python中的where 返回满足条件的元素，在每个维度下的坐标值： 压缩矩阵 关于scipy csr_matrix和csc_matrix函数的详解可以参考博客。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【faster rcnn】重装caffe——caffe-fast-rcnn]]></title>
    <url>%2F2018%2F07%2F07%2F%E3%80%90faster%20rcnn%E3%80%91%E9%87%8D%E8%A3%85caffe%E2%80%94%E2%80%94caffe-fast-rcnn%2F</url>
    <content type="text"><![CDATA[最近开始上手目标检测的代码，先从别人已经成功运行的例程开始： https://github.com/rbgirshick/py-faster-rcnn 参考了几篇博客： 深度学习实践经验：用Faster R-CNN训练行人检测数据集Caltech——准备工作 Faster-RCNN+ZF用自己的数据集训练模型(Python版本) 刚开始说需要重新编译caffe，那么之前花费功夫编译好的caffe要删掉吗？我觉得可以不用删除，甚至可以不用重新编译。后来按照教程开始运行demo.py，结果提示： ImportError: No module named _caffe 搜了一下，需要make pycaffe，可是我明明编译了python的接口，并且在/tools的路径下用终端进入python，import caffe都没有问题。所以只好在py-faster-rcnn的路径下重新编译caffe。我很害怕折腾，刚开始很保守地尝试了几种方案： 把caffe的原始包拷贝到py-faster-rcnn，按照教程配置MakeFile.Config，不行； 把caffe的原始包拷贝到py-faster-rcnn，把之前的MakeFile.Config替换一下，不行； 把自己编译好的caffe整个文件夹拷贝到py-faster-rcnn，提示350:21: Message type &quot;caffe.LayerParameter&quot; has no field named &quot;roi_pooling_param&quot;.； 后来又查找解决方案，说是最好用作者给出的caffe-fast-rcnn进行编译，因为作者可能对官方caffe进行了一些修改，比如加入自定义的layer。同时我注意到一点，这对后来成功运行代码起到决定性作用：很多教程包括作者的原始教程，都给出了MakeFile.Config，并且注明用于参考。这说明配置文件可以不一样，需要根据自己的电脑状况个性化处理，与别的修改都没关系。然后我就想用之前编译好的caffe的MakeFile.Config，放在作者给的caffe文件夹里，然后进行编译，一切OK！ Referencehttps://github.com/rbgirshick/py-faster-rcnn/issues/129 https://github.com/rbgirshick/py-faster-rcnn/issues/8 https://github.com/rbgirshick/fast-rcnn/issues/2]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pycharm】import问题]]></title>
    <url>%2F2018%2F07%2F06%2F%E3%80%90pycharm%E3%80%91import%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Pycharm下同一目录py文件不能相互调用？ https://blog.csdn.net/candy_gl/article/details/79222115 caffe debug 1-Pycharm import caffe 报错 no module named caffe https://www.cnblogs.com/keyky/p/6600557.html pycharm中import caffe/caffe2 https://blog.csdn.net/u013010889/article/details/70808866 pycharm加入import路径 【显示当前已添加的路径】 https://blog.csdn.net/hongxingabc/article/details/77094059]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】关于torch.nn的两点]]></title>
    <url>%2F2018%2F07%2F06%2F%E3%80%90pytorch%E3%80%91%E5%85%B3%E4%BA%8Etorch.nn%E7%9A%84%E4%B8%A4%E7%82%B9%2F</url>
    <content type="text"><![CDATA[torch.nn中的BatchNorm函数 12345class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)class torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 对于1d，其实是2d或3d：12Input: (N,C)(N,C) or (N,C,L)(N,C,L)Output: (N,C)(N,C) or (N,C,L)(N,C,L) (same shape as input) 对于2d，其实是4d：12Input: (N,C,H,W)(N,C,H,W)Output: (N,C,H,W)(N,C,H,W) (same shape as input) 对于3d，其实是5d：12Input: (N,C,D,H,W)(N,C,D,H,W)Output: (N,C,D,H,W)(N,C,D,H,W) (same shape as input) The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, tuple(‘abc’) returns (‘a’, ‘b’, ‘c’) and tuple( [1, 2, 3] ) returns (1, 2, 3). If no argument is given, the constructor creates a new empty tuple, (). Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, f(a, b, c) is a function call with three arguments, while f((a, b, c)) is a function call with a 3-tuple as the sole argument. torch.nn与torch.nn.functional之间的区别和联系 torch.nn.Conv2d1234567891011121314151617181920212223242526272829import torch.nn.functional as Fclass Conv2d(_ConvNd):def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):kernel_size = _pair(kernel_size)stride = _pair(stride)padding = _pair(padding)dilation = _pair(dilation)super(Conv2d, self).__init__( in_channels, out_channels, kernel_size, stride, padding, dilation, False, _pair(0), groups, bias)def forward(self, input):return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)``` #### torch.nn.functional.conv2d ```pythondef conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1): if input is not None and input.dim() != 4: raise ValueError("Expected 4D tensor as input, got &#123;&#125;D tensor instead.".format(input.dim())) f = _ConvNd(_pair(stride), _pair(padding), _pair(dilation), False, _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled) return f(input, weight, bias) 通过对比可以看出，torch.nn.Conv2d是一个类，而torch.nn.functional.conv2d是一个函数，并且，前者通过后者实现。也就是说nn.Conv2d是在F.conv2d外加的一层封装，从Module派生而来。关于Module最重要的一点是，它实现了call方法，在call方法里调用了forward()方法。所以，当执行self.Conv2d(x)，它就在调用Conv2d里面的forward()，并返回计算结果。通常在定义一些layer的时候，如果层内有weights、bias之类的参数时，用torch.nn，如果没有就用torch.nn.functional。 Reference https://blog.csdn.net/GZHermit/article/details/78730856https://blog.csdn.net/DuinoDu/article/details/76577498]]></content>
  </entry>
  <entry>
    <title><![CDATA[【pytorch】resnet]]></title>
    <url>%2F2018%2F07%2F06%2F%E3%80%90pytorch%E3%80%91resnet%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): self.inplanes = 64 super(ResNet, self).__init__() self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AvgPool2d(7, stride=1) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels m.weight.data.normal_(0, math.sqrt(2. / n)) elif isinstance(m, nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() ####_make_layer() produce layers with the same output size and channels, which contains 'blocks' block. ####downsample happens in the first layer def _make_layer(self, block, planes, blocks, stride=1): downsample = None if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(planes * block.expansion), ) layers = [] layers.append(block(self.inplanes, planes, stride, downsample)) #### make the 1st sublayer in given certain layer, which needs downsample. self.inplanes = planes * block.expansion for i in range(1, blocks): #### make the other layers, from 1 to blocks-1 layers.append(block(self.inplanes, planes)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = x.view(x.size(0), -1) x = self.fc(x) return x Reference PyTorch源码解读之torchvision.models https://blog.csdn.net/u014380165/article/details/79119664]]></content>
  </entry>
  <entry>
    <title><![CDATA[【dataset】voc数据集]]></title>
    <url>%2F2018%2F07%2F04%2F%E3%80%90dataset%E3%80%91voc%E6%95%B0%E6%8D%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[数据集与自己的网络框架不匹配时，通常有两个解决思路： 修改测试代码的接口，使其适应自己的数据格式； 将自己的数据格式转变为流行数据集，如voc的格式，然后使用标准的测试代码直接测试。 下面针对第二种，分析一下标准数据集VOC的数据结构。 如下图，共有五个文件夹： 其中： Annotations存放.xml格式的文件： 以2007_000027.xml为例： source：图像源 size：图片大小 object：物体名称（分类的类别） … ImageSets下面有四个子文件夹，分别表示四种challenge对应的图像标签： Action：人的动作 Layout：人体部位 Main：图像识别，一共20类 Segmentation：语义分割 以Main文件夹为例，每个类都有xxx_train.txt、xxx_val.txt、xxx_trainval.txt三个文件，每一个class的train数据都有5717个，每一个class的val数据都有5823个，_trainval将上面两个进行了合并，每一个class有11540个。 需要保证的是train和val两者没有交集，也就是训练数据和验证数据不能有重复，在选取训练数据的时候 ，也应该是随机产生的。 JPEDImages存放这个数据集的所有图像数据，即.jpg： JPEDImages与Annotations文件夹的数据一一对应。 最后是SegmentationClass和SegmentationObject两个文件夹，他们都是存放分割任务的分割结果。但是前者将同一类标注为同一种颜色，后者将不同的instance标注为不同的结果。 Reference https://blog.csdn.net/zhangjunbob/article/details/52769381]]></content>
  </entry>
  <entry>
    <title><![CDATA[【caffe】python接口获取网络中的数据信息]]></title>
    <url>%2F2018%2F06%2F30%2F%E3%80%90caffe%E3%80%91python%E6%8E%A5%E5%8F%A3%E8%8E%B7%E5%8F%96%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[查看神经网络中间层的blobs和paramsCaffe主要处理两种形式的数据流： 图像和标签在网络上的传输，随着网络的传输，它们转化更高层次的表示，最终以得分或者概率值的形式输出。 第二种数据流，主要保存各个网络层的参数，比如卷积层的weights和bias. 这些值是随着的网络的训练过程不断变化的。 第一种形式的数据流保存在net.blobs中：1net.blobs 它是有序字典，保存了每一层前后相应的数据。每个blob保存了data和gradient:12345678net.blobs['data'].data.shape # &gt;&gt; (64, 1, 28, 28)net.blobs['data'].diff.shape # &gt;&gt; (64, 1, 28, 28)net.blobs['conv1'].data.shape # &gt;&gt; (64, 20, 24, 24)net.blobs['conv1'].diff.shape # &gt;&gt; (64, 20, 24, 24)net.blobs['ip1'].data.shape # &gt;&gt; (64, 500)net.blobs['ip1'].diff.shape # &gt;&gt; (64, 500) 第二种形式的数据流，即网络层的参数，可以通过net.layers来获得：1net.layers 它的第一层是data layer:1len(net.layers[0].blobs) # &gt;&gt; 0 因为输入层没有权重参数，因此blob的个数是0 它的第二层是卷积层：1234len(net.layers[1].blobs) # &gt;&gt; 2net.layers[1].blobs[0].data.shape # &gt;&gt; (20, 1, 5, 5) conv1 weightsnet.layers[1].blobs[1].data.shape # &gt;&gt; (20,) bias 表示有20个卷积核，每个卷积核的大小是5*5，处理1-channel的输入图像。 还有一种获得各层参数的方式就是net.params：12345678910print net.params['conv1'][0].data.shape # (20, 1, 5, 5) conv1 weightsprint net.params['conv1'][1].data.shape # (20,) bias``` --- #### 实例-查看blobs```python# for each layer, show the output shapefor layer_name, blob in net.blobs.iteritems(): print layer_name + '\t' + str(blob.data.shape) 结果大致为：123456789101112131415data (50, 3, 227, 227)conv1 (50, 96, 55, 55)pool1 (50, 96, 27, 27)norm1 (50, 96, 27, 27)conv2 (50, 256, 27, 27)pool2 (50, 256, 13, 13)norm2 (50, 256, 13, 13)conv3 (50, 384, 13, 13)conv4 (50, 384, 13, 13)conv5 (50, 256, 13, 13)pool5 (50, 256, 6, 6)fc6 (50, 4096)fc7 (50, 4096)fc8 (50, 1000)prob (50, 1000) 实例-查看params函数为net.params,其中weight的样子应该是（output_channels,input_channels,filter_height,flier_width）, biases的形状只有一维output_channels,12for layer_name,parame in net.params.iteritems():print layer_name+'\t'+str(param[0].shape),str(param[1].data.shape) #可以看出param里0为weight，1为biase 结果为：12345678conv1 (96, 3, 11, 11) (96,) #输入3通道，输出96通道conv2 (256, 48, 5, 5) (256,) #输入为48，因为分成了两组，group=2conv3 (384, 256, 3, 3) (384,) #这里的输入没变conv4 (384, 192, 3, 3) (384,)conv5 (256, 192, 3, 3) (256,)fc6 (4096, 9216) (4096,) #9216=256*3*3fc7 (4096, 4096) (4096,)fc8 (1000, 4096) (1000,)]]></content>
  </entry>
  <entry>
    <title><![CDATA[【shell】根据label.txt提取图片]]></title>
    <url>%2F2018%2F06%2F21%2F%E3%80%90shell%E3%80%91%E6%A0%B9%E6%8D%AElabel.txt%E6%8F%90%E5%8F%96%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[目的：根据之前生成的label.txt，从源图片地址将每张用到的每张图片拷贝到新地址，即提取图片。背景：在制作测试集的过程中，需要根据每张图片的评分，将其从原来的存放位置挑选出来，移动到新的路径下。 逐行读取txt，为保证正确性，在前面加上index，统计总数： 加上路径前缀，构成绝对路径： 提取空格前面的名字，和空格后面的数字，即类别： 然后为每个类别创建一个文件夹，存放该类别的图片： 代码： 123if [ ! -d $class ]; then mkdir $b_dir/$classfi 最后就是copy了：1scp $imgdire $b_dir/$class Reference [1] shell下读取文件的方法 [2]shell字符串截断、切片与默认值 [3] Linux脚本shell字符串处理（全） [4]shell bash判断文件或文件夹是否存在 [5]Shell脚本——逐行处理文本文件 [6]Shell脚本中计算字符串长度的5种方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[【评价指标】accuracy、precision、recall的来龙去脉]]></title>
    <url>%2F2018%2F06%2F19%2F%E3%80%90%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E3%80%91accuracy%E3%80%81precision%E3%80%81recall%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89%2F</url>
    <content type="text"><![CDATA[准确率(Accuracy), 精确率(Precision), 召回率(Recall)： 之前对深度学习的量化指标的认识比较模糊，今天具体地整理一下各个指标的含义。只有明确量化指标，才能够对模型的质量更好地理解。 单标签图像分类下面形象地上一些概念： 预测的正类个数/被检索到的样本个数为TP+FP，这些中正确的个数为TP，precision为两者的比例：precision=TP/(TP+FP) 该指标是为了突出某个class（即true positive）的预测效果，做到不预测则罢，一旦预测就要精准，要求精度。 比如预测家禽的种类，有鸡、鸭、鹅、牛、羊，如果把对‘羊’的预测当做P，那么其他的就是N，如果预测羊正确，TP+1，如果预测羊错误，FP+1。 所有正样本个数/应该被检索到的样本个数为TP+FN，正确检索到的正样本个数为TP，recall为两个的比例：recall=TP/(TP+FN)该指标为了突出某个class的覆盖率，尽可能地预测到所有的正类，要求广度。 所有样本数量为TP+TN+FP+FN，正确分类的样本个数为TP+TN，accuracy为两者的比例：accuracy=(TP+TN)/(TP+TN+FP+FN)该指标比较均衡，不像上面两个指标只是突出正类，该指标追求综合的正确率。 多标签图像分类 多标签图像分类（Multi-label Image Classification）任务中图片的标签不止一个，因此评价不能用普通单标签图像分类的标准，即mean accuracy，该任务采用的是和信息检索中类似的方法——mAP（mean Average Precision）。mAP虽然字面意思和mean accuracy看起来差不多，但是计算方法要繁琐得多，以下是mAP的计算方法： 首先用训练好的模型得到所有测试样本的confidence score，每一类（如car）的confidence score保存到一个文件中（如comp1_cls_test_car.txt）。假设（这个类）共有20个测试样本，每个的id，confidence score和ground truth label如下：​​ 对confidence score排序，得到： 然后计算precision和recall，这两个标准的定义如下： 上图比较直观，圆圈内（true positives + false positives）是我们选出的元素,它对应于分类任务中我们取出的结果，比如对测试样本在训练好的car模型上分类，我们想得到top-5的结果，即： 在这个例子中，true positives就是指第4和第2张图片，false positives就是指第13，19，6张图片。方框内圆圈外的元素（false negatives和true negatives）是相对于方框内的元素而言，在这个例子中，是指confidence score排在top-5之外的元素，即： 其中，false negatives是指第9，16，7，20张图片，true negatives是指第1,18,5,15,10,17,12,14,8,11,3张图片。 那么，这个例子中Precision=2/5=40%，意思是对于car这一类别，我们选定了5个样本，其中正确的有2个，即准确率为40%；Recall=2/6=30%，意思是在所有测试样本中，共有6个car，但是因为我们只召回（检索到）了2个，所以召回率为30%。 实际多类别分类任务中，我们通常不满足只通过top-5来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有测试样本个数，本文中为20）对应的precision和recall。显然随着我们选定的样本越来也多，recall一定会越来越高，而precision整体上会呈下降趋势。把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线。这个例子的precision-recall曲线如下： 接下来说说AP的计算，此处参考的是PASCAL VOC CHALLENGE的计算方法。首先设定一组阈值，[0, 0.1, 0.2, …, 1]。然后对于recall大于每一个阈值（比如recall&gt;0.3），我们都会得到一个对应的最大precision。这样，我们就计算出了11个precision。AP即为这11个precision的平均值。这种方法英文叫做11-point interpolated average precision。​ 当然PASCAL VOC CHALLENGE自2010年后就换了另一种计算方法。新的计算方法假设这N个样本中有M个正例，那么我们会得到M个recall值（1/M, 2/M, …, M/M）,对于每个recall值r，我们可以计算出对应（r’ &gt; r）的最大precision，然后对这M个precision值取平均即得到最后的AP值。计算方法如下：​ 相应的Precision-Recall曲线（这条曲线是单调递减的）如下：​ AP衡量的是学出来的模型在每个类别上的好坏，mAP衡量的是学出的模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有AP的平均值。 top1 vs top5 To make things simple, we can specify the k in top-k only in test period. It seems there is no need to set k in training period. But if we induldge into the detail, we can find the subtle difference. If we set k in training, it see the situation where correct label occurs in top-k in the same way as that in top-1. So the particular accuracy is lower but seems with a stronger robust. We can also see this in the layer, to see if it functions in traing. 上面只是知道这些指标的含义，如何得到，即知其然，下面揣测一下其所以然： 对于多标签分类，mean accuracy失去含义，只剩下另外两个基本的指标——precision和recall，前者要求精度，后者要求广度，本质上这两个指标是矛盾的，如果将其分开看，那样会很片面和极端，不能客观地反映分类性能，因此需要综合起来，在某个指标固定的前提下，讨论另一个指标。然而某个指标如何固定，这是个问题 ，也比较繁琐，因此默认将这个指标遍历，然后得到对应的另一个指标，最后将这些结果求平均值，即mAP。 reference 准确率(Accuracy), 精确率(Precision), 召回率(Recall)和F1-Measure https://blog.argcv.com/articles/1036.c AP MAP Recall http://blog.sina.com.cn/s/blog_9db078090102whzw.html caffe中的Accuracy https://blog.csdn.net/scythe666/article/details/78790648 https://blog.csdn.net/u011501388/article/details/77962401]]></content>
  </entry>
  <entry>
    <title><![CDATA[【caffe】training log and visualizaiton]]></title>
    <url>%2F2018%2F06%2F18%2F%E3%80%90caffe%E3%80%91training%20log%20and%20visualizaiton%2F</url>
    <content type="text"><![CDATA[训练结果可视化 获取训练日志常规train或者test时，在命令前面加上GLOG_logtostderr=0 GLOG_log_dir=&#39;your_own_path&#39;,即： GLOG_logtostderr=0 GLOG_log_dir=/home/shukun/2018prcv/recognition/structure/ResNet_50/LOG /home/shukun/caffe/build/tools/caffe train -solver solver.prototxt -weights ResNet-50-model.caffemodel -gpu 1 GLOG_logtostderr=0 GLOG_log_dir=/home/shukun/2018prcv/recognition/structure/ResNet_50/LOG /home/shukun/caffe/build/tools/caffe test -model=test.prototxt -weights=snapshot_iter_12000.caffemodel -iterations=500 -gpu 1 之后系统会在指定目录下，生成四个文件： 这里我们需要用到的是caffe.usrname-Ubuntu.usrname.log.INFO.当前日期-当前时间.xxxx。注意，应该在这个文件后面加上后缀.log，然后进行后续操作。 在此基础上，需要用caffe自带的工具进行绘图。进入路径~/caffe/tools/extra,将其中的parse_log.sh、extract_seconds.py和plot_training_log.py.example拷贝到log存放的文件夹，然后在终端执行： bash parse_log.sh caffe.ubuntu.shukun.log.INFO.20180618-175544.32514.log 生成两个文件：caffe.ubuntu.shukun.log.INFO.20180618-175544.32514.log.test和caffe.ubuntu.shukun.log.INFO.20180618-175544.32514.log.train 这两个文件将绘图需要的直接数据提取了出来，相比之下原来的.log包含了我们训练/测试时在终端看到的所有信息。 绘制accuracy、loss曲线然后利用./plot_training_log.py.example画图，命令格式为： python plot_training_log.py.example 0 acc_iter.png caffe.ubuntu.shukun.log.INFO.20180618-175544.32514.log 其中第一个参数为数字0~7，每一个代表一种曲线类型： Supported chart types: 0: Test accuracy vs. Iters 1: Test accuracy vs. Seconds 2: Test loss vs. Iters 3: Test loss vs. Seconds 4: Train learning rate vs. Iters 5: Train learning rate vs. Seconds 6: Train loss vs. Iters 7: Train loss vs. Seconds 第二个参数为保存的图片名称； 第三个参数为log文件，注意：这里必须先修改train或test阶段生成的log文件名——在caffe.ubuntu.shukun.log.INFO.20180618-175544.32514加上后缀.log，否则无法绘图。 Referencehttps://blog.csdn.net/maweifei/article/details/53026349 https://blog.csdn.net/u013078356/article/details/51154847 https://blog.csdn.net/fx409494616/article/details/53197209 https://blog.csdn.net/sinat_34474705/article/details/77065972 https://blog.csdn.net/u011452869/article/details/54085275 【caffe训练日志输出】 https://blog.csdn.net/hduxiejun/article/details/53543617]]></content>
  </entry>
  <entry>
    <title><![CDATA[【shell】select files from different folders and put them into subfolders]]></title>
    <url>%2F2018%2F06%2F15%2F%E3%80%90shell%E3%80%91select%20files%20from%20different%20folders%20and%20put%20them%20into%20subfolders%2F</url>
    <content type="text"><![CDATA[Today, there is an emergency to deal with. Two folders are given. The first includes pure images and the second includes images with notifications and label txt. Document structure is as following: A/classes/pure images; B/classes/ sub_a: images with notifications; sub_b: corresponding label txt. The images in folder A and B have the same file name, and there only difference is that A’s are origin but B’s are notified with ground truth. Now I have to pick out origin images from folder A and its corresponding labels txt from folder B. Then rename the classes as increasing indexes from 1 to 2, 3, … And build a new pic folder and txt folder to contain images and labels respectively. At beginning, I want to use a ‘pysical method’ — manully conduct these steps one by one. But there are as many as 212 classes and in every class’ folder, it usually has many subfolders in depth. So I quickly give up this method and turn to the shell code. These are key points in the process: create folders from 1 to 212 create sub folders pic and txt in every folder go through deep direction and target specific files, .jpg or .txt distinguish from .jpg to .txt copy file from a new folder traverse class folder along A and B parallelly There are specific important commands of shell: create folders from 1 to 212 create sub folders pic and txt in every folder code:1234567for k in $( seq 1 10 )do mkdir /media/sun/Seagate_Casia/tank/new/$&#123;k&#125; dire=/media/sun/Seagate_Casia/tank/new/$&#123;k&#125; mkdir $dire/pic mkdir $dire/txt done go through deep direction and target specific files, .jpg or .txt code:1234567891011function copy_pic()&#123;for file in `ls $1` #the signal of system command ``do if [ -d $1"/"$file ] #notice the blank in this command then copy_pic $1"/"$file $2 $3 #this is very important for the func with more params else echo $1"/"$file #handle with files there fidone&#125; distinguish from .jpg to .txt code:1234if [ "$&#123;file##*.&#125;" = "jpg" ] then cp $1"/"$file $3 fi copy file from a new folder code:1cp $1"/"$file $3 traverse class folder along A and B parallelly: This is a trick combining above modules. Whole code is on my github. Review Divide whatever the problem into several sub problems, you will find it’s not that hard and not that unsolvable.]]></content>
  </entry>
  <entry>
    <title><![CDATA[【file with caffe】run label.py on remote server]]></title>
    <url>%2F2018%2F06%2F15%2F%E3%80%90file%20with%20caffe%E3%80%91run%20label.py%20on%20remote%20server%2F</url>
    <content type="text"><![CDATA[I’ve writen the python file, using it to read images’ name, assign the same label to images in the same folder. Before this, I successfully run them in pycharm. However there seems to be a pure python without IDE in the server and I have to run .py in its terminal. There are some points deserve attention: the running command is ./filename.py, the same as filename.sh previously run. when I successfully run it, there is some errors: the main error is import: not found. Notice that it’s not some module not found but the import itself. The reason is that I failed to specify which python to execute this .py. So I write this on the first line: #!/usr/bin/python If you want to use your python with specific environments, you can write: #!/usr/bin/env python Their differences are concluded as: Fixing that, there is another error: write this in the front: #&lt; pre class =&quot;python&quot; name=&quot;code&quot; &gt; # coding:utf-8 Other Tips Tip 1: frac = (float)(12000/40114) &gt;&gt; 0.0 frac = (float)12000/40114 &gt;&gt; error frac = float(12000)/40114 &gt;&gt; 0.299 Tip 2: tab is 8 characters, so anti-tab move both 4-indent and 8-indent content to the first colum. This may cause some logical errors.]]></content>
  </entry>
  <entry>
    <title><![CDATA[【caffe】Brewing ImageNet]]></title>
    <url>%2F2018%2F06%2F14%2F%E3%80%90caffe%E3%80%91Brewing%20ImageNet%2F</url>
    <content type="text"><![CDATA[This guide is meant to get you ready to train your own model on your own data. If you just want an ImageNet-trained network, then note that since training takes a lot of energy and we hate global warming, we provide the CaffeNet model trained as described below in the model zoo. Data Preparation The guide specifies all paths and assumes all commands are executed from the root caffe directory.By “ImageNet” we here mean the ILSVRC12 challenge, but you can easily train on the whole of ImageNet as well, just with more disk space, and a little longer training time.We assume that you already have downloaded the ImageNet training data and validation data, and they are stored on your disk like: /path/to/imagenet/train/n01440764/n01440764_10026.JPEG /path/to/imagenet/val/ILSVRC2012_val_00000001.JPEG You will first need to prepare some auxiliary data for training. This data can be downloaded by: ./data/ilsvrc12/get_ilsvrc_aux.sh The training and validation input are described in train.txt and val.txt as text listing all the files and their labels. Note that we use a different indexing for labels than the ILSVRC devkit: we sort the synset names in their ASCII order, and then label them from 0 to 999. See synset_words.txt for the synset/name mapping. You may want to resize the images to 256x256 in advance. By default, we do not explicitly do this because in a cluster environment, one may benefit from resizing images in a parallel fashion, using mapreduce. For example, Yangqing used his lightweight mincepie package. If you prefer things to be simpler, you can also use shell commands, something like: for name in /path/to/imagenet/val/*.JPEG; do convert -resize 256x256\! $name $name done Take a look at examples/imagenet/create_imagenet.sh: Set the paths to the train and val dirs as needed; et RESIZE=true to resize all images to 256x256 if you haven’t resized the images in advance. Now simply create the leveldbs with examples/imagenet/create_imagenet.sh. Note that examples/imagenet/ilsvrc12_train_leveldb and examples/imagenet/ilsvrc12_val_leveldb should not exist before this execution. It will be created by the script. GLOG_logtostderr=1 simply dumps more information for you to inspect, and you can safely ignore it. Compute Image Mean The model requires us to subtract the image mean from each image, so we have to compute the mean. tools/compute_image_mean.cpp implements that - it is also a good example to familiarize yourself on how to manipulate the multiple components, such as protocol buffers, leveldbs, and logging, if you are not familiar with them. Anyway, the mean computation can be carried out as: ./examples/imagenet/make_imagenet_mean.sh which will make data/ilsvrc12/imagenet_mean.binaryproto. Model Definition We are going to describe a reference implementation for the approach first proposed by Krizhevsky, Sutskever, and Hinton in their NIPS 2012 paper. The network definition models/bvlc_reference_caffenet/train_val.prototxt follows the one in Krizhevsky et al. Note that if you deviated from file paths suggested in this guide, you’ll need to adjust the relevant paths in the .prototxt files. If you look carefully at models/bvlc_reference_caffenet/train_val.prototxt, you will notice several include sections specifying either phase: TRAIN or phase: TEST. These sections allow us to define two closely related networks in one file: the network used for training and the network used for testing. These two networks are almost identical, sharing all layers except for those marked with include { phase: TRAIN } or include { phase: TEST }. In this case, only the input layers and one output layer are different. Input layer differences: The training network’s data input layer draws its data from examples/imagenet/ilsvrc12_train_leveldb and randomly mirrors the input image. The testing network’s data layer takes data from examples/imagenet/ilsvrc12_val_leveldb and does not perform random mirroring. Output layer differences: Both networks output the softmax_loss layer, which in training is used to compute the loss function and to initialize the backpropagation, while in validation this loss is simply reported. The testing network also has a second output layer, accuracy, which is used to report the accuracy on the test set. In the process of training, the test network will occasionally be instantiated and tested on the test set, producing lines like Test score #0: xxx and Test score #1: xxx. In this case score 0 is the accuracy (which will start around 1/1000 = 0.001 for an untrained network) and score 1 is the loss (which will start around 7 for an untrained network). We will also lay out a protocol buffer for running the solver. Let’s make a few plans: We will run in batches of 256, and run a total of 450,000 iterations (about 90 epochs). For every 1,000 iterations, we test the learned net on the validation data. We set the initial learning rate to 0.01, and decrease it every 100,000 iterations (about 20 epochs). Information will be displayed every 20 iterations. The network will be trained with momentum 0.9 and a weight decay of 0.0005. For every 10,000 iterations, we will take a snapshot of the current status. Sound good? This is implemented in models/bvlc_reference_caffenet/solver.prototxt. Training ImageNet Ready? Let’s train. ./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt Sit back and enjoy! On a K40 machine, every 20 iterations take about 26.5 seconds to run (while a on a K20 this takes 36 seconds), so effectively about 5.2 ms per image for the full forward-backward pass. About 2 ms of this is on forward, and the rest is backward. If you are interested in dissecting the computation time, you can run ./build/tools/caffe time --model=models/bvlc_reference_caffenet/train_val.prototxt Resume Training? We all experience times when the power goes out, or we feel like rewarding ourself a little by playing Battlefield (does anyone still remember Quake?). Since we are snapshotting intermediate results during training, we will be able to resume from snapshots. This can be done as easy as: ./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt --snapshot=models/bvlc_reference_caffenet/caffenet_train_iter_10000.solverstate where in the script caffenet_train_iter_10000.solverstate is the solver state snapshot that stores all necessary information to recover the exact solver state (including the parameters, momentum history, etc). Parting Words Hope you liked this recipe! Many researchers have gone further since the ILSVRC 2012 challenge, changing the network architecture and/or fine-tuning the various parameters in the network to address new data and tasks. Caffe lets you explore different network choices more easily by simply writing different prototxt files - isn’t that exciting? And since now you have a trained network, check out how to use it with the Python interface for classifying ImageNet. Review the loss and accuracy are computed by particular layer, which is correlated to prefessional code. Generally the kind of accuracy you want to calculate is included in caffe’s inherent layer. If you want to compute come special accuracy, you can create your own kind layer and register them in caffe.]]></content>
  </entry>
  <entry>
    <title><![CDATA[【caffe】从命令行到函数调用]]></title>
    <url>%2F2018%2F06%2F10%2F%E3%80%90caffe%E3%80%91%E4%BB%8E%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%B0%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[写在前面：经过几天的琢磨，caffe的使用流程已经基本掌握，但我始终对一些问题感到好奇，比如写的那些文本是如何形成网络的，在命令行输入的参数是怎么调用相应程序的，网路中每个层（module）的那些参数（或说属性）是怎么定义的？等等。这种好奇让我觉得很没谱，万一某一天caffe没有按照想法进行工作，或者在caffe主体的基础上自己有了一点不一样的想法，我该怎么去改？虽然这种情况出现时，我的水平可能已经很高了，但是现在始终在心里挥之不去。因此抽时间查找了一些相关材料，汇总如下。 在caffe.cpp的开头，可以看到很多宏，例如：1234DEFINE_string(gpu, "", "Optional; run in GPU mode on given device IDs separated by ','." "Use '-gpu all' to run on all available GPUs. The effective training " "batch size is multiplied by the number of devices."); 这个宏的使用方式为DEFINE_xxx(name, default_value, instruction);，这样就定义了一个xxx类型名为FLAGS_name的标志，如果用户没有在Command Line中提供其值，那么会默认为default_value，instruction是这个标志含义的说明。因此，上面的代码定义了一个string类型的名为FLAGS_gpu的标志，如果在Command Line中用户没有提供值，那么会默认为空字符串，根据说明可以得知这个标志是提供给用户来指定caffe将使用的GPU的。 定义了很多标志，要有相应的代码对其进行解析。 解析这些标志的代码在caffe.cpp中的main()中调用了/CAFFE_ROOT/src/common.cpp中的GlobalInit(&amp;argc, &amp;argv)函数。 ###从命令行写入参数，到具体的调用函数 在调用caffe网络时，我们在命令行写入如下参数：1caffe train -solver=solver.prototxt -weights=pretrained-weights.caffemodel -gpu 0 第一个参数是train/test/time/device_query，表示要实现的功能。对该部分参数解析的实质是GetBrewFunction函数得到四个函数的指针。当然，这四个指针首先要通过RegisterBrewFunction这个宏完成函数的注册。两个函数的定义如下：123456789101112131415161718192021222324#define RegisterBrewFunction(func) \namespace &#123; \class __Registerer_##func &#123; \ public: /* NOLINT */ \ __Registerer_##func() &#123; \ g_brew_map[#func] = &amp;func; \ &#125; \&#125;; \__Registerer_##func g_registerer_##func; \&#125;static BrewFunction GetBrewFunction(const caffe::string&amp; name) &#123; if (g_brew_map.count(name)) &#123; return g_brew_map[name]; &#125; else &#123; LOG(ERROR) &lt;&lt; "Available caffe actions:"; for (BrewMap::iterator it = g_brew_map.begin(); it != g_brew_map.end(); ++it) &#123; LOG(ERROR) &lt;&lt; "\t" &lt;&lt; it-&gt;first; &#125; LOG(FATAL) &lt;&lt; "Unknown action: " &lt;&lt; name; return NULL; // not reachable, just to suppress old compiler warnings. &#125;&#125; 以train函数为例子，RegisterBrewFunction(train)这个宏的作用是定义了一个名为__Register_train的类，在定义完这个类之后，定义了一个这个类的变量，会调用构造函数，这个类的构造函数在前面提到的g_brew_map中添加了key为”train”，value为指向train函数的指针的一个元素。 其中g_brew_map为一个全局变量： // A simple registry for caffe commands. typedef int (*BrewFunction)(); typedef std::map&lt;caffe::string, BrewFunction&gt; BrewMap; BrewMap g_brew_map; main函数内容如下：123456789101112131415161718192021222324252627282930int main(int argc, char** argv) &#123; // Print output to stderr (while still logging). FLAGS_alsologtostderr = 1; // Set version gflags::SetVersionString(AS_STRING(CAFFE_VERSION)); // Usage message. gflags::SetUsageMessage("command line brew\n" "usage: caffe &lt;command&gt; &lt;args&gt;\n\n" "commands:\n" " train train or finetune a model\n" " test score a model\n" " device_query show GPU diagnostic information\n" " time benchmark model execution time"); // Run tool or show usage. caffe::GlobalInit(&amp;argc, &amp;argv); if (argc == 2) &#123;#ifdef WITH_PYTHON_LAYER try &#123;#endif return GetBrewFunction(caffe::string(argv[1]))();#ifdef WITH_PYTHON_LAYER &#125; catch (bp::error_already_set) &#123; PyErr_Print(); return 1; &#125;#endif &#125; else &#123; gflags::ShowUsageWithFlagsRestrict(argv[0], "tools/caffe"); &#125;&#125; 总结：RegisterBrewFunction这个宏在每一个实现主要功能的函数之后将这个函数的名字和其对应的函数指针添加到了g_brew_map中，然后在main函数中，通过GetBrewFunction得到了我们需要调用的那个函数的函数指针，并完成了调用。 这样就实现了四个函数train/test/time/device_query的调用。 下面以train的内部结构为例看看后续的运行流程。 开头：1234CHECK_GT(FLAGS_solver.size(), 0) &lt;&lt; "Need a solver definition to train.";CHECK(!FLAGS_snapshot.size() || !FLAGS_weights.size()) &lt;&lt; "Give a snapshot to resume training or weights to finetune " "but not both."; 这段代码的第一行使用了glog的CHECK_GT宏（含义为check greater than），检查FLAGS_solver的size是否大于0，如果小于或等于0则输出提示：”Need a solver definition to train”。FLAGS_solver是最开始通过DEFINE_string定义的标志，如果我们希望训练一个模型，那么自然应该应该提供对应的solver定义文件的路径，这一句话正是在确保我们提供了这样的路径。这样的检查语句在后续的代码中会经常出现，将不再一一详细解释，如果有不清楚含义的glog宏可以去看看文档。 与第一行代码类似，第二行代码是确保用户没有同时提供snapshot和weights参数，这两个参数都是继续之前的训练或者进行fine-tuning的，如果同时指明了这两个标志，则不知道到底应该从哪个路径的文件去读入模型的相关参数更为合适。 接下来是：1vector&lt;string&gt; stages = get_stages_from_flags(); 该函数的定义：123456// Parse stages from flagsvector&lt;string&gt; get_stages_from_flags() &#123; vector&lt;string&gt; stages; boost::split(stages, FLAGS_stage, boost::is_any_of(",")); return stages;&#125; 需要注意stage和phase不一样，但是具体的区别暂时不清楚，以后遇到就会知道。下面是phase的定义：1234567891011// Parse phase from flagscaffe::Phase get_phase_from_flags(caffe::Phase default_value) &#123; if (FLAGS_phase == "") return default_value; if (FLAGS_phase == "TRAIN") return caffe::TRAIN; if (FLAGS_phase == "TEST") return caffe::TEST; LOG(FATAL) &lt;&lt; "phase must be \"TRAIN\" or \"TEST\""; return caffe::TRAIN; // Avoid warning&#125; 接下来是：123456789101112 caffe::SolverParameter solver_param; caffe::ReadSolverParamsFromTextFileOrDie(FLAGS_solver, &amp;solver_param);即从solver.prototxt中获取相关的配置参数。看一下这个函数：// Read parameters from a file into a SolverParameter proto message.void ReadSolverParamsFromTextFileOrDie(const string&amp; param_file, SolverParameter* param) &#123; CHECK(ReadProtoFromTextFile(param_file, param)) &lt;&lt; "Failed to parse SolverParameter file: " &lt;&lt; param_file; UpgradeSolverAsNeeded(param_file, param);&#125; 其中又调用了另一个函数ReadProtoFromTextFile(param_file, param)： 123456789bool ReadProtoFromTextFile(const char* filename, Message* proto) &#123; int fd = open(filename, O_RDONLY); CHECK_NE(fd, -1) &lt;&lt; "File not found: " &lt;&lt; filename; FileInputStream* input = new FileInputStream(fd); bool success = google::protobuf::TextFormat::Parse(input, proto); delete input; close(fd); return success;&#125; 一路跟踪参数param_file可以发现，FLAGS_solver是prototxt的文件路径，而solver_param存放从其中解析到的配置参数信息，即这一系列函数的作用是从param_file这个路径去读取solver的定义。 要想了解solver一共包含哪些参数，分别表示什么，能够修改哪些信息？可以通过message SolverParameter{xxx}一探究竟，路径是./src/caffe/proto/caffe.proto. 此外，其背后的工作原理是 caffe通过Google Protocol Buffer来定义data schema。 可以通过这篇博客了解一下。 回到train函数，后面基本都是对参数的一些解析，如设置gpu模式、遇到系统信号时（用户按了ctrl+c或者关闭了当前的terminal）的处理方式等。具体的细节，此处先不深入探讨，以后如有需要，再做补充。这里主要提出两个函数进行分析： 1solver-&gt;SetActionFunction(signal_handler.GetActionFunction()); 和1solver-&gt;Solve(); 其中涉及到以下四个方面： Solver的初始化（Register宏和构造函数） SIGINT和SIGHUP信号的处理 Solver::Solve()具体实现 SGDSolver::ApplyUpdate具体实现 12shared_ptr&lt;caffe::Solver&lt;float&gt; &gt; solver(caffe::SolverRegistry&lt;float&gt;::CreateSolver(solver_param)); 该段代码定义一个指向Solver的shared_ptr。其中主要是通过调用SolverRegistry这个类的静态成员函数CreateSolver得到一个指向Solver的指针来构造shared_ptr类型的solver。 下面具体看一下SolverRegistry这个类的代码，以便理解“如何通过同一个函数得到不同类型的Solver”：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class SolverRegistry &#123; public: typedef Solver&lt;Dtype&gt;* (*Creator)(const SolverParameter&amp;); typedef std::map&lt;string, Creator&gt; CreatorRegistry; static CreatorRegistry&amp; Registry() &#123; static CreatorRegistry* g_registry_ = new CreatorRegistry(); return *g_registry_; &#125; static void AddCreator(const string&amp; type, Creator creator) &#123; CreatorRegistry&amp; registry = Registry(); CHECK_EQ(registry.count(type), 0) &lt;&lt; "Solver type " &lt;&lt; type &lt;&lt; " already registered."; registry[type] = creator; &#125; static Solver&lt;Dtype&gt;* CreateSolver(const SolverParameter&amp; param) &#123; const string&amp; type = param.type(); CreatorRegistry&amp; registry = Registry(); CHECK_EQ(registry.count(type), 1) &lt;&lt; "Unknown solver type: " &lt;&lt; type &lt;&lt; " (known types: " &lt;&lt; SolverTypeListString() &lt;&lt; ")"; return registry[type](param); &#125; static vector&lt;string&gt; SolverTypeList() &#123; CreatorRegistry&amp; registry = Registry(); vector&lt;string&gt; solver_types; for (typename CreatorRegistry::iterator iter = registry.begin(); iter != registry.end(); ++iter) &#123; solver_types.push_back(iter-&gt;first); &#125; return solver_types; &#125; private: SolverRegistry() &#123;&#125; static string SolverTypeListString() &#123; vector&lt;string&gt; solver_types = SolverTypeList(); string solver_types_str; for (vector&lt;string&gt;::iterator iter = solver_types.begin(); iter != solver_types.end(); ++iter) &#123; if (iter != solver_types.begin()) &#123; solver_types_str += ", "; &#125; solver_types_str += *iter; &#125; return solver_types_str; &#125;&#125;; 从CreateSolver函数(第15行)入手，这个函数先定义了string类型的变量type，表示Solver的类型(SGD/Nestrov等)，然后定义了一个key类型为string，value类型为Creator的map：registry(4、5、6、17行)，其中Creator是一个函数指针类型，指向的函数的参数为SolverParameter类型，返回类型为Solver*(见第2行和第3行)。如果是一个已经register过的Solver类型，那么registry.count(type)应该为1，然后通过registry这个map返回了我们需要类型的Solver的creator，并调用这个creator函数，将creator返回的Solver*返回。 上面的代码中，Registry这个函数（第5行）中定义了一个static的变量g_registry，这个变量是一个指向CreatorRegistry这个map类型的指针，然后直接返回，因为这个变量是static的，所以即使多次调用这个函数，也只会定义一个g_registry，而且在其他地方修改这个map里的内容，是存储在这个map中的。事实上各个Solver的register的过程正是往g_registry指向的那个map里添加以Solver的type为key，对应的Creator函数指针为value的内容。 函数static void AddCreator(const string&amp; type, Creator creator)在添加creator的时候调用。下面具体来看一下Solver的register的过程：123456789101112131415161718192021222324template &lt;typename Dtype&gt;class SolverRegisterer &#123; public: SolverRegisterer(const string&amp; type, Solver&lt;Dtype&gt;* (*creator)(const SolverParameter&amp;)) &#123; // LOG(INFO) &lt;&lt; "Registering solver type: " &lt;&lt; type; SolverRegistry&lt;Dtype&gt;::AddCreator(type, creator); &#125;&#125;;#define REGISTER_SOLVER_CREATOR(type, creator) \ static SolverRegisterer&lt;float&gt; g_creator_f_##type(#type, creator&lt;float&gt;); \ static SolverRegisterer&lt;double&gt; g_creator_d_##type(#type, creator&lt;double&gt;) \#define REGISTER_SOLVER_CLASS(type) \ template &lt;typename Dtype&gt; \ Solver&lt;Dtype&gt;* Creator_##type##Solver( \ const SolverParameter&amp; param) \ &#123; \ return new type##Solver&lt;Dtype&gt;(param); \ &#125; \ REGISTER_SOLVER_CREATOR(type, Creator_##type##Solver)&#125;// register SGD SolverREGISTER_SOLVER_CLASS(SGD); 在sgd_solver.cpp(SGD Solver对应的cpp文件)末尾有上面第24行的代码，使用了REGISTER_SOLVER_CLASS这个宏，这个宏会定义一个名为Creator_SGDSolver的函数，这个函数即为Creator类型的指针指向的函数，在这个函数中调用了SGDSolver的构造函数，并将构造的这个变量得到的指针返回，这也就是Creator类型函数的作用：构造一个对应类型的Solver对象，将其指针返回。然后在这个宏里又调用了REGISTER_SOLVER_CREATOR这个宏，这里分别定义了SolverRegisterer这个模板类的float和double类型的static变量，这会去调用各自的构造函数，而在SolverRegisterer的构造函数中调用了之前提到的SolverRegistry类的AddCreator函数，这个函数就是将刚才定义的Creator_SGDSolver这个函数的指针存到g_registry指向的map里面。类似地，所有的Solver对应的cpp文件的末尾都调用了这个宏来完成注册，在所有的Solver都注册之后，我们就可以通过之前描述的方式，通过g_registry得到对应的Creator函数的指针，并通过调用这个Creator函数来构造对应的Solver。 SIGINT和SIGHUP信号的处理Caffe在train或者test的过程中都有可能会遇到系统信号(用户按下ctrl+c或者关掉了控制的terminal)，我们可以通过对sigint_effect和sighup_effect来设置遇到系统信号的时候希望进行的处理方式： caffe train –solver=/path/to/solver.prototxt –sigint_effect=EFFECT –sighup_effect=EFFECT 先看一下train函数的相关调用： 1234caffe::SignalHandler signal_handler( GetRequestedAction(FLAGS_sigint_effect), GetRequestedAction(FLAGS_sighup_effect));solver-&gt;SetActionFunction(signal_handler.GetActionFunction()); 函数GetRequesedAction在caffe.cpp中定义，作用是将设置的string类型的标志转变为枚举类型的变量：12345678910111213141516171819202122caffe::SolverAction::Enum GetRequestedAction( const std::string&amp; flag_value) &#123; if (flag_value == "stop") &#123; return caffe::SolverAction::STOP; &#125; if (flag_value == "snapshot") &#123; return caffe::SolverAction::SNAPSHOT; &#125; if (flag_value == "none") &#123; return caffe::SolverAction::NONE; &#125; LOG(FATAL) &lt;&lt; "Invalid signal effect \""&lt;&lt; flag_value &lt;&lt; "\" was specified";&#125;// SolverAction::Enum的定义namespace SolverAction &#123; enum Enum &#123; NONE = 0, // Take no special action. STOP = 1, // Stop training. snapshot_after_train controls whether a // snapshot is created. SNAPSHOT = 2 // Take a snapshot, and keep training. &#125;;&#125; 其中SolverAction::Enum的定义在solver.hpp中，这是一个定义为枚举类型的数据类型，只有三个可能的值，分别对应了三种处理系统信号的方式： NONE(忽略信号什么都不做) STOP(停止训练) SNAPSHOT(保存当前的训练状态，继续训练) 再回到train函数中设置如何处理系统信号的代码，其中：FLAGS_sigint_effect和FLAGS_sighup_effect是通过gflags定义和解析的两个Command Line Interface的输入参数，分别对应遇到sigint和sighup信号的处理方式，如果用户不设定，sigint的默认值为stop，sighup的默认值为snapshot。GetRequestedAction函数会将string类型的FLAGS_xx转为SolverAction::Enum类型，并用来定义一个SignalHandler类型的对象signal_handler。可以看到这部分代码都依赖于SignalHandler这个类的接口，看一下相关代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// header fileclass SignalHandler &#123; public: // Contructor. Specify what action to take when a signal is received. SignalHandler(SolverAction::Enum SIGINT_action, SolverAction::Enum SIGHUP_action); ~SignalHandler(); ActionCallback GetActionFunction(); private: SolverAction::Enum CheckForSignals() const; SolverAction::Enum SIGINT_action_; SolverAction::Enum SIGHUP_action_;&#125;;// source fileSignalHandler::SignalHandler(SolverAction::Enum SIGINT_action, SolverAction::Enum SIGHUP_action): SIGINT_action_(SIGINT_action), SIGHUP_action_(SIGHUP_action) &#123; HookupHandler();&#125;void HookupHandler() &#123; if (already_hooked_up) &#123; LOG(FATAL) &lt;&lt; "Tried to hookup signal handlers more than once."; &#125; already_hooked_up = true; struct sigaction sa; sa.sa_handler = &amp;handle_signal; // ...&#125;static volatile sig_atomic_t got_sigint = false;static volatile sig_atomic_t got_sighup = false;void handle_signal(int signal) &#123; switch (signal) &#123; case SIGHUP: got_sighup = true; break; case SIGINT: got_sigint = true; break; &#125;&#125;ActionCallback SignalHandler::GetActionFunction() &#123; return boost::bind(&amp;SignalHandler::CheckForSignals, this);&#125;SolverAction::Enum SignalHandler::CheckForSignals() const &#123; if (GotSIGHUP()) &#123; return SIGHUP_action_; &#125; if (GotSIGINT()) &#123; return SIGINT_action_; &#125; return SolverAction::NONE;&#125;bool GotSIGINT() &#123; bool result = got_sigint; got_sigint = false; return result;&#125;bool GotSIGHUP() &#123; bool result = got_sighup; got_sighup = false; return result;&#125;// ActionCallback的含义typedef boost::function&lt;SolverAction::Enum()&gt; ActionCallback; SignalHandler这个类有两个数据成员，都是SolverAction::Enum类型的，分别对应sigint和sighup信号，在构造函数中，用解析FLAGS_xx得到的结果分别给两个成员赋值，然后调用了HookupHandler函数，这个函数的主要作用是定义了一个sigaction类型(应该是系统级别的代码)的对象sa，然后通过sa.sa_handler = &amp;handle_signal来设置，当有遇到系统信号时，调用handle_signal函数来处理，而我们可以看到这个函数的处理很简单，就是判断一下当前的信号是什么类型，如果是sigint就将全局的static变量got_sigint变为true，sighup的处理类似。 在根据用户设置（或者默认值）的参数定义了signal_handler之后，solver通过SetActionFunction来设置了如何处理系统信号。这个函数的输入为signal_handler的GetActionFunction的返回值，根据上面的代码我们可以看到，GetActionFunction会返回signal_handler这个对象的CheckForSignals函数的地址(boost::bind的具体使用请参考boost官方文档)。而在Solver的SetActionFunction函数中只是简单的把Solver的一个成员action_request_function_赋值为输入参数的值，以当前的例子来说就是，solver对象的action_request_function_指向了signal_handler对象的CheckForSignals函数的地址。其中的ActionCallback是一个函数指针类型，指向了参数为空，返回值为SolverAction::Enum类型的函数(boost::function具体用法参考官方文档)。 总结起来，我们通过定义一个SignalHandler类型的对象，告知系统在遇到系统信号的时候回调handle_signal函数来改变全局变量got_sigint和got_sighup的值，然后通过Solver的接口设置了其遇到系统函数将调用signal_handler的Check函数，这个函数实际上就是去判断当前是否遇到了系统信号，如果遇到某个类型的信号，就返回我们之前设置的处理方式(SolverAction::Enum类型)。剩余的具体处理再交给Solver的其它函数，后面会具体分析。 Review caffe，虽然内核是C++，但是其封装非常好，对于使用者来说，只需要写一个文本文档，定义网络结构和相关参数，然后就可以直接运行。运行的环境涉及到C++、Python、MATLAB的语言。所以，在不同的编译环境下，把内核的接口进行相应地转换（编译），就可以运行。 Main Reference http://alanse7en.github.io/caffedai-ma-jie-xi-4/]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】调试笔记]]></title>
    <url>%2F2018%2F06%2F08%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[目的： 在别人的框架上跑自己的数据，熟悉这个流程 测试数据的质量，看看是否适合作为比赛用的数据 在别人的基础上修改，原程序是使用jpg直接训练，这里想修改为lmdb。结果提示 后来一查，说是Inputlayer的类型不对，应该改为Data，注意有两处都要改，如下图： 一共205类，train包含2475个样本，valid包含412个样本，test包含1238个样本，batchsize均为20，训练300个iterations，结果如下： accuracy达到15.67%，然后test，结果只有0.5%，惨不忍睹！ 这分明是随机猜测的结果：205*0.5%≈1.后来一检查，原来是test的输出层没有改。修改完之后，再进行test： 结果为21.29%，明显好很多。后来又训练了700个iterations，训练完的accuracy在20%~25%，test结果如下： 结果为22.02%，仅仅提升了不到0.8个百分点。（这是什么原因？） 所以，数据的样本容量num_sample&amp;batchsize&amp;max_iter之前的关系，是不是可以用一个经验公式来表示？ 比如：max_iter×batchsize/num_sample=N，即每个样本能够训练迭代（forward+backward）N次？ train_iter、test_iter、max_iter等参数的含义，可以搬到这里。 还有，train、valid、test样本集之间的比例该如何把握？ 我觉得，train是evolution的motivation，是这个庞大machine的motor，推动这个machine向我们期待的方向移动，比如跳起来去接触悬在空中的小球，而valid是一个轻盈的小球，所以样本量可以稍微少一点，但是也不排除在这个引导下，由于对人的无解而产生的一种“隐形过拟合”，虽然他并不参与training（没有backward），因为test像是一个广袤的天空，随时随地会出现小球，需要这个machine去碰，所以valid越大越好，那样就越逼近test，而test越大就越逼近现实，因为现实中，无非就是“往天空随意抛出一个小球”，让machine去碰嘛！ 由于PC配置一般，为了减少训练时间，我取了总样本的10%进行训练、验证和测试，这个比例如何把握？ 对于训练而言，取了2475张图片，每个类大约12张，我现在不清楚深度学习网络能够把一张图片学到什么程度？但是可以猜测，如果一个类，特征鲜明（相对于其他类），那么数量可以稍微少一些；如果特征不明确，情况复杂，那么就需要相对多一些的样本来训练网络，以便覆盖到所有的情况。 关于载入已经调好的参数文件.caffemodel，根据网络的名字命名吗？如果遇到新的网络，就随机初始化？ 关于accuracy的计算，看了一下caffe的源码，默认是top-1.所以对于205类的detection，22%的正确率也还行吧？]]></content>
  </entry>
  <entry>
    <title><![CDATA[【caffe】interface]]></title>
    <url>%2F2018%2F06%2F06%2F%E3%80%90caffe%E3%80%91interface%2F</url>
    <content type="text"><![CDATA[Caffe has command line, Python, and MATLAB interfaces for day-to-day usage, interfacing with research code, and rapid prototyping. While Caffe is a C++ library at heart and it exposes a modular interface for development, not every occasion calls for custom compilation. The cmdcaffe, pycaffe, and matcaffe interfaces are here for you. 虽然Caffe是一个C ++库，并且它提供了一个用于开发的模块化接口，但并非每次都需要自定义编译。 Command Line The command line interface – cmdcaffe – is the caffe tool for model training, scoring, and diagnostics. Run caffe without any arguments for help. This tool and others are found in caffe/build/tools. (The following example calls require completing the LeNet / MNIST example first.) Training: caffe train learns models from scratch, resumes learning from saved snapshots, and fine-tunes models to new data and tasks: All training requires a solver configuration through the -solver solver.prototxt argument. Resuming requires the -snapshot model_iter_1000.solverstate argument to load the solver snapshot. Fine-tuning requires the -weights model.caffemodel argument for the model initialization. For example, you can run: # train LeNet caffe train -solver examples/mnist/lenet_solver.prototxt # train on GPU 2 caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 2 # resume training from the half-way point snapshot caffe train -solver examples/mnist/lenet_solver.prototxt -snapshot examples/mnist/lenet_iter_5000.solverstate For a full example of fine-tuning, see examples/finetuning_on_flickr_style, but the training call alone is # fine-tune CaffeNet model weights for style recognition caffe train -solver examples/finetuning_on_flickr_style/solver.prototxt -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel Testing: caffe test scores models by running them in the test phase and reports the net output as its score. The net architecture must be properly defined to output an accuracy measure or loss as its output. The per-batch score is reported and then the grand average is reported last. # score the learned LeNet model on the validation set as defined in the # model architeture lenet_train_test.prototxt caffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 100 Benchmarking: caffe time benchmarks model execution layer-by-layer through timing and synchronization. This is useful to check system performance and measure relative execution times for models. # (These example calls require you complete the LeNet / MNIST example first.) # time LeNet training on CPU for 10 iterations caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10 # time LeNet training on GPU for the default 50 iterations caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0 # time a model architecture with the given weights on the first GPU for 10 iterations caffe time -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 10 Diagnostics: caffe device_query reports GPU details for reference and checking device ordinals for running on a given device in multi-GPU machines. # query the first device caffe device_query -gpu 0 Parallelism: the -gpu flag to the caffe tool can take a comma separated list of IDs to run on multiple GPUs. A solver and net will be instantiated for each GPU so the batch size is effectively multiplied by the number of GPUs. To reproduce single GPU training, reduce the batch size in the network definition accordingly. # train on GPUs 0 &amp; 1 (doubling the batch size) caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 0,1 # train on all GPUs (multiplying batch size by number of devices) caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all Python The Python interface – pycaffe – is the caffe module and its scripts in caffe/python. import caffe to load models, do forward and backward, handle IO, visualize networks, and even instrument model solving. All model data, derivatives, and parameters are exposed for reading and writing. caffe.Net is the central interface for loading, configuring, and running models. caffe.Classifier and caffe.Detector provide convenience interfaces for common tasks. caffe.SGDSolver exposes the solving interface. caffe.io handles input / output with preprocessing and protocol buffers. caffe.draw visualizes network architectures. Caffe blobs are exposed as numpy ndarrays for ease-of-use and efficiency. Tutorial IPython notebooks are found in caffe/examples: do ipython notebook caffe/examples to try them. For developer reference docstrings can be found throughout the code. Compile pycaffe by make pycaffe. Add the module directory to your $PYTHONPATH by export PYTHONPATH=/path/to/caffe/python:$PYTHONPATH or the like for import caffe. MATLAB The MATLAB interface matcaffe is the caffe package in caffe/matlab in which you can integrate Caffe in your Matlab code. In MatCaffe, you can Creating multiple Nets in Matlab Do forward and backward computation Access any layer within a network, and any parameter blob in a layer Get and set data or diff to any blob within a network, not restricting to input blobs or output blobs Save a network’s parameters to file, and load parameters from file Reshape a blob and reshape a network Edit network parameter and do network surgery Create multiple Solvers in Matlab for training Resume training from solver snapshots Access train net and test nets in a solver Run for a certain number of iterations and give back control to Matlab Intermingle arbitrary Matlab code with gradient steps An ILSVRC image classification demo is in caffe/matlab/demo/classification_demo.m (you need to download BAIR CaffeNet from Model Zoo to run it). Build MatCaffe Build MatCaffe with make all matcaffe. After that, you may test it using make mattest. Common issue: if you run into error messages like libstdc++.so.6:version ‘GLIBCXX_3.4.15’ not found during make mattest, then it usually means that your Matlab’s runtime libraries do not match your compile-time libraries. You may need to do the following before you start Matlab: export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64 export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6 Or the equivalent based on where things are installed on your system, and do make mattest again to see if the issue is fixed. Note: this issue is sometimes more complicated since during its startup Matlab may overwrite your LD_LIBRARY_PATH environment variable. You can run !ldd ./matlab/+caffe/private/caffe_.mexa64 (the mex extension may differ on your system) in Matlab to see its runtime libraries, and preload your compile-time libraries by exporting them to your LD_PRELOAD environment variable. After successful building and testing, add this package to Matlab search PATH by starting matlab from caffe root folder and running the following commands in Matlab command window. addpath ./matlab You can save your Matlab search PATH by running savepath so that you don’t have to run the command above again every time you use MatCaffe. Use MatCaffe MatCaffe is very similar to PyCaffe in usage. Examples below shows detailed usages and assumes you have downloaded BAIR CaffeNet from Model Zoo and started matlab from caffe root folder. model = &apos;./models/bvlc_reference_caffenet/deploy.prototxt&apos;; weights = &apos;./models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&apos;; Set mode and deviceMode and device should always be set BEFORE you create a net or a solver. Use CPU: caffe.set_mode_cpu(); Use GPU and specify its gpu_id: caffe.set_mode_gpu(); caffe.set_device(gpu_id); Create a network and access its layers and blobsCreate a network: net = caffe.Net(model, weights, &apos;test&apos;); % create net and load weights Or net = caffe.Net(model, &apos;test&apos;); % create net but not load weights net.copy_from(weights); % load weights which creates net object as Net with properties: layer_vec: [1x23 caffe.Layer] blob_vec: [1x15 caffe.Blob] inputs: {&apos;data&apos;} outputs: {&apos;prob&apos;} name2layer_index: [23x1 containers.Map] name2blob_index: [15x1 containers.Map] layer_names: {23x1 cell} blob_names: {15x1 cell} The two containers.Map objects are useful to find the index of a layer or a blob by its name. You have access to every blob in this network. To fill blob ‘data’ with all ones: net.blobs(&apos;data&apos;).set_data(ones(net.blobs(&apos;data&apos;).shape)); To multiply all values in blob ‘data’ by 10: net.blobs(&apos;data&apos;).set_data(net.blobs(&apos;data&apos;).get_data() * 10); Be aware that since Matlab is 1-indexed and column-major, the usual 4 blob dimensions in Matlab are [width, height, channels, num], and width is the fastest dimension. Also be aware that images are in BGR channels. Also, Caffe uses single-precision float data. If your data is not single, set_data will automatically convert it to single. You also have access to every layer, so you can do network surgery. For example, to multiply conv1 parameters by 10: net.params(&apos;conv1&apos;, 1).set_data(net.params(&apos;conv1&apos;, 1).get_data() * 10); % set weights net.params(&apos;conv1&apos;, 2).set_data(net.params(&apos;conv1&apos;, 2).get_data() * 10); % set bias Alternatively, you can use net.layers(&apos;conv1&apos;).params(1).set_data(net.layers(&apos;conv1&apos;).params(1).get_data() * 10); net.layers(&apos;conv1&apos;).params(2).set_data(net.layers(&apos;conv1&apos;).params(2).get_data() * 10); To save the network you just modified: net.save(&apos;my_net.caffemodel&apos;); To get a layer’s type (string): layer_type = net.layers(&apos;conv1&apos;).type; Forward and backwardForward pass can be done using net.forward or net.forward_prefilled. Function net.forward takes in a cell array of N-D arrays containing data of input blob(s) and outputs a cell array containing data from output blob(s). Function net.forward_prefilled uses existing data in input blob(s) during forward pass, takes no input and produces no output. After creating some data for input blobs like data = rand(net.blobs(&#39;data&#39;).shape); you can run res = net.forward({data}); prob = res{1}; Or net.blobs(&apos;data&apos;).set_data(data); net.forward_prefilled(); prob = net.blobs(&apos;prob&apos;).get_data(); Backward is similar using net.backward or net.backward_prefilled and replacing get_data and set_data with get_diff and set_diff. After creating some gradients for output blobs like prob_diff = rand(net.blobs(&#39;prob&#39;).shape); you can run res = net.backward({prob_diff}); data_diff = res{1}; Or net.blobs(&apos;prob&apos;).set_diff(prob_diff); net.backward_prefilled(); data_diff = net.blobs(&apos;data&apos;).get_diff(); However, the backward computation above doesn’t get correct results, because Caffe decides that the network does not need backward computation. To get correct backward results, you need to set ‘force_backward: true’ in your network prototxt. After performing forward or backward pass, you can also get the data or diff in internal blobs. For example, to extract pool5 features after forward pass: pool5_feat = net.blobs(&apos;pool5&apos;).get_data(); Reshape Assume you want to run 1 image at a time instead of 10: net.blobs(&apos;data&apos;).reshape([227 227 3 1]); % reshape blob &apos;data&apos; net.reshape(); Then the whole network is reshaped (the second command?), and now net.blobs(‘prob’).shape should be [1000 1]; TrainingAssume you have created training and validation lmdbs following our ImageNET Tutorial, to create a solver and train on ILSVRC 2012 classification dataset: solver = caffe.Solver(&apos;./models/bvlc_reference_caffenet/solver.prototxt&apos;); which creates solver object as Solver with properties: net: [1x1 caffe.Net] test_nets: [1x1 caffe.Net] To train: solver.solve(); Or train for only 1000 iterations (so that you can do something to its net before training more iterations) solver.step(1000); To get iteration number: iter = solver.iter(); To get its network: train_net = solver.net; test_net = solver.test_nets(1); To resume from a snapshot your_snapshot.solverstate: solver.restore(&apos;your_snapshot.solverstate&apos;); Input and outputcaffe.io class provides basic input functions load_image and read_mean. For example, to read ILSVRC 2012 mean file (assume you have downloaded imagenet example auxiliary files by running ./data/ilsvrc12/get_ilsvrc_aux.sh): mean_data = caffe.io.read_mean(&apos;./data/ilsvrc12/imagenet_mean.binaryproto&apos;); To read Caffe’s example image and resize to [width, height] and suppose we want width = 256; height = 256; im_data = caffe.io.load_image(&apos;./examples/images/cat.jpg&apos;); im_data = imresize(im_data, [width, height]); % resize using Matlab&apos;s imresize Keep in mind that width is the fastest dimension and channels are BGR, which is different from the usual way that Matlab stores an image. If you don’t want to use caffe.io.load_image and prefer to load an image by yourself, you can do im_data = imread(&apos;./examples/images/cat.jpg&apos;); % read image im_data = im_data(:, :, [3, 2, 1]); % convert from RGB to BGR im_data = permute(im_data, [2, 1, 3]); % permute width and height im_data = single(im_data); % convert to single precision Also, you may take a look at caffe/matlab/demo/classification_demo.m to see how to prepare input by taking crops from an image. We show in caffe/matlab/hdf5creation how to read and write HDF5 data with Matlab. We do not provide extra functions for data output as Matlab itself is already quite powerful in output. Clear nets and solversCall caffe.reset_all() to clear all solvers and stand-alone nets you have created. Reference http://caffe.berkeleyvision.org/tutorial/interfaces.html caffe学习与当前的任务 caffe本质上仍是C++，只不过提供了很多借口，使得在不同环境下可以运行（训练和测试）， 什么才是不同的语言呢？主要还是看网络的实现方式，如果用python编写，例如用到很多nn的函数；caffe的网络虽然在prototxt中定义，看起来像一个纯文本，但是他是要送到后方经过C++处理的。 对于目前的任务，我想，一个是自己fine-tuning数据公司提供的数据，看看质量如何；另一个就是等到数据发布后，选手们会提交自己的框架、算法、代码，到时候会对他们进行测试，即调用网络并计算出一定的指标。除此之外，说的稍微远一点，detection和segmentation也要看一些，到时候万一用得着呢？反正以后一定会用得着。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】批量删除子文件夹和文件名中的空格]]></title>
    <url>%2F2018%2F06%2F06%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E5%AD%90%E6%96%87%E4%BB%B6%E5%A4%B9%E5%92%8C%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%AD%E7%9A%84%E7%A9%BA%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[目的： 利用create_imagenet在jpg基础上得到lmdb格式的文件； 问题： create_imagenet中的路径不支持空格，所以需要将文件路径以及文件名中的所有空格删除，由于有200+个子文件夹以及4w+张图片，因此需要批量操作。 使用昨天生成标签文档txt的程序肯定不行，因为那个只是读取路径和文件名，然后分配一个类别，生成txt文档；而现在需要做的是对文件路径和文件名进行实际的修改。 Google了一个“如何批量删除文档空格”，给出的95%的例程都是单文件夹下进行操作。而我们的文档组织结构如下： 所以需要先遍历子文件夹，再遍历其中每张图片。 1. 在子文件夹下删除图片名字中的空格——这是最核心的操作12345for name in *.jpgdo na=$(echo $name | tr ' ' '_') #tr ' ' '_' 将空格替换为下划线。单行执行时，读取屏幕输入，并输出执行后结果 mv "$name" "$na"done 其中，| 叫做管道符号，tr为translate的缩写，主要用于删除文件中的控制字符，或进行字符转换。 mv是move的缩写，用来移动文件或者对文件改名。关于这个命令，我觉得设计地很模糊，对新人不友好，对于移动文件还是对文件改名只是根据第二个参数的类型，而我们要修改的对象包括路径本身，如果这个路径是新的路径（之前的路径中有空格），那么就会产生新路径并将原路径下的文件剪切到新路径下；如果这个路径仍是原路径（原路径中没有空格，无需改动），那么就会提示无法移动文件。 语法： mv [选项] 源文件或目录 目标文件或目录 操作说明： 视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。 mv执行结果： 题外话：后来无意发现这里有一个小奇葩，但是也不影响后续生成lmdb的操作： 2. 对子文件夹的名称进行操作如果上来就用： 12345678910filelist=`ls /home/sun/Documents/python/PRCV2018/data/project1/image/`num=0for file in $filelistdo newname=$(echo $file | tr ' ' '_') mv "$path$file" "$path$newname" echo $file let num+=1doneecho $num 那么系统会将带有空格的文件夹名称分隔开，如“A B.txt”变为A，B.txt。Google了以下解决方案，只需要在for循环的前面加上即可。在上述基础上，对文件名进行处理：12345678910111213IFS=$(echo -en "\n\b")echo -en $IFSfilelist=`ls /home/sun/Documents/python/PRCV2018/data/project1/image/`num=0for file in $filelistdo newname=$(echo $file | tr ' ' '_') mv "$path$file" "$path$newname" echo $file let num+=1doneecho $num 此时得到了文件的绝对路径，下一步就是在绝对路径的索引下，和上一部分内容结合，对文件进行处理。这时有个很重要的部分，就是需要结合文档结构进行操作——需要先遍历子文件夹，然后遍历文件。 3. 使用Shell遍历目录及其子目录中的所有文件该部分主要参考这位前辈的教程： 4. 结果 当然奇葩仍然存在： 删除了文件路径以及文件名中的空格之后，很快就得到了lmdb文件： 除了文章中列出的参考教程，还参考了以下教程，在此罗列出来，对于一个新人，可以让我们从不同角度了解shell的语法和原理:[1] shell遍历目录下所有文件： https://blog.csdn.net/u012307002/article/details/51308710 [2] mv无法获取文件状态（根本原因是路径不对，或者文件不存在）： http://forum.ubuntu.org.cn/viewtopic.php?f=21&amp;t=395842 [3] shell函数的定义和调用： http://www.runoob.com/linux/linux-shell-func.html [4] let指令： https://www.cnblogs.com/kaishirenshi/p/7686910.html [5] shell 中的for、while循环及if语句： https://www.cnblogs.com/wenqiang/p/5352276.html [6] BASH Shell: For Loop File Names With Spaces： https://www.cyberciti.biz/tips/handling-filenames-with-spaces-in-bash.html [7] SHELL技巧：处理文件名中的那些空格： http://www.cnblogs.com/cocowool/archive/2013/01/15/2861904.html [8] Linux系统下除去文件名称中的空格字符： http://blog.sina.com.cn/s/blog_7ed5a8080101bh90.html [9] Shell处理有空格的文件夹： https://my.oschina.net/yehun/blog/893217]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】生成标签文件]]></title>
    <url>%2F2018%2F06%2F05%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91%E7%94%9F%E6%88%90%E6%A0%87%E7%AD%BE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[预期实现效果 生成一个标签文本，文本的每一行表示一个样本，格式为： 图片地址/名称（空格）标签类别具体如下图： 根据比例，对总数据集进行划分，分为train.txt、val.txt、test.txt。 分步实现 join的作用： 是在拼接路径的时候用的。举个例子： os.path.join(“home”, “me”, “mywork”) 在Linux系统上会返回“home/me/mywork” 在Windows系统上会返回”home\me\mywork” 好处是可以根据系统自动选择正确的路径分隔符”/“或”\” 实现两级读取 folders = GetFileList(&apos;/media/sun/Seagate Expansion Drive/CAS/project1/image&apos;) # 该路径为图片的存放地址 i=0 for folder in folders: i+=1 print(i,&apos;:&apos;,folder) 通过上述代码，发现folders就是路径，所以后面可以直接将教程的循环作为内循环： total_txt = open(&apos;total.txt&apos;, &apos;w&apos;) for ind, folder in enumerate(folders): imgfile = GetFileList(folder) for img in imgfile: str1 = img + &apos; &apos; + str(ind) + &apos;\n&apos; total_txt.writelines(str1) total_txt.close() 至此，生成total.txt，包含了所有的jpg以及他们对应的类（每个文件夹下的所有图片为一个类，从0开始标注）。下面根据一定比例，将total.txt分割为train.txt、valid.txt、test.txt。 实现对txt的逐行读取 specify = [1,3,5] for ind in specify: str2 = linecache.getline(&apos;total.txt&apos;,ind) print(str2) 生成txt 参考 https://blog.csdn.net/qq_15505637/article/details/77687910 生成随机数 生成指定范围内的、无重复的、整数、随机值。 alternative method： 利用shuffle()先对index打乱，然后直接对index进行整段划分； 对total.txt按指定行读取，并存储到新的txt文件 def split_data(p_train = 0.6, p_val = 0.1, p_test = 0.4): t = list(range(num_total)) random.shuffle(t) num_train = int(p_train*num_total) num_val = int(p_val*num_total) num_test = num_total - num_train - num_val print(num_train,num_val,num_test,num_train+num_val+num_test) train_ind = t[0:num_train] val_ind = t[num_train:num_train+num_val] test_ind = t[num_train+num_val:] print(len(train_ind),len(val_ind),len(test_ind)) # print(type(train_ind)) train_txt = open(&apos;train.txt&apos;, &apos;w&apos;) for ind in train_ind: str2 = linecache.getline(&apos;total.txt&apos;, ind) train_txt.writelines(str2) # print(str2) train_txt.close() val_txt = open(&apos;val.txt&apos;, &apos;w&apos;) for ind in val_ind: str2 = linecache.getline(&apos;total.txt&apos;, ind) val_txt.writelines(str2) # print(str2) val_txt.close() test_txt = open(&apos;test.txt&apos;, &apos;w&apos;) for ind in test_ind: str2 = linecache.getline(&apos;total.txt&apos;, ind) test_txt.writelines(str2) # print(str2) test_txt.close() 最终结果 根据img文件的存放，生成标签文档total.txt； 根据给定的比例，对total.txt进行打乱划分，生成三个子标签文档train.txt、val.txt、test.txt。 Reference https://blog.csdn.net/u010417185/article/details/52119863]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】linux下安装MATLAB 2017a]]></title>
    <url>%2F2018%2F06%2F04%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91linux%E4%B8%8B%E5%AE%89%E8%A3%85MATLAB%202017a%2F</url>
    <content type="text"><![CDATA[1.下载文件Matlab R2017a 链接地址：https://pan.baidu.com/s/1hsVnxdE#list/path=%2F（如果失效，可以私信我） 2.安装MATLAB安装过程全称参考[1]，没有什么问题。有两点需要重复一下： ####2.1 挂载iso文件的命令 进入R2017a_glnxa64_dvd1.iso的文件目录下，打开终端，运行： $sudo mount -t auto -o loop R2017a_glnxa64_dvd1.iso /home/sun/Matlab 即： $sudo mount -t auto -o 文件名.iso MATLAB的安装路径 在挂载R2017a_glnxa64_dvd2.iso时也是同样的操作。挂载完成后，会多出一个盘，说明挂载成功。同时自动弹出一个iso文件界面，就是里面的内容。 ####2. 错误：无法从DVD内部安装运行程序… 其实教程[1]中已经提到这个问题，作为小白的我一时没有看懂，所以折腾了一下。按照以下命令运行： cd cd /home/sun/Matlab sudo ./install 3.破解在安装完MATLAB进行破解时，由于版本为2017a，而教程[1]的版本为2016a，所以参考了第二个教程[2]。在2017a中，只需要拷贝两个文件即可： license_standalone.lic libmwservices.so 碎碎念：在教程[1]中，对我而言有个比较新的点是，取消安装目录的权限： 进入到MATLAB文件夹，然后执行以下命令： sudo chmod 777 * -R 4.生成MATLAB桌面快捷方式：1.添加路径在根目录（/home/sun）中，找到.bashrc，添加一句指令，见教程[1]； 2.生成快捷方式进入/home/sun/.local/share/applications，运行以下命令： sudo gedit /usr/share/applications/Matlab.desktop 生成一个启动器，然后将下列代码拷进去： [Desktop Entry] Type=Application Name=Matlab GenericName=Matlab 2017a Comment=Matlab:The Language of Technical Computing Exec=sh /home/sun/MATLAB/R2017a/bin/matlab -desktop Icon=/home/sun/MATLAB/R2017a/toolbox/nnet/nnresource/icons/matlab.png StartupNotify=true Terminal=false Categories=Development;Matlab; 注意修改文件路径！ 然后就生成了MATLAB的图标，将其拷贝到桌面即可。 Reference[1]. https://blog.csdn.net/GJXS2017/article/details/78705410 [2]. https://blog.csdn.net/u011713358/article/details/69659265 [3]. https://blog.csdn.net/bug_creator/article/details/79382525 Update再次安装出现的新问题： 安装的时候没有弹出图形安装界面，直接显示installing… finish! 则需要在根目录media下来安装[4]. https://blog.csdn.net/xunan003/article/details/79210712 解决方法：]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】在自己的数据集上跑深度学习]]></title>
    <url>%2F2018%2F06%2F02%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91%E5%9C%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%B7%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[今天在比较真实的数据集（Oxford flower dataset）上，第一次，真正地开始跑深度学习框架。 上一篇文章开头提到，使用深度学习解决问题主要分为四个步骤： 下载图片，并制作分类信息txt，分别在train.txt、valid.txt和test.txt中将图片名称与类别相对应； 根据上述文件，生成lmdb； 定义自己的深度学习框架，设置好参数； 训练并验证。 折腾完1、2步，接下来就用到深度学习的具体知识了。 让我们从训练时的指令开始： caffe train -solver=solver.prototxt -weights=pretrained-weights.caffemodel -gpu 0 参数solver指定的文件solver.prototxt： net: &quot;train_val.prototxt&quot; #test_iter: 21 # enough iterations to cover the 1020 images with a batch size of 50 test_iter: 4 #test_interval: 500 test_interval: 50 base_lr: 0.001 # lr for fine-tuning should be lower than when starting from scratch lr_policy: &quot;step&quot; gamma: 0.1 stepsize: 20000 # stepsize should also be lower, as we&apos;re closer to being done #display: 50 display: 10 #max_iter: 50000 # 160+ h max_iter: 3000 momentum: 0.9 weight_decay: 0.0005 snapshot: 5000 snapshot_prefix: &quot;snapshot&quot; #solver_mode: GPU solver_mode: CPU 这个文件主要是设置训练的参数，由变量的定义可以比较直观地看出他们的含义。由于我的目的是体验一下这个完整的流程，对正确率暂时没有要求，所以做了一些更改。 参数weights指定网络中参数的初始化文件，这对于fine-tuning非常重要。现在给的是pretrained-weights.caffemodel，表明用这个文件初始化深度学习网络。除此之外，在snapshot后，也会生成类似文件，如snapshot_iter_617.caffemodel，表示迭代到617次时的网络参数，以后可以在这个基础上恢复训练。 参数gpu指定在用到的gpu编号。由于我的渣渣电脑是AMD的gpu，现在也不知道怎么用，所以默默选择了用CPU训练，删掉了这一部分。 接下来进入solver.prototxt文件，主要看网络开头的数据层： name: &quot;Oxford102_CaffeNet&quot; layer { name: &quot;data&quot; type: &quot;ImageData&quot; top: &quot;data&quot; top: &quot;label&quot; image_data_param { source: &quot;/home/sun/Documents/python/fine-tuning/Oxford102/CaffeNet/auxiliary/train.txt&quot; batch_size: 50 new_height: 256 new_width: 256 } transform_param { crop_size: 227 mean_file: &quot;/home/sun/Documents/python/fine-tuning/Oxford102/CaffeNet/auxiliary/imagenet_mean.binaryproto&quot; mirror: true } include: { phase: TRAIN } } layer { name: &quot;data&quot; type: &quot;ImageData&quot; top: &quot;data&quot; top: &quot;label&quot; image_data_param { source: &quot;/home/sun/Documents/python/fine-tuning/Oxford102/CaffeNet/auxiliary/valid.txt&quot; batch_size: 50 new_height: 256 new_width: 256 } transform_param { crop_size: 227 mean_file: &quot;/home/sun/Documents/python/fine-tuning/Oxford102/CaffeNet/auxiliary/imagenet_mean.binaryproto&quot; mirror: false } include: { phase: TEST } } layer { name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; top: &quot;conv1&quot; param { lr_mult: 1 decay_mult: 1 } 主要还是路径的设置： source：表示图片的路径。注意这里用到的仍是jpg数据，而不是lmdb。难道折腾的lmdb就是为了计算mean文件吗？既然用到jpg数据，txt中的图片名称前，就要加上其绝对路径，这一点与计算lmdb时的txt不一样。 mean_file：均值文件的路径。 更改完这些之后，就可以开心地训练了！ 一开始我没有看清楚solver文件中的参数含义，训练时max_iter仍然保留原来的50000.计算一下需要160+个小时，也就是下周的这个时候，然后果断终止了训练。比较意外的是，终止后，自动进行snapshot，保留了当时的参数文件.caffemodel，这一点很让人感动。 第一次完整地跑这个流程，还是非常激动的。熟练之后，就可以为所欲为，实现自己的idea了！ 截个训练时的图：]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】深度学习之流程初体验]]></title>
    <url>%2F2018%2F05%2F30%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91%E9%80%9A%E8%BF%87MNIST%E4%BE%8B%E7%A8%8B%E4%B8%8A%E6%89%8Bfine%20tuning%EF%BC%88%E9%99%84caffe%E5%AE%89%E8%A3%85%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深度学习（分类问题）的流程大致为： 准备数据 准备模型 加载数据、模型以及参数 调试参数（反复的训练、验证和测试） 利用compute_image_mean.cpp生成个人数据集的均值文件imagenet_mean.binaryproto 1.获取compute_image_mean.cpp（安装caffe）上次说道，在数据集上跑baseline，有一个很好的项目，https://github.com/junyuseu/fine-tuning，clone下来运行时发现，少了个均值文件mean_file: “../imagenet_mean.binaryproto”，Google一下，都说是用..caffe/tools文件夹里面的compute_image_mean.cpp文件生成。既然文件路径都这么统一，那很可能是安装的caffe自带的文件。然后Google如何在Linux下（CPU only）安装caffe。问题解决（参考：1 2 3）。（如果Google和百度都找不到类似的问题，那就说明这个问题非常personal） 2.通过MNIST样例，实现完整的深度学习流程（caffe自带工具.sh等的语法解释和剖析）# 第一步：下载 MNIST 数据集 ./data/mnist/get_mnist.sh # 第二步：数据格式转换 ./examples/mnist/create_mnist.sh # 第三步：训练LeNet-5的网络参数 ./examples/mnist/train_lenet.sh # 第四步：对测试集进行预测测试 ./build/tools/caffe.bin test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -iterations 100 下面对这些步骤进行详细地解释： 第一步，获取数据。由于我们用的是自己的数据集，所以这里暂时不用详细了解get_mnist.sh文件。 第二步，将数据转换为lmdb/leveldb格式。看一下create_mnist.sh的细节： #!/usr/bin/env sh # This script converts the mnist data into lmdb/leveldb format, # depending on the value assigned to $BACKEND. set -e ###此处为变量设置，用于简化后面的表达 EXAMPLE=examples/mnist ###指定lmdb/leveldb文件生成的地址 DATA=data/mnist ###上一步生成的data的存放地址 BUILD=build/examples/mnist ###暂时不知道如何打开bin(这里刨个坑) ###指定lmdb/leveldb BACKEND=&quot;lmdb&quot; echo &quot;Creating ${BACKEND}...&quot; ###删除当前的lmdb文件，如果有的话。 rm -rf $EXAMPLE/mnist_train_${BACKEND} rm -rf $EXAMPLE/mnist_test_${BACKEND} #这里是该文件的主要部分，利用.bin工具，对第一步得到的data以及对应的label进行处理，得到lmdb/leveldb。至于为什么要这样做，lmdb/leveldb文件又是什么？这里刨个坑。 $BUILD/convert_mnist_data.bin $DATA/train-images-idx3-ubyte \ $DATA/train-labels-idx1-ubyte $EXAMPLE/mnist_train_${BACKEND} --backend=${BACKEND} $BUILD/convert_mnist_data.bin $DATA/t10k-images-idx3-ubyte \ $DATA/t10k-labels-idx1-ubyte $EXAMPLE/mnist_test_${BACKEND} --backend=${BACKEND} echo &quot;Done.&quot; 第三步，训练LeNet-5的网络参数。看一下train_lenet.sh的细节： #!/usr/bin/env sh set -e # 我也是刚接触shell语法，百度了一下，这么说： # set命令的-e参数，linux自带的说明如下： # &quot;Exit immediately if a simple command exits with a non-zero status.&quot; # 也就是说，在&quot;set -e&quot;之后出现的代码，一旦出现了返回值非零，整个脚本就会立即退出。有的人喜欢使用这个参 数，是出于保证代码安全性的考虑。但有的时候，这种美好的初衷，也会导致严重的问题。 # 运行solver，即examples/mnist/lenet_solver.prototxt ./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt $@ 运行第三步后，开始训练。下面是训练的一部分截图： 可以看到每隔500次iteration，进行一次in-training的test。这与我们在lenet_solver.prototxt中设定的参数有关： # Carry out testing every 500 training iterations. test_interval: 500 除此之外，在迭代到5000的时候，文件夹里出现了如下文件： 这也和我们设置的参数有关： # snapshot intermediate results snapshot: 5000 snapshot_prefix: &quot;examples/mnist/lenet&quot; 这样也顺便理解了一点snapshot的作用：在训练中保存一些中间的状态，方便以后追踪或者从此处开始复原。我现在能想到的最具体的作用——由于训练需要很长时间，万一中间发生了点意外，训练终止（比如停电！），那么我们可以从最近的一个时间点开始恢复，不至于前功尽弃。在学术上可能也有点用，比如在训练到一定阶段后用两种不同的方法进行训练从而对比效果？以后慢慢体会。 总之，该步之后，就完成了最终的训练，理论上应该得到理想的网络。这种理想网络的实质就是基于训练框架（net: “examples/mnist/lenet_train_test.prototxt”）的一套参数，因为训练完后，仅仅多生成以下两个文件，除此之外没有察觉到任何变化。（下一步对网络test的指令也可以印证这一点） 最后一步：对训练结果进行测试。 ./build/tools/caffe.bin test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -iterations 100 同样，利用caffe.bin这个工具进行测试。参数如下： test：表示状态（？） model：同train阶段，lenet_train_test.prototxt weights：训练的结果，lenet_iter_10000.caffemodel iterations：迭代次数为100（不太理解为什么在test阶段需要这个？） 测试的accuracy在99%以上，训练非常理想。这样就实现了下载数据——准备数据（转换为lmdb/leveldb格式）——训练模型——测试模型深度学习的完整流程。 Referencehttps://blog.csdn.net/xhhjin/article/details/78512913]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】python3中的zip函数]]></title>
    <url>%2F2018%2F05%2F28%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91python3%E4%B8%AD%E7%9A%84zip%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[今天开始探索“如何在数据集上跑baseline”，一大早就找到了一个很好的项目，本以为可以速战速决，结果一开始就踩了个zip的坑。 源代码片段如下： labels = np.array(zip(files, image_labels)) ～～～（中间部分）～～～ def write_set_file(fout, labels): with open(fout, &apos;w+&apos;) as f: for label in labels: f.write(&apos;{}/{} {}\n&apos;.format(cwd,label[0],label[1])) write_set_file(&apos;train.txt&apos;, labels[idx_train,:]) write_set_file(&apos;test.txt&apos;, labels[idx_test,:]) write_set_file(&apos;valid.txt&apos;, labels[idx_valid,:]) 总体来看，就是根据图片名称，对其分类标签进行数字化，然后对数据集切分为train、test、valid三大部分。结果run之后，提示： IndexError: too many indices for array 找到错误位置，打印labels.shape，结果是空；又打印labels，结果显示; ndarray &lt;zip object at 0x7fa11be482c8&gt; 为此专门在python在线工具测试了一小段代码： x = [1, 2, 3] y = [4, 5, 6] z = [7, 8, 9] xyz = zip(x, y, z) print(xyz) array = np.array(xyz) print(array) 结果输出一切正常： [(1, 4, 7), (2, 5, 8), (3, 6, 9)] [[1 4 7] [2 5 8] [3 6 9]] 这就开始了自我怀疑的入坑之路。后来无意中Google了一下： ndarray &lt;zip object at 0x7fa11be482c8&gt; 然后才发现问题所在： 由于版本问题，python3中zip返回的是一个迭代器，这跟之前不一样，所以打印时看不到具体的内容。只有通过list(zip(object))才能将其内容呈现出来。而array，好像跟list没有直接关系 (我找的所有资料都是将zip转换为list)。至于之间的种种原因，还没来得及细究，迭代器之类的隐形坑以后补上，现在先专注于实现baseline。总之，通过list过渡，解决了这个问题： labels = list(zip(files, image_labels)) labels = np.array(labels) print(labels) 回头想想这个锅应该分给python在线工具，结果仔细一搜才发现，这个在线工具也是分版本的，我之前一直用的碰巧是python2。 不甘心，为了identify两个环境下的结果，又找了python3的在线工具，同样执行上面的小段代码，结果显示： &lt;zip object at 0x7fa67deba808&gt; &lt;zip object at 0x7fa67deba808&gt; 完美。 教训 不能只盯着初始的、显化的debug信息，应该进行思考分析，追根溯源，若发现过程中有哪些不正常的现象，就去Google，这样才能真正找到问题根源。 调试代码的过程中(科研应该也是)，如果怀疑地很是地方、很犀利，那么问题很容易解决，并且产生好的idea，即“好的问题”能为你打开一个世界的大门。 reference： http://www.cnblogs.com/antflow/p/7299112.html https://stackoverflow.com/questions/31683959/the-zip-function-in-python-3?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa https://blog.csdn.net/weixin_37226516/article/details/60881763 拾穗来自底层科研人员的疑问：为什么同样的方法，大神很容易发文章而我却被拒？ A： Q：]]></content>
  </entry>
  <entry>
    <title><![CDATA[【ML一步一脚印】CIFAR10的数据结构]]></title>
    <url>%2F2018%2F05%2F27%2F%E3%80%90ML%E4%B8%80%E6%AD%A5%E4%B8%80%E8%84%9A%E5%8D%B0%E3%80%91CIFAR10%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[之前自己钻研faster rcnn的源码，读到paper中对应的关键地方，总是因为数据结构的一些问题戛然而止，而数据问题追根溯源要看imbd (image database) 的结构。机缘巧合，今天想到了这个问题的关键点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475''''' 首先把官网的python版本数据下载保存到本地 '''file1 = '/home/sun/Documents/python/spring1718_assignment2_v2/cs231n/datasets/cifar-10-batches-py/data_batch_1'file2 = '/home/sun/Documents/python/spring1718_assignment2_v2/cs231n/datasets/cifar-10-batches-py/batches.meta'file3 = '/home/sun/Documents/python/spring1718_assignment2_v2/cs231n/datasets/cifar-10-batches-py/test_batch' def unpickle(file): # 该函数将cifar10提供的文件读取到python的数据结构(字典)中 import pickle fo = open(file, 'rb') dict = pickle.load(fo, encoding='iso-8859-1') fo.close() return dict dict_train_batch1 = unpickle(file1) # 将data_batch文件读入到数据结构(字典)中 print("---------------------train_batch1---------------------")print("type_train_batch1:",type(dict_train_batch1))print(dict_train_batch1) # 每个batch是一个字典print("\n") print("---------------------key_train_batch1---------------------")print(dict_train_batch1.keys()) # 字典里有4组键值对print("\n") ''''' trainSet字典里有4组键值对 1，batch_label ：表明batch的位置,没什么用 2，data ：32*32图片的数值化数组，是一个10000*3072的numpy二维数组, 每一行代表一张图片，一行分3段(红绿蓝色道)，每段1024个元素。 3，labels ：data每一行对应的标签（数字0-9），是个一维数组，10000个元素 4，filenames ： data每一行对应的文件名，同是一个一维数组，10000个元素 '''print("---------------------data_train_batch1---------------------")data_train_batch1 = dict_train_batch1.get('data') # 字典中取dataprint("type_data_train_batch1:",type(data_train_batch1))print("shape_data_train_batch1:",data_train_batch1.shape)print(data_train_batch1)print("\n") print("---------------------label_train_batch1---------------------")labels = dict_train_batch1.get('labels') # 字典中取labelsprint("type_labels",type(labels))print("len_label_train_batch1:",len(labels))print(labels)print("\n") print("---------------------filename_train_batch1---------------------")filenames = dict_train_batch1.get('filenames') # 字典中取filenamesprint("type_filenames,",type(filenames))print("len_filenames,",len(filenames))print(filenames)print("\n") print('--------------我是分割线---------------------------------') dict_test_batch = unpickle(file3)print(dict_test_batch)print(dict_test_batch.keys())''''' 跟trainSet中一样，testSet中有相同的4组键值对 说明同上 ''' print('--------------我是分割线---------------------------------') ''''' batches.meta是一个字典，其中包含了一个列表，列表中是10种分类的具体名称 一般这个文件用不到 '''dict_meta_batch = unpickle(file2)print("type_meta_batch,",type(dict_meta_batch))print(dict_meta_batch) reference: [1] https://blog.csdn.net/qq_32166627/article/details/62043568 [2] http://www.cs.toronto.edu/~kriz/cifar.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[GoldenTime]]></title>
    <url>%2F2018%2F05%2F26%2F2018-05-26-goldentime%2F</url>
    <content type="text"><![CDATA[Today is a beautiful day. I learn two skills: replace the back tyre of my bike (with the aid of my senior labmate) build my personal blog (based on github) For me, learning happens everyday, but recording not. It has embarrassed me for a time. So I push myself to build this blog. Life is easy, you get what you pay. Think and Action, with pure heart, strong heart, open heart, positive heart. This is my goldentime! Come on!]]></content>
  </entry>
</search>
